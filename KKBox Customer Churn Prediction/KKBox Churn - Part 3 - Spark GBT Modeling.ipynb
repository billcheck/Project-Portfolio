{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KKBox Customer Churn Prediction\n",
    "### w/ BigQuery and Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: <font color=green>*Model Creation and Evaluation*</font>\n",
    "Please refer to the following article for a comprehensive review of the project: XXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "from __future__ import absolute_import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports for PySpark\n",
    "import findspark\n",
    "findspark.init()\n",
    "# import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# # Imports for BigQuery connection\n",
    "# import json\n",
    "# import pprint\n",
    "# import subprocess\n",
    "\n",
    "# # Imports for GCP\n",
    "# from google.cloud import bigquery\n",
    "import time \n",
    "# import gcsfs\n",
    "\n",
    "# Imports for Spark ML\n",
    "from pyspark.ml.feature import (VectorAssembler,StandardScaler, OneHotEncoderEstimator, OneHotEncoder)\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, Evaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataproc Specs\n",
    "\n",
    "# Jupyter Initialization: gs://srcd-dataproc/jupyter.sh \n",
    "# Components Installed: Anaconda and Jupyter\n",
    "# Master Node:   x1 - 4 vCPU w/ 15 GB RAM each\n",
    "# Workers Nodes: x5 - 4 vCPU w/ 15 GB RAM each\n",
    "# Disk: 100GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Google Credentials\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='D:\\OneDrive\\J-5\\GitHub\\Google Credentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.Builder().config(conf=SparkConf().setMaster(\"local[*]\")).getOrCreate()\n",
    "\n",
    "# Instantiate BigQuery magic\n",
    "# %load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[msno: string, membership_expire_date: timestamp, payment_method_id: int, payment_plan_days: int, plan_list_price: int, net_paid_amount: int, is_net_paid_amount: string, is_auto_renew: int, is_cancel: int, city: int, bd: int, registered_via: int, registration_init_time: timestamp, membership_length: int, is_churn: int, total_songs: int, total_logins: int, total_secs: double, sum_num_unq: int, sum_num_repeat: int, sum_over_50pec: int, sum_over_75pec: int, sum_over_985pec: int, total_transactions: int, total_spent: int, avg_spent_trans: double, spent_per_logins: double, spent_per_secs: double, spent_per_song: double, spent_per_num_unq: double, spent_per_num_repeats: double, never_active_subscriber: int, total_spent_zero: int, city_agg: int, payment_method_agg: int, expire_last_login: int, total_cancelations: int, songs_last_7: int, songs_last_7_AVG: double, logins_last_7: int, logins_last_7_AVG: double, total_secs_last_7: double, total_secs_last_7_AVG: double, num_unq_last_7: int, num_unq_last_7_AVG: double, num_repeat_last_7: int, num_repeat_last_7_AVG: double, over_50perc_last_7: int, over_50perc_last_7_AVG: double, over_75perc_last_7: int, over_75perc_last_7_AVG: double, over_985perc_last_7: int, over_985perc_last_7_AVG: double, songs_last_15: int, songs_last_15_AVG: double, logins_last_15: int, logins_last_15_AVG: double, total_secs_last_15: double, total_secs_last_15_AVG: double, num_unq_last_15: int, num_unq_last_15_AVG: double, num_repeat_last_15: int, num_repeat_last_15_AVG: double, over_50perc_last_15: int, over_50perc_last_15_AVG: double, over_75perc_last_15: int, over_75perc_last_15_AVG: double, over_985perc_last_15: int, over_985perc_last_15_AVG: double, songs_last_30: int, songs_last_30_AVG: double, logins_last_30: int, logins_last_30_AVG: double, total_secs_last_30: double, total_secs_last_30_AVG: double, num_unq_last_30: int, num_unq_last_30_AVG: double, num_repeat_last_30: int, num_repeat_last_30_AVG: double, over_50perc_last_30: int, over_50perc_last_30_AVG: double, over_75perc_last_30: int, over_75perc_last_30_AVG: double, over_985perc_last_30: int, over_985perc_last_30_AVG: double, songs_last_60: int, songs_last_60_AVG: double, logins_last_60: int, logins_last_60_AVG: double, total_secs_last_60: double, total_secs_last_60_AVG: double, num_unq_last_60: int, num_unq_last_60_AVG: double, num_repeat_last_60: int, num_repeat_last_60_AVG: double, over_50perc_last_60: int, over_50perc_last_60_AVG: double, over_75perc_last_60: int, over_75perc_last_60_AVG: double, over_985perc_last_60: int, over_985perc_last_60_AVG: double, songs_last_120: int, songs_last_120_AVG: double, logins_last_120: int, logins_last_120_AVG: double, total_secs_last_120: double, total_secs_last_120_AVG: double, num_unq_last_120: int, num_unq_last_120_AVG: double, num_repeat_last_120: int, num_repeat_last_120_AVG: double, over_50perc_last_120: int, over_50perc_last_120_AVG: double, over_75perc_last_120: int, over_75perc_last_120_AVG: double, over_985perc_last_120: int, over_985perc_last_120_AVG: double, login_after_expire_10: int, login_after_expire_20: int, login_after_expire_30: int, SUM_unq_songs_0_15: int, AVG_unq_songs_0_15: double, STD_unq_songs_0_15: double, SUM_songs_0_15: int, AVG_songs_0_15: double, STD_songs_0_15: double, SUM_secs_0_15: double, AVG_secs_0_15: double, STD_secs_0_15: double, SUM_songs50_0_15: int, AVG_songs50_0_15: double, STD_songs50_0_15: double, SUM_logins_0_15: int, AVG_logins_0_15: double, SUM_repeats_0_15: int, AVG_repeats_0_15: double, STD_repeats_0_15: double, SUM_unq_songs_15_30: int, AVG_unq_songs_15_30: double, STD_unq_songs_15_30: double, SUM_songs_15_30: int, AVG_songs_15_30: double, STD_songs_15_30: double, SUM_secs_15_30: double, AVG_secs_15_30: double, STD_secs_15_30: double, SUM_songs50_15_30: int, AVG_songs50_15_30: double, STD_songs50_15_30: double, SUM_logins_15_30: int, AVG_logins_15_30: double, SUM_repeats_15_30: int, AVG_repeats_15_30: double, STD_repeats_15_30: double, SUM_unq_songs_30_45: int, AVG_unq_songs_30_45: double, STD_unq_songs_30_45: double, SUM_songs_30_45: int, AVG_songs_30_45: double, STD_songs_30_45: double, SUM_secs_30_45: double, AVG_secs_30_45: double, STD_secs_30_45: double, SUM_songs50_30_45: int, AVG_songs50_30_45: double, STD_songs50_30_45: double, SUM_logins_30_45: int, AVG_logins_30_45: double, SUM_repeats_30_45: int, AVG_repeats_30_45: double, STD_repeats_30_45: double, SUM_unq_songs_45_60: int, AVG_unq_songs_45_60: double, STD_unq_songs_45_60: double, SUM_songs_45_60: int, AVG_songs_45_60: double, STD_songs_45_60: double, SUM_secs_45_60: double, AVG_secs_45_60: double, STD_secs_45_60: double, SUM_songs50_45_60: int, AVG_songs50_45_60: double, STD_songs50_45_60: double, SUM_logins_45_60: int, AVG_logins_45_60: double, SUM_repeats_45_60: int, AVG_repeats_45_60: double, STD_repeats_45_60: double, DIFSUM_unq_songs_0_15_15_30: int, DIFAVG_unq_songs_0_15_15_30: double, DIFSTD_unq_songs_0_15_15_30: double, DIFSUM_songs_0_15_15_30: int, DIFAVG_songs_0_15_15_30: double, DIFSTD_songs_0_15_15_30: double, DIFSUM_secs_0_15_15_30: double, DIFAVG_secs_0_15_15_30: double, DIFSTD_secs_0_15_15_30: double, DIFSUM_songs50_0_15_15_30: int, DIFAVG_songs50_0_15_15_30: double, DIFSTD_songs50_0_15_15_30: double, DIFSUM_logins_0_15_15_30: int, DIFAVG_logins_0_15_15_30: double, DIFSUM_repeats_0_15_15_30: int, DIFAVG_repeats_0_15_15_30: double, DIFSTD_repeats_0_15_15_30: double, DIFSUM_unq_songs_15_30_30_45: int, DIFAVG_unq_songs_15_30_30_45: double, DIFSTD_unq_songs_15_30_30_45: double, DIFSUM_songs_15_30_30_45: int, DIFAVG_songs_15_30_30_45: double, DIFSTD_songs_15_30_30_45: double, DIFSUM_secs_15_30_30_45: double, DIFAVG_secs_15_30_30_45: double, DIFSTD_secs_15_30_30_45: double, DIFSUM_songs50_15_30_30_45: int, DIFAVG_songs50_15_30_30_45: double, DIFSTD_songs50_15_30_30_45: double, DIFSUM_logins_15_30_30_45: int, DIFAVG_logins_15_30_30_45: double, DIFSUM_repeats_15_30_30_45: int, DIFAVG_repeats_15_30_30_45: double, DIFSTD_repeats_15_30_30_45: double, DIFSUM_unq_songs_30_45_45_60: int, DIFAVG_unq_songs_30_45_45_60: double, DIFSTD_unq_songs_30_45_45_60: double, DIFSUM_songs_30_45_45_60: int, DIFAVG_songs_30_45_45_60: double, DIFSTD_songs_30_45_45_60: double, DIFSUM_secs_30_45_45_60: double, DIFAVG_secs_30_45_45_60: double, DIFSTD_secs_30_45_45_60: double, DIFSUM_songs50_30_45_45_60: int, DIFAVG_songs50_30_45_45_60: double, DIFSTD_songs50_30_45_45_60: double, DIFSUM_logins_30_45_45_60: int, DIFAVG_logins_30_45_45_60: double, DIFSUM_repeats_30_45_45_60: int, DIFAVG_repeats_30_45_45_60: double, DIFSTD_repeats_30_45_45_60: double]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # If Working Locally on Computer, Importing Data Locally#\n",
    "\n",
    "# # Import DRV_Jan2016 (Train Set) \n",
    "# DRV_Jan2016_1to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_1to1',inferSchema=True,header=True)\n",
    "# DRV_Jan2016_3to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_3to1',inferSchema=True,header=True)\n",
    "# DRV_Jan2016_5to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_5to1',inferSchema=True,header=True)\n",
    "# DRV_Jan2016_7to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_7to1',inferSchema=True,header=True)\n",
    "# DRV_Jan2016_9to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_9to1',inferSchema=True,header=True)\n",
    "# DRV_Jan2016_11to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_11to1',inferSchema=True,header=True)\n",
    "# DRV_Jan2016_13to1 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_13to1',inferSchema=True,header=True)\n",
    "\n",
    "# DRV_Jan20160 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016000000000000',inferSchema=True,header=True)\n",
    "# DRV_Jan20161 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016000000000001',inferSchema=True,header=True)\n",
    "# DRV_Jan20162 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016000000000002',inferSchema=True,header=True)\n",
    "\n",
    "# DRV_Jan2016 = DRV_Jan20160.union(DRV_Jan20161)\n",
    "# DRV_Jan2016 = DRV_Jan2016.union(DRV_Jan20162)\n",
    "\n",
    "# DRV_Jan20160.unpersist()\n",
    "# DRV_Jan20161.unpersist()\n",
    "# DRV_Jan20162.unpersist()\n",
    "\n",
    "# # Import DRV_Feb2016 (Validation Set) \n",
    "# DRV_Feb20160 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Feb2016000000000000',inferSchema=True,header=True)\n",
    "# DRV_Feb20161 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Feb2016000000000001',inferSchema=True,header=True)\n",
    "# DRV_Feb20162 = spark.read.csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Feb2016000000000002',inferSchema=True,header=True)\n",
    "\n",
    "# DRV_Feb2016 = DRV_Feb20160.union(DRV_Feb20161)\n",
    "# DRV_Feb2016 = DRV_Feb2016.union(DRV_Feb20162)\n",
    "\n",
    "# DRV_Feb20160.unpersist()\n",
    "# DRV_Feb20161.unpersist()\n",
    "# DRV_Feb20162.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Working on Dataproc Cloud ##\n",
    "\n",
    "# Import DRV_Jan2016 (Train Set) \n",
    "DRV_Jan2016_1to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_1to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_3to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_3to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_5to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_5to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_7to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_7to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_9to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_9to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_11to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_11to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_13to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_13to1',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Jan20160 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000000',inferSchema=True,header=True)\n",
    "DRV_Jan20161 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000001',inferSchema=True,header=True)\n",
    "DRV_Jan20162 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000002',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Jan2016 = DRV_Jan20160.union(DRV_Jan20161)\n",
    "DRV_Jan2016 = DRV_Jan2016.union(DRV_Jan20162)\n",
    "\n",
    "DRV_Jan20160 = None\n",
    "DRV_Jan20161 = None\n",
    "DRV_Jan20162 = None\n",
    "\n",
    "# Import DRV_Feb2016 (Validation Set) \n",
    "DRV_Feb20160 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000000',inferSchema=True,header=True)\n",
    "DRV_Feb20161 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000001',inferSchema=True,header=True)\n",
    "DRV_Feb20162 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000002',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Feb2016 = DRV_Feb20160.union(DRV_Feb20161)\n",
    "DRV_Feb2016 = DRV_Feb2016.union(DRV_Feb20162)\n",
    "\n",
    "DRV_Feb20160 = None\n",
    "DRV_Feb20161 = None\n",
    "DRV_Feb20162 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cast Correct Column Types on All Sets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "column_types_pd = [('msno', 'STRING'),\n",
    " ('membership_expire_date', 'DATE'),\n",
    " ('payment_method_id', 'INT64'),\n",
    " ('payment_plan_days', 'INT64'),\n",
    " ('plan_list_price', 'INT64'),\n",
    " ('net_paid_amount', 'INT64'),\n",
    " ('is_net_paid_amount', 'STRING'),\n",
    " ('is_auto_renew', 'INT64'),\n",
    " ('city', 'INT64'),\n",
    " ('bd', 'INT64'),\n",
    " ('registered_via', 'INT64'),\n",
    " ('registration_init_time', 'DATE'),\n",
    " ('membership_length', 'INT64'),\n",
    " ('is_churn', 'FLOAT64'),\n",
    " ('total_songs', 'INT64'),\n",
    " ('total_logins', 'INT64'),\n",
    " ('total_secs', 'FLOAT64'),\n",
    " ('sum_num_unq', 'INT64'),\n",
    " ('sum_num_repeat', 'INT64'),\n",
    " ('sum_over_50pec', 'INT64'),\n",
    " ('sum_over_75pec', 'INT64'),\n",
    " ('sum_over_985pec', 'INT64'),\n",
    " ('total_transactions', 'INT64'),\n",
    " ('total_spent', 'FLOAT64'),\n",
    " ('avg_spent_trans', 'FLOAT64'),\n",
    " ('spent_per_logins', 'FLOAT64'),\n",
    " ('spent_per_secs', 'FLOAT64'),\n",
    " ('spent_per_song', 'FLOAT64'),\n",
    " ('spent_per_num_unq', 'FLOAT64'),\n",
    " ('spent_per_num_repeats', 'FLOAT64'),\n",
    " ('never_active_subscriber', 'FLOAT64'),\n",
    " ('total_spent_zero', 'FLOAT64'),\n",
    " ('city_agg', 'INT64'),\n",
    " ('payment_method_agg', 'INT64'),\n",
    " ('songs_last_7', 'FLOAT64'),\n",
    " ('songs_last_7_AVG', 'FLOAT64'),\n",
    " ('logins_last_7', 'FLOAT64'),\n",
    " ('logins_last_7_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_7', 'FLOAT64'),\n",
    " ('total_secs_last_7_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_7', 'FLOAT64'),\n",
    " ('num_unq_last_7_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_7', 'FLOAT64'),\n",
    " ('num_repeat_last_7_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_7', 'FLOAT64'),\n",
    " ('over_50perc_last_7_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_7', 'FLOAT64'),\n",
    " ('over_75perc_last_7_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_7', 'FLOAT64'),\n",
    " ('over_985perc_last_7_AVG', 'FLOAT64'),\n",
    " ('songs_last_15', 'FLOAT64'),\n",
    " ('songs_last_15_AVG', 'FLOAT64'),\n",
    " ('logins_last_15', 'FLOAT64'),\n",
    " ('logins_last_15_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_15', 'FLOAT64'),\n",
    " ('total_secs_last_15_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_15', 'FLOAT64'),\n",
    " ('num_unq_last_15_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_15', 'FLOAT64'),\n",
    " ('num_repeat_last_15_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_15', 'FLOAT64'),\n",
    " ('over_50perc_last_15_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_15', 'FLOAT64'),\n",
    " ('over_75perc_last_15_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_15', 'FLOAT64'),\n",
    " ('over_985perc_last_15_AVG', 'FLOAT64'),\n",
    " ('songs_last_30', 'FLOAT64'),\n",
    " ('songs_last_30_AVG', 'FLOAT64'),\n",
    " ('logins_last_30', 'FLOAT64'),\n",
    " ('logins_last_30_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_30', 'FLOAT64'),\n",
    " ('total_secs_last_30_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_30', 'FLOAT64'),\n",
    " ('num_unq_last_30_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_30', 'FLOAT64'),\n",
    " ('num_repeat_last_30_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_30', 'FLOAT64'),\n",
    " ('over_50perc_last_30_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_30', 'FLOAT64'),\n",
    " ('over_75perc_last_30_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_30', 'FLOAT64'),\n",
    " ('over_985perc_last_30_AVG', 'FLOAT64'),\n",
    " ('songs_last_60', 'FLOAT64'),\n",
    " ('songs_last_60_AVG', 'FLOAT64'),\n",
    " ('logins_last_60', 'FLOAT64'),\n",
    " ('logins_last_60_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_60', 'FLOAT64'),\n",
    " ('total_secs_last_60_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_60', 'FLOAT64'),\n",
    " ('num_unq_last_60_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_60', 'FLOAT64'),\n",
    " ('num_repeat_last_60_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_60', 'FLOAT64'),\n",
    " ('over_50perc_last_60_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_60', 'FLOAT64'),\n",
    " ('over_75perc_last_60_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_60', 'FLOAT64'),\n",
    " ('over_985perc_last_60_AVG', 'FLOAT64'),\n",
    " ('songs_last_120', 'FLOAT64'),\n",
    " ('songs_last_120_AVG', 'FLOAT64'),\n",
    " ('logins_last_120', 'FLOAT64'),\n",
    " ('logins_last_120_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_120', 'FLOAT64'),\n",
    " ('total_secs_last_120_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_120', 'FLOAT64'),\n",
    " ('num_unq_last_120_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_120', 'FLOAT64'),\n",
    " ('num_repeat_last_120_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_120', 'FLOAT64'),\n",
    " ('over_50perc_last_120_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_120', 'FLOAT64'),\n",
    " ('over_75perc_last_120_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_120', 'FLOAT64'),\n",
    " ('over_985perc_last_120_AVG', 'FLOAT64'),\n",
    " ('SUM_unq_songs_0_15', 'FLOAT64'),\n",
    " ('AVG_unq_songs_0_15', 'FLOAT64'),\n",
    " ('SUM_songs_0_15', 'FLOAT64'),\n",
    " ('AVG_songs_0_15', 'FLOAT64'),\n",
    " ('SUM_secs_0_15', 'FLOAT64'),\n",
    " ('AVG_secs_0_15', 'FLOAT64'),\n",
    " ('SUM_songs50_0_15', 'FLOAT64'),\n",
    " ('AVG_songs50_0_15', 'FLOAT64'),\n",
    " ('SUM_logins_0_15', 'FLOAT64'),\n",
    " ('AVG_logins_0_15', 'FLOAT64'),\n",
    " ('SUM_repeats_0_15', 'FLOAT64'),\n",
    " ('AVG_repeats_0_15', 'FLOAT64'),\n",
    " ('SUM_unq_songs_15_30', 'FLOAT64'),\n",
    " ('AVG_unq_songs_15_30', 'FLOAT64'),\n",
    " ('SUM_songs_15_30', 'FLOAT64'),\n",
    " ('AVG_songs_15_30', 'FLOAT64'),\n",
    " ('SUM_secs_15_30', 'FLOAT64'),\n",
    " ('AVG_secs_15_30', 'FLOAT64'),\n",
    " ('SUM_songs50_15_30', 'FLOAT64'),\n",
    " ('AVG_songs50_15_30', 'FLOAT64'),\n",
    " ('SUM_logins_15_30', 'FLOAT64'),\n",
    " ('AVG_logins_15_30', 'FLOAT64'),\n",
    " ('SUM_repeats_15_30', 'FLOAT64'),\n",
    " ('AVG_repeats_15_30', 'FLOAT64'),\n",
    " ('SUM_unq_songs_30_45', 'FLOAT64'),\n",
    " ('AVG_unq_songs_30_45', 'FLOAT64'),\n",
    " ('SUM_songs_30_45', 'FLOAT64'),\n",
    " ('AVG_songs_30_45', 'FLOAT64'),\n",
    " ('SUM_secs_30_45', 'FLOAT64'),\n",
    " ('AVG_secs_30_45', 'FLOAT64'),\n",
    " ('SUM_songs50_30_45', 'FLOAT64'),\n",
    " ('AVG_songs50_30_45', 'FLOAT64'),\n",
    " ('SUM_logins_30_45', 'FLOAT64'),\n",
    " ('AVG_logins_30_45', 'FLOAT64'),\n",
    " ('SUM_repeats_30_45', 'FLOAT64'),\n",
    " ('AVG_repeats_30_45', 'FLOAT64'),\n",
    " ('SUM_unq_songs_45_60', 'FLOAT64'),\n",
    " ('AVG_unq_songs_45_60', 'FLOAT64'),\n",
    " ('SUM_songs_45_60', 'FLOAT64'),\n",
    " ('AVG_songs_45_60', 'FLOAT64'),\n",
    " ('SUM_secs_45_60', 'FLOAT64'),\n",
    " ('AVG_secs_45_60', 'FLOAT64'),\n",
    " ('SUM_songs50_45_60', 'FLOAT64'),\n",
    " ('AVG_songs50_45_60', 'FLOAT64'),\n",
    " ('SUM_logins_45_60', 'FLOAT64'),\n",
    " ('AVG_logins_45_60', 'FLOAT64'),\n",
    " ('SUM_repeats_45_60', 'FLOAT64'),\n",
    " ('AVG_repeats_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_unq_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_unq_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_secs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_secs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_songs50_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_songs50_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_logins_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_logins_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_repeats_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_repeats_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_unq_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_unq_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_secs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_secs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_songs50_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_songs50_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_logins_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_logins_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_repeats_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_repeats_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_unq_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_unq_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_secs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_secs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_songs50_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_songs50_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_logins_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_logins_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_repeats_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_repeats_30_45_45_60', 'FLOAT64'),\n",
    " ('expire_last_login', 'INT64'),\n",
    " ('total_cancelations', 'INT64'),\n",
    " ('login_after_expire_10', 'INT64'),\n",
    " ('login_after_expire_20', 'INT64'),\n",
    " ('login_after_expire_30', 'INT64'),\n",
    " ('STD_unq_songs_0_15', 'FLOAT64'),\n",
    " ('STD_songs_0_15', 'FLOAT64'),\n",
    " ('STD_secs_0_15', 'FLOAT64'),\n",
    " ('STD_songs50_0_15', 'FLOAT64'),\n",
    " ('STD_repeats_0_15', 'FLOAT64'),\n",
    " ('STD_unq_songs_15_30', 'FLOAT64'),\n",
    " ('STD_songs_15_30', 'FLOAT64'),\n",
    " ('STD_secs_15_30', 'FLOAT64'),\n",
    " ('STD_songs50_15_30', 'FLOAT64'),\n",
    " ('STD_repeats_15_30', 'FLOAT64'),\n",
    " ('STD_unq_songs_30_45', 'FLOAT64'),\n",
    " ('STD_songs_30_45', 'FLOAT64'),\n",
    " ('STD_secs_30_45', 'FLOAT64'),\n",
    " ('STD_songs50_30_45', 'FLOAT64'),\n",
    " ('STD_repeats_30_45', 'FLOAT64'),\n",
    " ('STD_unq_songs_45_60', 'FLOAT64'),\n",
    " ('STD_songs_45_60', 'FLOAT64'),\n",
    " ('STD_secs_45_60', 'FLOAT64'),\n",
    " ('STD_songs50_45_60', 'FLOAT64'),\n",
    " ('STD_repeats_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_unq_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_secs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_songs50_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_repeats_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_unq_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_secs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_songs50_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_repeats_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_unq_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_secs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_songs50_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_repeats_30_45_45_60', 'FLOAT64'),\n",
    " ('is_cancel', 'INT64')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Correctly Cast DRV_Feb2016\n",
    "for feature, datatype in column_types_pd:\n",
    "    if datatype == 'STRING':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS string)\"))')\n",
    "    if datatype == 'DATE':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS timestamp)\"))')\n",
    "    if datatype == 'INT64':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS integer)\"))')\n",
    "    if datatype == 'FLOAT64':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS double)\"))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pre-Processing\n",
    "https://medium.com/@dhiraj.p.rai/essentials-of-feature-engineering-in-pyspark-part-i-76a57680a85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Split Feautres by Categorical or Continuous</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Categorical feature names\n",
    "cat_feats = ['is_auto_renew', 'total_spent_zero', 'city_agg', 'payment_method_agg', 'never_active_subscriber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Continuous feature names\n",
    "cont_feats = [x for x in DRV_Jan2016_1to1.columns if x not in cat_feats]\n",
    "cont_feats.remove('msno')\n",
    "cont_feats.remove('is_churn')\n",
    "cont_feats.remove('membership_expire_date')\n",
    "cont_feats.remove('registration_init_time')\n",
    "cont_feats.remove('city')\n",
    "cont_feats.remove('bd')\n",
    "cont_feats.remove('payment_method_id')\n",
    "cont_feats.remove('is_net_paid_amount')\n",
    "cont_feats.remove('registered_via')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Data Pre-Processing</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Encode Categorical Variables*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical, 'Vector' feature names\n",
    "cat_feats_vec = ['is_auto_renew_vec', 'total_spent_zero_vec', 'city_agg_vec', 'payment_method_agg_vec', 'never_active_subscriber_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "\n",
    "is_auto_renew_encoder = OneHotEncoder(inputCol='is_auto_renew',outputCol='is_auto_renew_vec')\n",
    "total_spent_zero_encoder = OneHotEncoder(inputCol='total_spent_zero',outputCol='total_spent_zero_vec')\n",
    "city_agg_encoder = OneHotEncoder(inputCol='city_agg',outputCol='city_agg_vec')\n",
    "payment_method_agg_encoder = OneHotEncoder(inputCol='payment_method_agg',outputCol='payment_method_agg_vec')\n",
    "never_active_subscriber_encoder = OneHotEncoder(inputCol='never_active_subscriber',outputCol='never_active_subscriber_vec')\n",
    "# is_net_paid_amount_encoder = OneHotEncoder(inputCol='is_net_paid_amount',outputCol='is_net_paid_amount_vec')\n",
    "\n",
    "# registered_via_encoder = OneHotEncoder(inputCol='registered_via',outputCol='registered_via_vec')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Vector Assembler*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = cont_feats + cat_feats_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Feature Scaling*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all features into our final output features\n",
    "scaler = StandardScaler(inputCol='features', \n",
    "                        outputCol='features_scaled',\n",
    "                        withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation: Pipeline and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Create Pipeline Object</font> -\n",
    "https://spark.apache.org/docs/2.4.3/ml-pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate Model Estimators and Parameters\n",
    "gbt = GBTClassifier(featuresCol='features_scaled',\n",
    "                    labelCol='is_churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Model Tuning</font> -\n",
    "https://spark.apache.org/docs/2.4.3/ml-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_evaluator = BinaryClassificationEvaluator(labelCol='is_churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Gradient Boosted Trees Parameter Tuning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Execution and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: All Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 303\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to1 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 357\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to1 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 420\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to1 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 506\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to1 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 636\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to1 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 894\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to1 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1082\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to1 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Evaluate Trained Model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create Custom Evaluator***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator that we can use instead of BinaryClassificationEvaluator() in grid search\n",
    "class ClassEvaluator:\n",
    "\n",
    "    def __init__(self, resultname, resultdata, model):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Initialize variables\n",
    "        self.resultPandas = resultdata[['is_churn', 'prediction']].toPandas()\n",
    "        self.resultdata = resultdata \n",
    "        self.resultname = resultname\n",
    "        self.model = model\n",
    "        \n",
    "        self.cm = confusion_matrix(self.resultPandas['is_churn'],self.resultPandas['prediction'])\n",
    "        \n",
    "        # Calculate confusion matrix values\n",
    "        self.tp = self.cm[0][0]\n",
    "        self.fn = self.cm[0][1]\n",
    "        self.tn = self.cm[1][1]\n",
    "        self.fp = self.cm[1][0]\n",
    "        \n",
    "    def evaluate(self):\n",
    "        # Calculate Metrics and add epsilon to prevent division by zero\n",
    "        precision = self.tp / float(self.tp + self.fp + 0.00001)\n",
    "        recall = self.tp / float(self.tp + self.fn + 0.00001)\n",
    "        f1 = (2 * precision * recall) / float(precision + recall + 0.00001)\n",
    "        error = (self.fp + self.fn + 0.00001) / (self.tp + self.fp + self.tn + self.fn + 0.00001)\n",
    "        \n",
    "        # Instantiate Evaluator and call AUC metric\n",
    "        my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                                labelCol='is_churn')\n",
    "        AUC = my_eval.evaluate(self.resultdata)\n",
    "        \n",
    "        \n",
    "        return pd.DataFrame(data=[[self.resultname, AUC, f1, precision, recall, error]], \n",
    "                            columns=['resultname', 'AUC', 'f1', 'precision', 'recall', 'error'])\n",
    "    \n",
    "    def confusionmatrix(self):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Print Confusion Matrix\n",
    "        return self.cm\n",
    "        \n",
    "    \n",
    "    def modelparams(self):\n",
    "        scores = self.model.avgMetrics\n",
    "        params = [{p.name: v for p, v in m.items()} for m in self.model.getEstimatorParamMaps()]\n",
    "        params_pd = pd.DataFrame(params)\n",
    "        params_pd['AUC score'] = scores\n",
    "        return params_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: All Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transform Train Data on Trained Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created = {\n",
    "                  'gbt_model_1to1' : (gbt_model_1to1, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to1' : (gbt_model_3to1, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to1' : (gbt_model_5to1, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to1' : (gbt_model_7to1, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to1' : (gbt_model_9to1, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to1' : (gbt_model_11to1, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to1' : (gbt_model_13to1, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_13to1\n",
      "[[664719   8032]\n",
      " [  9165   9983]]\n",
      " \n",
      "gbt_model_11to1\n",
      "[[662295  10456]\n",
      " [  8295  10853]]\n",
      " \n",
      "gbt_model_1to1\n",
      "[[588901  83850]\n",
      " [  1946  17202]]\n",
      " \n",
      "gbt_model_5to1\n",
      "[[648674  24077]\n",
      " [  5662  13486]]\n",
      " \n",
      "gbt_model_9to1\n",
      "[[659427  13324]\n",
      " [  7553  11595]]\n",
      " \n",
      "gbt_model_3to1\n",
      "[[634113  38638]\n",
      " [  4040  15108]]\n",
      " \n",
      "gbt_model_7to1\n",
      "[[655981  16770]\n",
      " [  6932  12216]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_resultsall = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_resultsall = train_resultsall.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1</td>\n",
       "      <td>0.886867</td>\n",
       "      <td>0.932097</td>\n",
       "      <td>0.875363</td>\n",
       "      <td>0.996706</td>\n",
       "      <td>0.124001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1</td>\n",
       "      <td>0.865790</td>\n",
       "      <td>0.967439</td>\n",
       "      <td>0.942567</td>\n",
       "      <td>0.993669</td>\n",
       "      <td>0.061682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1</td>\n",
       "      <td>0.834257</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.964211</td>\n",
       "      <td>0.991347</td>\n",
       "      <td>0.042982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1</td>\n",
       "      <td>0.806525</td>\n",
       "      <td>0.982250</td>\n",
       "      <td>0.975073</td>\n",
       "      <td>0.989543</td>\n",
       "      <td>0.034256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1</td>\n",
       "      <td>0.792871</td>\n",
       "      <td>0.984412</td>\n",
       "      <td>0.980195</td>\n",
       "      <td>0.988676</td>\n",
       "      <td>0.030173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1</td>\n",
       "      <td>0.775627</td>\n",
       "      <td>0.986037</td>\n",
       "      <td>0.984458</td>\n",
       "      <td>0.987630</td>\n",
       "      <td>0.027101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1</td>\n",
       "      <td>0.754710</td>\n",
       "      <td>0.987225</td>\n",
       "      <td>0.988061</td>\n",
       "      <td>0.986400</td>\n",
       "      <td>0.024855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to1  0.886867  0.932097   0.875363  0.996706  0.124001\n",
       "0   gbt_model_3to1  0.865790  0.967439   0.942567  0.993669  0.061682\n",
       "0   gbt_model_5to1  0.834257  0.977586   0.964211  0.991347  0.042982\n",
       "0   gbt_model_7to1  0.806525  0.982250   0.975073  0.989543  0.034256\n",
       "0   gbt_model_9to1  0.792871  0.984412   0.980195  0.988676  0.030173\n",
       "0  gbt_model_11to1  0.775627  0.986037   0.984458  0.987630  0.027101\n",
       "0  gbt_model_13to1  0.754710  0.987225   0.988061  0.986400  0.024855"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_resultsall.sort_values('AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: All Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_13to1\n",
      "[[520605   7599]\n",
      " [ 11662   8261]]\n",
      " \n",
      "gbt_model_11to1\n",
      "[[518491   9713]\n",
      " [ 10807   9116]]\n",
      " \n",
      "gbt_model_1to1\n",
      "[[451574  76630]\n",
      " [  2645  17278]]\n",
      " \n",
      "gbt_model_5to1\n",
      "[[507052  21152]\n",
      " [  7455  12468]]\n",
      " \n",
      "gbt_model_9to1\n",
      "[[516148  12056]\n",
      " [  9905  10018]]\n",
      " \n",
      "gbt_model_3to1\n",
      "[[492518  35686]\n",
      " [  5431  14492]]\n",
      " \n",
      "gbt_model_7to1\n",
      "[[512813  15391]\n",
      " [  9089  10834]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_resultsall = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_resultsall = validation_resultsall.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1</td>\n",
       "      <td>0.861081</td>\n",
       "      <td>0.919302</td>\n",
       "      <td>0.854923</td>\n",
       "      <td>0.994177</td>\n",
       "      <td>0.144629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1</td>\n",
       "      <td>0.829920</td>\n",
       "      <td>0.959926</td>\n",
       "      <td>0.932439</td>\n",
       "      <td>0.989093</td>\n",
       "      <td>0.075014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1</td>\n",
       "      <td>0.792882</td>\n",
       "      <td>0.972560</td>\n",
       "      <td>0.959955</td>\n",
       "      <td>0.985510</td>\n",
       "      <td>0.052190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1</td>\n",
       "      <td>0.757328</td>\n",
       "      <td>0.976683</td>\n",
       "      <td>0.970862</td>\n",
       "      <td>0.982585</td>\n",
       "      <td>0.044661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1</td>\n",
       "      <td>0.740006</td>\n",
       "      <td>0.979164</td>\n",
       "      <td>0.977175</td>\n",
       "      <td>0.981171</td>\n",
       "      <td>0.040066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1</td>\n",
       "      <td>0.719586</td>\n",
       "      <td>0.980591</td>\n",
       "      <td>0.981611</td>\n",
       "      <td>0.979582</td>\n",
       "      <td>0.037437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1</td>\n",
       "      <td>0.700130</td>\n",
       "      <td>0.981832</td>\n",
       "      <td>0.985614</td>\n",
       "      <td>0.978090</td>\n",
       "      <td>0.035140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to1  0.861081  0.919302   0.854923  0.994177  0.144629\n",
       "0   gbt_model_3to1  0.829920  0.959926   0.932439  0.989093  0.075014\n",
       "0   gbt_model_5to1  0.792882  0.972560   0.959955  0.985510  0.052190\n",
       "0   gbt_model_7to1  0.757328  0.976683   0.970862  0.982585  0.044661\n",
       "0   gbt_model_9to1  0.740006  0.979164   0.977175  0.981171  0.040066\n",
       "0  gbt_model_11to1  0.719586  0.980591   0.981611  0.979582  0.037437\n",
       "0  gbt_model_13to1  0.700130  0.981832   0.985614  0.978090  0.035140"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_resultsall.sort_values('AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now currently have ~230 Features with the inclusion of our *Bi-Weekly Activity Block* and *Comparison of Bi-Weekly Activity Block Features*. Looking at the results above we can see that we have made some improvements on AUC. We also notice how Recall increased significantly over the Ratio'd subsets. The ratio'd subsets seemed to have helped address the issue of having a high amount of False Positives.\n",
    "\n",
    "We can see that our models are still overfitting with the higher ratio'd models being the worst. However our Precision scores are better over our higher ratio'd models along with an improvement in model error and a slight decrease in Recall. Each of these models have there pros and cons and we might benefit from some sort of ensemble of these models. Before we do such a thing let's play around a bit with feature selection to see if we improve on the overall generalization between our Train and Validation models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Feature Importance</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will derive average feature importance scores for all features. Then we will produce a 5 Number Summary on these scores and group our features based on their scores against the following thresholds: Mean, 75th Percentile, 50th Percentile, and 25th Percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "importances = gbt_model_1to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column1 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_3to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column3 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_5to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column5 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_7to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column7 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_9to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column9 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_11to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column11 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_13to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column13 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.merge(column1, column3 , on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column5, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column7, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column9, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column11, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column13, on='Features')\n",
    "\n",
    "feature_imp['avg'] = feature_imp[list(feature_imp.columns[1:-1])].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    230.000000\n",
       "mean       0.004142\n",
       "std        0.017953\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000357\n",
       "75%        0.001211\n",
       "max        0.167032\n",
       "Name: avg, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 5-Number Sumamry\n",
    "feature_imp['avg'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>login_after_expire_30</td>\n",
       "      <td>0.130559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>total_transactions</td>\n",
       "      <td>0.131067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>is_auto_renew_vec</td>\n",
       "      <td>0.167032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>login_after_expire_20</td>\n",
       "      <td>0.020181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>is_cancel</td>\n",
       "      <td>0.039873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>plan_list_price</td>\n",
       "      <td>0.073427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>avg_spent_trans</td>\n",
       "      <td>0.035378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>expire_last_login</td>\n",
       "      <td>0.039178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>total_spent</td>\n",
       "      <td>0.045327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>net_paid_amount</td>\n",
       "      <td>0.035028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>membership_length</td>\n",
       "      <td>0.034247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>spent_per_logins</td>\n",
       "      <td>0.020374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>total_spent_zero_vec</td>\n",
       "      <td>0.004367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>logins_last_60</td>\n",
       "      <td>0.004768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>SUM_logins_30_45</td>\n",
       "      <td>0.007124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>payment_method_agg_vec</td>\n",
       "      <td>0.008423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>payment_plan_days</td>\n",
       "      <td>0.006718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>logins_last_120</td>\n",
       "      <td>0.004970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>SUM_songs50_0_15</td>\n",
       "      <td>0.006731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>spent_per_secs</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>DIFSUM_logins_15_30_30_45</td>\n",
       "      <td>0.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>SUM_logins_45_60</td>\n",
       "      <td>0.001842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>spent_per_num_unq</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>sum_over_50pec</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>songs_last_60</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>total_logins</td>\n",
       "      <td>0.005262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>over_50perc_last_7</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>DIFSUM_secs_0_15_15_30</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>num_repeat_last_120</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>SUM_songs50_30_45</td>\n",
       "      <td>0.002277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Features       avg\n",
       "0       login_after_expire_30  0.130559\n",
       "1          total_transactions  0.131067\n",
       "2           is_auto_renew_vec  0.167032\n",
       "3       login_after_expire_20  0.020181\n",
       "4                   is_cancel  0.039873\n",
       "5             plan_list_price  0.073427\n",
       "6             avg_spent_trans  0.035378\n",
       "7           expire_last_login  0.039178\n",
       "8                 total_spent  0.045327\n",
       "9             net_paid_amount  0.035028\n",
       "10          membership_length  0.034247\n",
       "11           spent_per_logins  0.020374\n",
       "12       total_spent_zero_vec  0.004367\n",
       "13             logins_last_60  0.004768\n",
       "14           SUM_logins_30_45  0.007124\n",
       "15     payment_method_agg_vec  0.008423\n",
       "16          payment_plan_days  0.006718\n",
       "17            logins_last_120  0.004970\n",
       "18           SUM_songs50_0_15  0.006731\n",
       "19             spent_per_secs  0.002468\n",
       "20  DIFSUM_logins_15_30_30_45  0.003375\n",
       "21           SUM_logins_45_60  0.001842\n",
       "22          spent_per_num_unq  0.001552\n",
       "23             sum_over_50pec  0.001031\n",
       "24              songs_last_60  0.001827\n",
       "25               total_logins  0.005262\n",
       "26         over_50perc_last_7  0.001230\n",
       "27     DIFSUM_secs_0_15_15_30  0.001463\n",
       "28        num_repeat_last_120  0.001519\n",
       "29          SUM_songs50_30_45  0.002277"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp[['Features','avg']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feats = feature_imp[feature_imp['avg'] > .004158]['Features'].tolist()\n",
    "quart25_feats = feature_imp[feature_imp['avg'] > .000215]['Features'].tolist()\n",
    "quart50_feats = feature_imp[feature_imp['avg'] > .000455]['Features'].tolist()\n",
    "quart75_feats = feature_imp[feature_imp['avg'] > .001476]['Features'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mean_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'is_cancel',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'membership_length',\n",
    " 'expire_last_login',\n",
    " 'total_spent',\n",
    " 'net_paid_amount',\n",
    " 'SUM_logins_30_45',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'payment_method_agg_vec',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'total_logins',\n",
    " 'SUM_songs50_0_15',\n",
    " 'payment_plan_days',\n",
    " 'num_unq_last_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quart25_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'is_cancel',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'membership_length',\n",
    " 'expire_last_login',\n",
    " 'total_spent',\n",
    " 'net_paid_amount',\n",
    " 'SUM_logins_30_45',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'payment_method_agg_vec',\n",
    " 'logins_last_120',\n",
    " 'SUM_logins_45_60',\n",
    " 'spent_per_song',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'songs_last_60',\n",
    " 'total_logins',\n",
    " 'SUM_secs_45_60',\n",
    " 'num_unq_last_7',\n",
    " 'STD_repeats_0_15',\n",
    " 'SUM_songs50_0_15',\n",
    " 'sum_over_50pec',\n",
    " 'SUM_songs50_30_45',\n",
    " 'SUM_songs_30_45',\n",
    " 'over_985perc_last_120',\n",
    " 'DIFAVG_unq_songs_0_15_15_30',\n",
    " 'spent_per_secs',\n",
    " 'over_50perc_last_7',\n",
    " 'sum_over_75pec',\n",
    " 'DIFSUM_songs_0_15_15_30',\n",
    " 'payment_plan_days',\n",
    " 'DIFSUM_logins_0_15_15_30',\n",
    " 'spent_per_num_unq',\n",
    " 'SUM_repeats_45_60',\n",
    " 'total_secs_last_7',\n",
    " 'STD_songs50_30_45',\n",
    " 'STD_songs_45_60',\n",
    " 'STD_repeats_30_45',\n",
    " 'DIFSUM_secs_0_15_15_30',\n",
    " 'total_secs_last_15',\n",
    " 'DIFSTD_unq_songs_0_15_15_30',\n",
    " 'spent_per_num_repeats',\n",
    " 'STD_repeats_15_30',\n",
    " 'STD_songs_15_30',\n",
    " 'STD_secs_0_15',\n",
    " 'num_unq_last_15',\n",
    " 'SUM_repeats_15_30',\n",
    " 'SUM_songs50_15_30',\n",
    " 'DIFSUM_repeats_30_45_45_60',\n",
    " 'over_75perc_last_120',\n",
    " 'total_secs_last_120',\n",
    " 'DIFSTD_repeats_15_30_30_45',\n",
    " 'sum_num_unq',\n",
    " 'num_repeat_last_7',\n",
    " 'num_repeat_last_120',\n",
    " 'STD_unq_songs_15_30',\n",
    " 'DIFSUM_songs50_0_15_15_30',\n",
    " 'STD_songs_0_15',\n",
    " 'DIFAVG_unq_songs_15_30_30_45',\n",
    " 'songs_last_15',\n",
    " 'logins_last_30',\n",
    " 'STD_secs_15_30',\n",
    " 'songs_last_7',\n",
    " 'SUM_unq_songs_15_30',\n",
    " 'DIFSUM_unq_songs_15_30_30_45',\n",
    " 'DIFAVG_logins_30_45_45_60',\n",
    " 'DIFSTD_songs50_15_30_30_45',\n",
    " 'DIFSUM_unq_songs_0_15_15_30',\n",
    " 'sum_num_repeat',\n",
    " 'num_unq_last_60',\n",
    " 'total_secs',\n",
    " 'DIFSTD_repeats_0_15_15_30',\n",
    " 'logins_last_15',\n",
    " 'DIFAVG_unq_songs_30_45_45_60',\n",
    " 'DIFSUM_secs_15_30_30_45',\n",
    " 'SUM_unq_songs_30_45',\n",
    " 'DIFAVG_logins_0_15_15_30',\n",
    " 'songs_last_30',\n",
    " 'STD_unq_songs_0_15',\n",
    " 'total_songs',\n",
    " 'DIFSTD_songs50_0_15_15_30',\n",
    " 'DIFSTD_songs_30_45_45_60',\n",
    " 'DIFSUM_secs_30_45_45_60',\n",
    " 'SUM_songs_45_60',\n",
    " 'STD_unq_songs_45_60',\n",
    " 'SUM_unq_songs_45_60',\n",
    " 'SUM_repeats_30_45',\n",
    " 'DIFSUM_logins_30_45_45_60',\n",
    " 'DIFAVG_repeats_30_45_45_60',\n",
    " 'DIFSTD_repeats_30_45_45_60',\n",
    " 'SUM_songs50_45_60',\n",
    " 'DIFSUM_repeats_0_15_15_30',\n",
    " 'DIFSTD_unq_songs_15_30_30_45',\n",
    " 'DIFAVG_songs_0_15_15_30',\n",
    " 'sum_over_985pec',\n",
    " 'DIFSTD_songs_15_30_30_45',\n",
    " 'STD_repeats_45_60',\n",
    " 'DIFAVG_songs50_15_30_30_45',\n",
    " 'DIFSUM_logins_15_30_30_45',\n",
    " 'DIFAVG_repeats_15_30_30_45',\n",
    " 'DIFSUM_unq_songs_30_45_45_60',\n",
    " 'STD_songs50_45_60',\n",
    " 'SUM_secs_30_45',\n",
    " 'over_75perc_last_30',\n",
    " 'over_985perc_last_30',\n",
    " 'over_75perc_last_7',\n",
    " 'total_secs_last_60',\n",
    " 'num_repeat_last_60',\n",
    " 'over_50perc_last_60',\n",
    " 'over_75perc_last_60',\n",
    " 'over_75perc_last_60_AVG',\n",
    " 'over_985perc_last_60',\n",
    " 'songs_last_120',\n",
    " 'num_repeat_last_15',\n",
    " 'over_985perc_last_15',\n",
    " 'total_secs_last_30',\n",
    " 'num_unq_last_30',\n",
    " 'SUM_songs_15_30',\n",
    " 'over_985perc_last_7',\n",
    " 'SUM_logins_15_30',\n",
    " 'STD_unq_songs_30_45',\n",
    " 'logins_last_7',\n",
    " 'STD_songs50_0_15',\n",
    " 'num_unq_last_120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quart50_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'is_cancel',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'membership_length',\n",
    " 'expire_last_login',\n",
    " 'total_spent',\n",
    " 'net_paid_amount',\n",
    " 'SUM_logins_30_45',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'payment_method_agg_vec',\n",
    " 'logins_last_120',\n",
    " 'SUM_logins_45_60',\n",
    " 'spent_per_song',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'songs_last_60',\n",
    " 'total_logins',\n",
    " 'SUM_secs_45_60',\n",
    " 'num_unq_last_7',\n",
    " 'STD_repeats_0_15',\n",
    " 'SUM_songs50_0_15',\n",
    " 'sum_over_50pec',\n",
    " 'SUM_songs50_30_45',\n",
    " 'SUM_songs_30_45',\n",
    " 'over_985perc_last_120',\n",
    " 'DIFAVG_unq_songs_0_15_15_30',\n",
    " 'spent_per_secs',\n",
    " 'over_50perc_last_7',\n",
    " 'sum_over_75pec',\n",
    " 'DIFSUM_songs_0_15_15_30',\n",
    " 'payment_plan_days',\n",
    " 'DIFSUM_logins_0_15_15_30',\n",
    " 'spent_per_num_unq',\n",
    " 'SUM_repeats_45_60',\n",
    " 'total_secs_last_7',\n",
    " 'STD_songs50_30_45',\n",
    " 'STD_repeats_30_45',\n",
    " 'DIFSUM_secs_0_15_15_30',\n",
    " 'total_secs_last_15',\n",
    " 'DIFSTD_unq_songs_0_15_15_30',\n",
    " 'spent_per_num_repeats',\n",
    " 'STD_repeats_15_30',\n",
    " 'STD_songs_15_30',\n",
    " 'num_unq_last_15',\n",
    " 'SUM_repeats_15_30',\n",
    " 'SUM_songs50_15_30',\n",
    " 'DIFSUM_repeats_30_45_45_60',\n",
    " 'over_75perc_last_120',\n",
    " 'total_secs_last_120',\n",
    " 'sum_num_unq',\n",
    " 'num_repeat_last_7',\n",
    " 'num_repeat_last_120',\n",
    " 'STD_unq_songs_15_30',\n",
    " 'STD_songs_0_15',\n",
    " 'songs_last_15',\n",
    " 'logins_last_30',\n",
    " 'songs_last_7',\n",
    " 'DIFSUM_unq_songs_15_30_30_45',\n",
    " 'DIFAVG_logins_30_45_45_60',\n",
    " 'DIFSTD_songs50_15_30_30_45',\n",
    " 'sum_num_repeat',\n",
    " 'num_unq_last_60',\n",
    " 'logins_last_15',\n",
    " 'DIFSUM_secs_15_30_30_45',\n",
    " 'SUM_unq_songs_30_45',\n",
    " 'DIFAVG_logins_0_15_15_30',\n",
    " 'songs_last_30',\n",
    " 'STD_unq_songs_0_15',\n",
    " 'total_songs',\n",
    " 'DIFSUM_secs_30_45_45_60',\n",
    " 'SUM_songs_45_60',\n",
    " 'STD_unq_songs_45_60',\n",
    " 'DIFSUM_logins_30_45_45_60',\n",
    " 'SUM_songs50_45_60',\n",
    " 'sum_over_985pec',\n",
    " 'DIFSUM_logins_15_30_30_45',\n",
    " 'STD_songs50_45_60',\n",
    " 'total_secs_last_60',\n",
    " 'over_50perc_last_60',\n",
    " 'over_75perc_last_60',\n",
    " 'over_75perc_last_60_AVG',\n",
    " 'over_985perc_last_60',\n",
    " 'songs_last_120',\n",
    " 'over_985perc_last_15',\n",
    " 'total_secs_last_30',\n",
    " 'num_unq_last_30',\n",
    " 'over_985perc_last_7',\n",
    " 'logins_last_7',\n",
    " 'STD_songs50_0_15',\n",
    " 'num_unq_last_120']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quart75_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'is_cancel',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'membership_length',\n",
    " 'expire_last_login',\n",
    " 'total_spent',\n",
    " 'net_paid_amount',\n",
    " 'SUM_logins_30_45',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'payment_method_agg_vec',\n",
    " 'logins_last_120',\n",
    " 'SUM_logins_45_60',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'songs_last_60',\n",
    " 'total_logins',\n",
    " 'num_unq_last_7',\n",
    " 'SUM_songs50_0_15',\n",
    " 'SUM_songs50_30_45',\n",
    " 'over_985perc_last_120',\n",
    " 'spent_per_secs',\n",
    " 'over_50perc_last_7',\n",
    " 'payment_plan_days',\n",
    " 'DIFSUM_logins_0_15_15_30',\n",
    " 'DIFSUM_secs_0_15_15_30',\n",
    " 'num_unq_last_15',\n",
    " 'total_secs_last_120',\n",
    " 'sum_num_unq',\n",
    " 'num_repeat_last_7',\n",
    " 'logins_last_30',\n",
    " 'DIFAVG_logins_30_45_45_60',\n",
    " 'sum_num_repeat',\n",
    " 'num_unq_last_60',\n",
    " 'logins_last_15',\n",
    " 'DIFAVG_logins_0_15_15_30',\n",
    " 'DIFSUM_logins_15_30_30_45',\n",
    " 'STD_songs50_45_60',\n",
    " 'total_secs_last_60',\n",
    " 'over_50perc_last_60',\n",
    " 'over_75perc_last_60',\n",
    " 'over_985perc_last_60',\n",
    " 'songs_last_120',\n",
    " 'total_secs_last_30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: Mean Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = mean_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 148.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to1mean = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 191.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to1mean = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 234.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to1mean = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 275.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to1mean = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 331.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to1mean = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to1mean = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to1mean = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_createdmean = {\n",
    "                  'gbt_model_1to1mean' : (gbt_model_1to1mean, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to1mean' : (gbt_model_3to1mean, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to1mean' : (gbt_model_5to1mean, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to1mean' : (gbt_model_7to1mean, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to1mean' : (gbt_model_9to1mean, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to1mean' : (gbt_model_11to1mean, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to1mean' : (gbt_model_13to1mean, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: Mean Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_11to1mean\n",
      "[[662201  10550]\n",
      " [  8337  10811]]\n",
      " \n",
      "gbt_model_7to1mean\n",
      "[[655106  17645]\n",
      " [  6870  12278]]\n",
      " \n",
      "gbt_model_13to1mean\n",
      "[[664998   7753]\n",
      " [  9255   9893]]\n",
      " \n",
      "gbt_model_9to1mean\n",
      "[[659104  13647]\n",
      " [  7541  11607]]\n",
      " \n",
      "gbt_model_1to1mean\n",
      "[[589475  83276]\n",
      " [  1970  17178]]\n",
      " \n",
      "gbt_model_5to1mean\n",
      "[[648101  24650]\n",
      " [  5480  13668]]\n",
      " \n",
      "gbt_model_3to1mean\n",
      "[[635987  36764]\n",
      " [  4121  15027]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_resultsmean = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_createdmean.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_resultsmean = train_resultsmean.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1mean</td>\n",
       "      <td>0.774460</td>\n",
       "      <td>0.985935</td>\n",
       "      <td>0.984318</td>\n",
       "      <td>0.987567</td>\n",
       "      <td>0.027297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1mean</td>\n",
       "      <td>0.807494</td>\n",
       "      <td>0.981628</td>\n",
       "      <td>0.973772</td>\n",
       "      <td>0.989622</td>\n",
       "      <td>0.035431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1mean</td>\n",
       "      <td>0.752568</td>\n",
       "      <td>0.987368</td>\n",
       "      <td>0.988476</td>\n",
       "      <td>0.986274</td>\n",
       "      <td>0.024582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1mean</td>\n",
       "      <td>0.792944</td>\n",
       "      <td>0.984176</td>\n",
       "      <td>0.979715</td>\n",
       "      <td>0.988688</td>\n",
       "      <td>0.030623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1mean</td>\n",
       "      <td>0.886666</td>\n",
       "      <td>0.932564</td>\n",
       "      <td>0.876216</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>0.123206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1mean</td>\n",
       "      <td>0.838584</td>\n",
       "      <td>0.977278</td>\n",
       "      <td>0.963359</td>\n",
       "      <td>0.991615</td>\n",
       "      <td>0.043547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1mean</td>\n",
       "      <td>0.865067</td>\n",
       "      <td>0.968853</td>\n",
       "      <td>0.945353</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>0.059091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resultname       AUC        f1  precision    recall     error\n",
       "0  gbt_model_11to1mean  0.774460  0.985935   0.984318  0.987567  0.027297\n",
       "0   gbt_model_7to1mean  0.807494  0.981628   0.973772  0.989622  0.035431\n",
       "0  gbt_model_13to1mean  0.752568  0.987368   0.988476  0.986274  0.024582\n",
       "0   gbt_model_9to1mean  0.792944  0.984176   0.979715  0.988688  0.030623\n",
       "0   gbt_model_1to1mean  0.886666  0.932564   0.876216  0.996669  0.123206\n",
       "0   gbt_model_5to1mean  0.838584  0.977278   0.963359  0.991615  0.043547\n",
       "0   gbt_model_3to1mean  0.865067  0.968853   0.945353  0.993562  0.059091"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_resultsmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: Mean Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_11to1mean\n",
      "[[518298   9906]\n",
      " [ 10624   9299]]\n",
      " \n",
      "gbt_model_7to1mean\n",
      "[[512417  15787]\n",
      " [  9118  10805]]\n",
      " \n",
      "gbt_model_13to1mean\n",
      "[[520898   7306]\n",
      " [ 11670   8253]]\n",
      " \n",
      "gbt_model_9to1mean\n",
      "[[515886  12318]\n",
      " [  9875  10048]]\n",
      " \n",
      "gbt_model_1to1mean\n",
      "[[453390  74814]\n",
      " [  2671  17252]]\n",
      " \n",
      "gbt_model_5to1mean\n",
      "[[505300  22904]\n",
      " [  7417  12506]]\n",
      " \n",
      "gbt_model_3to1mean\n",
      "[[492577  35627]\n",
      " [  5401  14522]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_resultsmean = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_createdmean.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_resultsmean = validation_resultsmean.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1mean</td>\n",
       "      <td>0.723996</td>\n",
       "      <td>0.980574</td>\n",
       "      <td>0.981246</td>\n",
       "      <td>0.979914</td>\n",
       "      <td>0.037455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1mean</td>\n",
       "      <td>0.756225</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>0.970112</td>\n",
       "      <td>0.982517</td>\n",
       "      <td>0.045437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1mean</td>\n",
       "      <td>0.700207</td>\n",
       "      <td>0.982106</td>\n",
       "      <td>0.986168</td>\n",
       "      <td>0.978087</td>\n",
       "      <td>0.034620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1mean</td>\n",
       "      <td>0.740511</td>\n",
       "      <td>0.978938</td>\n",
       "      <td>0.976679</td>\n",
       "      <td>0.981218</td>\n",
       "      <td>0.040489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1mean</td>\n",
       "      <td>0.862148</td>\n",
       "      <td>0.921271</td>\n",
       "      <td>0.858362</td>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.141363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1mean</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>0.970866</td>\n",
       "      <td>0.956638</td>\n",
       "      <td>0.985534</td>\n",
       "      <td>0.055317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1mean</td>\n",
       "      <td>0.830728</td>\n",
       "      <td>0.960014</td>\n",
       "      <td>0.932551</td>\n",
       "      <td>0.989154</td>\n",
       "      <td>0.074851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resultname       AUC        f1  precision    recall     error\n",
       "0  gbt_model_11to1mean  0.723996  0.980574   0.981246  0.979914  0.037455\n",
       "0   gbt_model_7to1mean  0.756225  0.976270   0.970112  0.982517  0.045437\n",
       "0  gbt_model_13to1mean  0.700207  0.982106   0.986168  0.978087  0.034620\n",
       "0   gbt_model_9to1mean  0.740511  0.978938   0.976679  0.981218  0.040489\n",
       "0   gbt_model_1to1mean  0.862148  0.921271   0.858362  0.994143  0.141363\n",
       "0   gbt_model_5to1mean  0.792177  0.970866   0.956638  0.985534  0.055317\n",
       "0   gbt_model_3to1mean  0.830728  0.960014   0.932551  0.989154  0.074851"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_resultsmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_createdmean.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: 75th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = quart75_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to175 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 205.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to175 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to175 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 299.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to175 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to175 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 395.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to175 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 470.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to175 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created75 = {\n",
    "                  'gbt_model_1to175' : (gbt_model_1to175, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to175' : (gbt_model_3to175, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to175' : (gbt_model_5to175, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to175' : (gbt_model_7to175, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to175' : (gbt_model_9to175, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to175' : (gbt_model_11to175, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to175' : (gbt_model_13to175, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: 75th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_5to175\n",
      "[[648695  24056]\n",
      " [  5683  13465]]\n",
      " \n",
      "gbt_model_7to175\n",
      "[[655732  17019]\n",
      " [  6945  12203]]\n",
      " \n",
      "gbt_model_9to175\n",
      "[[659269  13482]\n",
      " [  7549  11599]]\n",
      " \n",
      "gbt_model_3to175\n",
      "[[634692  38059]\n",
      " [  4058  15090]]\n",
      " \n",
      "gbt_model_11to175\n",
      "[[662256  10495]\n",
      " [  8315  10833]]\n",
      " \n",
      "gbt_model_1to175\n",
      "[[588327  84424]\n",
      " [  1939  17209]]\n",
      " \n",
      "gbt_model_13to175\n",
      "[[664766   7985]\n",
      " [  9132  10016]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_results75 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created75.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_results75 = train_results75.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to175</td>\n",
       "      <td>0.833724</td>\n",
       "      <td>0.977586</td>\n",
       "      <td>0.964242</td>\n",
       "      <td>0.991315</td>\n",
       "      <td>0.042982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to175</td>\n",
       "      <td>0.806001</td>\n",
       "      <td>0.982050</td>\n",
       "      <td>0.974702</td>\n",
       "      <td>0.989520</td>\n",
       "      <td>0.034635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to175</td>\n",
       "      <td>0.792858</td>\n",
       "      <td>0.984295</td>\n",
       "      <td>0.979960</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.030396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to175</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>0.967881</td>\n",
       "      <td>0.943428</td>\n",
       "      <td>0.993647</td>\n",
       "      <td>0.060872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to175</td>\n",
       "      <td>0.775075</td>\n",
       "      <td>0.985992</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.027186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to175</td>\n",
       "      <td>0.886623</td>\n",
       "      <td>0.931617</td>\n",
       "      <td>0.874509</td>\n",
       "      <td>0.996715</td>\n",
       "      <td>0.124820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to175</td>\n",
       "      <td>0.755607</td>\n",
       "      <td>0.987284</td>\n",
       "      <td>0.988131</td>\n",
       "      <td>0.986449</td>\n",
       "      <td>0.024739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_5to175  0.833724  0.977586   0.964242  0.991315  0.042982\n",
       "0   gbt_model_7to175  0.806001  0.982050   0.974702  0.989520  0.034635\n",
       "0   gbt_model_9to175  0.792858  0.984295   0.979960  0.988679  0.030396\n",
       "0   gbt_model_3to175  0.865750  0.967881   0.943428  0.993647  0.060872\n",
       "0  gbt_model_11to175  0.775075  0.985992   0.984400  0.987600  0.027186\n",
       "0   gbt_model_1to175  0.886623  0.931617   0.874509  0.996715  0.124820\n",
       "0  gbt_model_13to175  0.755607  0.987284   0.988131  0.986449  0.024739"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_results75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: 75th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_5to175\n",
      "[[507259  20945]\n",
      " [  7433  12490]]\n",
      " \n",
      "gbt_model_7to175\n",
      "[[512699  15505]\n",
      " [  8898  11025]]\n",
      " \n",
      "gbt_model_9to175\n",
      "[[516019  12185]\n",
      " [  9771  10152]]\n",
      " \n",
      "gbt_model_3to175\n",
      "[[493293  34911]\n",
      " [  5351  14572]]\n",
      " \n",
      "gbt_model_11to175\n",
      "[[518486   9718]\n",
      " [ 10804   9119]]\n",
      " \n",
      "gbt_model_1to175\n",
      "[[452142  76062]\n",
      " [  2618  17305]]\n",
      " \n",
      "gbt_model_13to175\n",
      "[[520545   7659]\n",
      " [ 11558   8365]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_results75 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created75.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_results75 = validation_results75.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to175</td>\n",
       "      <td>0.793630</td>\n",
       "      <td>0.972784</td>\n",
       "      <td>0.960347</td>\n",
       "      <td>0.985558</td>\n",
       "      <td>0.051773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to175</td>\n",
       "      <td>0.762013</td>\n",
       "      <td>0.976750</td>\n",
       "      <td>0.970646</td>\n",
       "      <td>0.982941</td>\n",
       "      <td>0.044521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to175</td>\n",
       "      <td>0.743247</td>\n",
       "      <td>0.979164</td>\n",
       "      <td>0.976931</td>\n",
       "      <td>0.981417</td>\n",
       "      <td>0.040056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to175</td>\n",
       "      <td>0.832661</td>\n",
       "      <td>0.960786</td>\n",
       "      <td>0.933906</td>\n",
       "      <td>0.989269</td>\n",
       "      <td>0.073454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to175</td>\n",
       "      <td>0.719657</td>\n",
       "      <td>0.980589</td>\n",
       "      <td>0.981602</td>\n",
       "      <td>0.979588</td>\n",
       "      <td>0.037440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to175</td>\n",
       "      <td>0.862296</td>\n",
       "      <td>0.919951</td>\n",
       "      <td>0.855999</td>\n",
       "      <td>0.994243</td>\n",
       "      <td>0.143543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to175</td>\n",
       "      <td>0.702683</td>\n",
       "      <td>0.981871</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.035059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_5to175  0.793630  0.972784   0.960347  0.985558  0.051773\n",
       "0   gbt_model_7to175  0.762013  0.976750   0.970646  0.982941  0.044521\n",
       "0   gbt_model_9to175  0.743247  0.979164   0.976931  0.981417  0.040056\n",
       "0   gbt_model_3to175  0.832661  0.960786   0.933906  0.989269  0.073454\n",
       "0  gbt_model_11to175  0.719657  0.980589   0.981602  0.979588  0.037440\n",
       "0   gbt_model_1to175  0.862296  0.919951   0.855999  0.994243  0.143543\n",
       "0  gbt_model_13to175  0.702683  0.981871   0.985500  0.978279  0.035059"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_results75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created75.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: 50th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = quart50_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 210.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to150 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 270.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to150 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 326.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to150 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to150 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 443.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to150 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 502.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to150 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 590.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to150 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created50 = {\n",
    "                  'gbt_model_1to150' : (gbt_model_1to150, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to150' : (gbt_model_3to150, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to150' : (gbt_model_5to150, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to150' : (gbt_model_7to150, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to150' : (gbt_model_9to150, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to150' : (gbt_model_11to150, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to150' : (gbt_model_13to150, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: 50th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_13to150\n",
      "[[664759   7992]\n",
      " [  9131  10017]]\n",
      " \n",
      "gbt_model_1to150\n",
      "[[588108  84643]\n",
      " [  1952  17196]]\n",
      " \n",
      "gbt_model_7to150\n",
      "[[655927  16824]\n",
      " [  6976  12172]]\n",
      " \n",
      "gbt_model_5to150\n",
      "[[648417  24334]\n",
      " [  5592  13556]]\n",
      " \n",
      "gbt_model_3to150\n",
      "[[633643  39108]\n",
      " [  4031  15117]]\n",
      " \n",
      "gbt_model_11to150\n",
      "[[662568  10183]\n",
      " [  8403  10745]]\n",
      " \n",
      "gbt_model_9to150\n",
      "[[659596  13155]\n",
      " [  7632  11516]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_results50 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created50.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_results50 = train_results50.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to150</td>\n",
       "      <td>0.755628</td>\n",
       "      <td>0.987280</td>\n",
       "      <td>0.988120</td>\n",
       "      <td>0.986450</td>\n",
       "      <td>0.024748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to150</td>\n",
       "      <td>0.886121</td>\n",
       "      <td>0.931422</td>\n",
       "      <td>0.874184</td>\n",
       "      <td>0.996692</td>\n",
       "      <td>0.125156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to150</td>\n",
       "      <td>0.805336</td>\n",
       "      <td>0.982176</td>\n",
       "      <td>0.974992</td>\n",
       "      <td>0.989477</td>\n",
       "      <td>0.034398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to150</td>\n",
       "      <td>0.835894</td>\n",
       "      <td>0.977439</td>\n",
       "      <td>0.963829</td>\n",
       "      <td>0.991450</td>\n",
       "      <td>0.043252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to150</td>\n",
       "      <td>0.865675</td>\n",
       "      <td>0.967075</td>\n",
       "      <td>0.941869</td>\n",
       "      <td>0.993679</td>\n",
       "      <td>0.062349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to150</td>\n",
       "      <td>0.773009</td>\n",
       "      <td>0.986163</td>\n",
       "      <td>0.984864</td>\n",
       "      <td>0.987476</td>\n",
       "      <td>0.026862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to150</td>\n",
       "      <td>0.790933</td>\n",
       "      <td>0.984482</td>\n",
       "      <td>0.980446</td>\n",
       "      <td>0.988562</td>\n",
       "      <td>0.030043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0  gbt_model_13to150  0.755628  0.987280   0.988120  0.986450  0.024748\n",
       "0   gbt_model_1to150  0.886121  0.931422   0.874184  0.996692  0.125156\n",
       "0   gbt_model_7to150  0.805336  0.982176   0.974992  0.989477  0.034398\n",
       "0   gbt_model_5to150  0.835894  0.977439   0.963829  0.991450  0.043252\n",
       "0   gbt_model_3to150  0.865675  0.967075   0.941869  0.993679  0.062349\n",
       "0  gbt_model_11to150  0.773009  0.986163   0.984864  0.987476  0.026862\n",
       "0   gbt_model_9to150  0.790933  0.984482   0.980446  0.988562  0.030043"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_results50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: 50th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_13to150\n",
      "[[520637   7567]\n",
      " [ 11635   8288]]\n",
      " \n",
      "gbt_model_1to150\n",
      "[[452660  75544]\n",
      " [  2656  17267]]\n",
      " \n",
      "gbt_model_7to150\n",
      "[[512751  15453]\n",
      " [  8835  11088]]\n",
      " \n",
      "gbt_model_5to150\n",
      "[[506968  21236]\n",
      " [  7392  12531]]\n",
      " \n",
      "gbt_model_3to150\n",
      "[[492961  35243]\n",
      " [  5186  14737]]\n",
      " \n",
      "gbt_model_11to150\n",
      "[[518728   9476]\n",
      " [ 10834   9089]]\n",
      " \n",
      "gbt_model_9to150\n",
      "[[516233  11971]\n",
      " [  9945   9978]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_results50 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created50.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_results50 = validation_results50.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to150</td>\n",
       "      <td>0.700838</td>\n",
       "      <td>0.981888</td>\n",
       "      <td>0.985674</td>\n",
       "      <td>0.978141</td>\n",
       "      <td>0.035032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to150</td>\n",
       "      <td>0.861833</td>\n",
       "      <td>0.920485</td>\n",
       "      <td>0.856980</td>\n",
       "      <td>0.994167</td>\n",
       "      <td>0.142668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to150</td>\n",
       "      <td>0.763643</td>\n",
       "      <td>0.976859</td>\n",
       "      <td>0.970744</td>\n",
       "      <td>0.983061</td>\n",
       "      <td>0.044311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to150</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.972536</td>\n",
       "      <td>0.959796</td>\n",
       "      <td>0.985629</td>\n",
       "      <td>0.052229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to150</td>\n",
       "      <td>0.836488</td>\n",
       "      <td>0.960604</td>\n",
       "      <td>0.933278</td>\n",
       "      <td>0.989589</td>\n",
       "      <td>0.073758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to150</td>\n",
       "      <td>0.719133</td>\n",
       "      <td>0.980794</td>\n",
       "      <td>0.982060</td>\n",
       "      <td>0.979542</td>\n",
       "      <td>0.037053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to150</td>\n",
       "      <td>0.739082</td>\n",
       "      <td>0.979209</td>\n",
       "      <td>0.977336</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.039983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0  gbt_model_13to150  0.700838  0.981888   0.985674  0.978141  0.035032\n",
       "0   gbt_model_1to150  0.861833  0.920485   0.856980  0.994167  0.142668\n",
       "0   gbt_model_7to150  0.763643  0.976859   0.970744  0.983061  0.044311\n",
       "0   gbt_model_5to150  0.794384  0.972536   0.959796  0.985629  0.052229\n",
       "0   gbt_model_3to150  0.836488  0.960604   0.933278  0.989589  0.073758\n",
       "0  gbt_model_11to150  0.719133  0.980794   0.982060  0.979542  0.037053\n",
       "0   gbt_model_9to150  0.739082  0.979209   0.977336  0.981100  0.039983"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_results50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created50.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: 25th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = quart25_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 251.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to125 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to125 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 381.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to125 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 448.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to125 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 514.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to125 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 577.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to125 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 682.0\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to125 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created25 = {\n",
    "                  'gbt_model_1to125' : (gbt_model_1to125, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to125' : (gbt_model_3to125, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to125' : (gbt_model_5to125, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to125' : (gbt_model_7to125, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to125' : (gbt_model_9to125, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to125' : (gbt_model_11to125, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to125' : (gbt_model_13to125, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: 25th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_3to125\n",
      "[[633621  39130]\n",
      " [  4067  15081]]\n",
      " \n",
      "gbt_model_13to125\n",
      "[[664409   8342]\n",
      " [  8972  10176]]\n",
      " \n",
      "gbt_model_7to125\n",
      "[[655931  16820]\n",
      " [  6952  12196]]\n",
      " \n",
      "gbt_model_5to125\n",
      "[[648495  24256]\n",
      " [  5592  13556]]\n",
      " \n",
      "gbt_model_9to125\n",
      "[[659540  13211]\n",
      " [  7607  11541]]\n",
      " \n",
      "gbt_model_1to125\n",
      "[[588772  83979]\n",
      " [  1936  17212]]\n",
      " \n",
      "gbt_model_11to125\n",
      "[[662347  10404]\n",
      " [  8352  10796]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_results25 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created25.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_results25 = train_results25.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to125</td>\n",
       "      <td>0.864719</td>\n",
       "      <td>0.967031</td>\n",
       "      <td>0.941836</td>\n",
       "      <td>0.993622</td>\n",
       "      <td>0.062433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to125</td>\n",
       "      <td>0.759520</td>\n",
       "      <td>0.987133</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.986676</td>\n",
       "      <td>0.025024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to125</td>\n",
       "      <td>0.805966</td>\n",
       "      <td>0.982197</td>\n",
       "      <td>0.974998</td>\n",
       "      <td>0.989512</td>\n",
       "      <td>0.034358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to125</td>\n",
       "      <td>0.835952</td>\n",
       "      <td>0.977499</td>\n",
       "      <td>0.963945</td>\n",
       "      <td>0.991451</td>\n",
       "      <td>0.043139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to125</td>\n",
       "      <td>0.791544</td>\n",
       "      <td>0.984458</td>\n",
       "      <td>0.980363</td>\n",
       "      <td>0.988598</td>\n",
       "      <td>0.030088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to125</td>\n",
       "      <td>0.887032</td>\n",
       "      <td>0.931995</td>\n",
       "      <td>0.875171</td>\n",
       "      <td>0.996723</td>\n",
       "      <td>0.124173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to125</td>\n",
       "      <td>0.774177</td>\n",
       "      <td>0.986034</td>\n",
       "      <td>0.984535</td>\n",
       "      <td>0.987547</td>\n",
       "      <td>0.027108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_3to125  0.864719  0.967031   0.941836  0.993622  0.062433\n",
       "0  gbt_model_13to125  0.759520  0.987133   0.987600  0.986676  0.025024\n",
       "0   gbt_model_7to125  0.805966  0.982197   0.974998  0.989512  0.034358\n",
       "0   gbt_model_5to125  0.835952  0.977499   0.963945  0.991451  0.043139\n",
       "0   gbt_model_9to125  0.791544  0.984458   0.980363  0.988598  0.030088\n",
       "0   gbt_model_1to125  0.887032  0.931995   0.875171  0.996723  0.124173\n",
       "0  gbt_model_11to125  0.774177  0.986034   0.984535  0.987547  0.027108"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_results25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: 25th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_3to125\n",
      "[[494805  33399]\n",
      " [  5286  14637]]\n",
      " \n",
      "gbt_model_13to125\n",
      "[[520345   7859]\n",
      " [ 11482   8441]]\n",
      " \n",
      "gbt_model_7to125\n",
      "[[512863  15341]\n",
      " [  9144  10779]]\n",
      " \n",
      "gbt_model_5to125\n",
      "[[506987  21217]\n",
      " [  7434  12489]]\n",
      " \n",
      "gbt_model_9to125\n",
      "[[516235  11969]\n",
      " [ 10015   9908]]\n",
      " \n",
      "gbt_model_1to125\n",
      "[[450871  77333]\n",
      " [  2593  17330]]\n",
      " \n",
      "gbt_model_11to125\n",
      "[[518574   9630]\n",
      " [ 10774   9149]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_results25 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created25.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_results25 = validation_results25.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to125</td>\n",
       "      <td>0.835724</td>\n",
       "      <td>0.962374</td>\n",
       "      <td>0.936769</td>\n",
       "      <td>0.989430</td>\n",
       "      <td>0.070577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to125</td>\n",
       "      <td>0.704401</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.985121</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>0.035286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to125</td>\n",
       "      <td>0.755995</td>\n",
       "      <td>0.976681</td>\n",
       "      <td>0.970956</td>\n",
       "      <td>0.982483</td>\n",
       "      <td>0.044670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to125</td>\n",
       "      <td>0.793348</td>\n",
       "      <td>0.972515</td>\n",
       "      <td>0.959832</td>\n",
       "      <td>0.985549</td>\n",
       "      <td>0.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to125</td>\n",
       "      <td>0.737327</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>0.977340</td>\n",
       "      <td>0.980969</td>\n",
       "      <td>0.040107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to125</td>\n",
       "      <td>0.861721</td>\n",
       "      <td>0.918576</td>\n",
       "      <td>0.853593</td>\n",
       "      <td>0.994282</td>\n",
       "      <td>0.145817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to125</td>\n",
       "      <td>0.720493</td>\n",
       "      <td>0.980701</td>\n",
       "      <td>0.981768</td>\n",
       "      <td>0.979647</td>\n",
       "      <td>0.037225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_3to125  0.835724  0.962374   0.936769  0.989430  0.070577\n",
       "0  gbt_model_13to125  0.704401  0.981749   0.985121  0.978410  0.035286\n",
       "0   gbt_model_7to125  0.755995  0.976681   0.970956  0.982483  0.044670\n",
       "0   gbt_model_5to125  0.793348  0.972515   0.959832  0.985549  0.052271\n",
       "0   gbt_model_9to125  0.737327  0.979146   0.977340  0.980969  0.040107\n",
       "0   gbt_model_1to125  0.861721  0.918576   0.853593  0.994282  0.145817\n",
       "0  gbt_model_11to125  0.720493  0.980701   0.981768  0.979647  0.037225"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created50.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=black>Evaluation of Generalization over All Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025785</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>-0.020628</td>\n",
       "      <td>gbt_model_1to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035870</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>-0.013331</td>\n",
       "      <td>gbt_model_3to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041375</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>gbt_model_5to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049198</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>-0.010405</td>\n",
       "      <td>gbt_model_7to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052865</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>-0.009892</td>\n",
       "      <td>gbt_model_9to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054580</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>-0.010285</td>\n",
       "      <td>gbt_model_13to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056040</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>gbt_model_11to1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error       resultname\n",
       "0  0.025785  0.012795   0.020439  0.002530 -0.020628   gbt_model_1to1\n",
       "0  0.035870  0.007513   0.010128  0.004576 -0.013331   gbt_model_3to1\n",
       "0  0.041375  0.005026   0.004256  0.005837 -0.009209   gbt_model_5to1\n",
       "0  0.049198  0.005566   0.004211  0.006958 -0.010405   gbt_model_7to1\n",
       "0  0.052865  0.005248   0.003019  0.007505 -0.009892   gbt_model_9to1\n",
       "0  0.054580  0.005392   0.002447  0.008310 -0.010285  gbt_model_13to1\n",
       "0  0.056040  0.005446   0.002847  0.008048 -0.010336  gbt_model_11to1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_resultsall[train_resultsall.columns[1:]] - validation_resultsall[validation_resultsall.columns[1:]]\n",
    "results_all['resultname'] = train_resultsall['resultname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>-0.018157</td>\n",
       "      <td>gbt_model_1to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034339</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.012802</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>-0.015760</td>\n",
       "      <td>gbt_model_3to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046406</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.006721</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>-0.011771</td>\n",
       "      <td>gbt_model_5to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050464</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>gbt_model_11to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051269</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>-0.010005</td>\n",
       "      <td>gbt_model_7to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052361</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>-0.010038</td>\n",
       "      <td>gbt_model_13to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052433</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>-0.009866</td>\n",
       "      <td>gbt_model_9to1mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error           resultname\n",
       "0  0.024519  0.011293   0.017854  0.002526 -0.018157   gbt_model_1to1mean\n",
       "0  0.034339  0.008839   0.012802  0.004408 -0.015760   gbt_model_3to1mean\n",
       "0  0.046406  0.006412   0.006721  0.006081 -0.011771   gbt_model_5to1mean\n",
       "0  0.050464  0.005360   0.003072  0.007653 -0.010157  gbt_model_11to1mean\n",
       "0  0.051269  0.005358   0.003660  0.007105 -0.010005   gbt_model_7to1mean\n",
       "0  0.052361  0.005262   0.002307  0.008186 -0.010038  gbt_model_13to1mean\n",
       "0  0.052433  0.005238   0.003035  0.007470 -0.009866   gbt_model_9to1mean"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mean = train_resultsmean[train_resultsmean.columns[1:]] - validation_resultsmean[validation_resultsmean.columns[1:]]\n",
    "results_mean['resultname'] = train_resultsmean['resultname']\n",
    "results_mean.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.018510</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>-0.018723</td>\n",
       "      <td>gbt_model_1to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033089</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>-0.012582</td>\n",
       "      <td>gbt_model_3to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>-0.008791</td>\n",
       "      <td>gbt_model_5to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>-0.009886</td>\n",
       "      <td>gbt_model_7to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049611</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>-0.009660</td>\n",
       "      <td>gbt_model_9to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052924</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>gbt_model_13to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.008012</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>gbt_model_11to175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error         resultname\n",
       "0  0.024326  0.011665   0.018510  0.002472 -0.018723   gbt_model_1to175\n",
       "0  0.033089  0.007096   0.009522  0.004378 -0.012582   gbt_model_3to175\n",
       "0  0.040094  0.004802   0.003896  0.005757 -0.008791   gbt_model_5to175\n",
       "0  0.043987  0.005301   0.004057  0.006579 -0.009886   gbt_model_7to175\n",
       "0  0.049611  0.005131   0.003029  0.007263 -0.009660   gbt_model_9to175\n",
       "0  0.052924  0.005413   0.002631  0.008170 -0.010320  gbt_model_13to175\n",
       "0  0.055418  0.005404   0.002798  0.008012 -0.010254  gbt_model_11to175"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_75 = train_results75[validation_results25.columns[1:]] - validation_results75[validation_results25.columns[1:]]\n",
    "results_75['resultname'] = train_results75['resultname']\n",
    "results_75.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>-0.017512</td>\n",
       "      <td>gbt_model_1to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.008591</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>-0.011410</td>\n",
       "      <td>gbt_model_3to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>-0.008977</td>\n",
       "      <td>gbt_model_5to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041693</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>-0.009913</td>\n",
       "      <td>gbt_model_7to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051851</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>gbt_model_9to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053876</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>-0.010191</td>\n",
       "      <td>gbt_model_11to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054790</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.008309</td>\n",
       "      <td>-0.010284</td>\n",
       "      <td>gbt_model_13to150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error         resultname\n",
       "0  0.024287  0.010937   0.017204  0.002525 -0.017512   gbt_model_1to150\n",
       "0  0.029187  0.006471   0.008591  0.004089 -0.011410   gbt_model_3to150\n",
       "0  0.041510  0.004904   0.004033  0.005821 -0.008977   gbt_model_5to150\n",
       "0  0.041693  0.005317   0.004248  0.006415 -0.009913   gbt_model_7to150\n",
       "0  0.051851  0.005273   0.003110  0.007462 -0.009940   gbt_model_9to150\n",
       "0  0.053876  0.005369   0.002804  0.007935 -0.010191  gbt_model_11to150\n",
       "0  0.054790  0.005392   0.002446  0.008309 -0.010284  gbt_model_13to150"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_50 = train_results50[train_results50.columns[1:]] - validation_results50[validation_results50.columns[1:]]\n",
    "results_50['resultname'] = train_results50['resultname']\n",
    "results_50.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025311</td>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-0.021644</td>\n",
       "      <td>gbt_model_1to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028995</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>-0.008144</td>\n",
       "      <td>gbt_model_3to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042604</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.005902</td>\n",
       "      <td>-0.009131</td>\n",
       "      <td>gbt_model_5to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>-0.010313</td>\n",
       "      <td>gbt_model_7to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053684</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>-0.010117</td>\n",
       "      <td>gbt_model_11to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.007629</td>\n",
       "      <td>-0.010019</td>\n",
       "      <td>gbt_model_9to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055119</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>-0.010262</td>\n",
       "      <td>gbt_model_13to125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error         resultname\n",
       "0  0.025311  0.013419   0.021578  0.002441 -0.021644   gbt_model_1to125\n",
       "0  0.028995  0.004657   0.005067  0.004192 -0.008144   gbt_model_3to125\n",
       "0  0.042604  0.004984   0.004113  0.005902 -0.009131   gbt_model_5to125\n",
       "0  0.049971  0.005516   0.004042  0.007029 -0.010313   gbt_model_7to125\n",
       "0  0.053684  0.005333   0.002767  0.007901 -0.010117  gbt_model_11to125\n",
       "0  0.054217  0.005312   0.003023  0.007629 -0.010019   gbt_model_9to125\n",
       "0  0.055119  0.005384   0.002479  0.008266 -0.010262  gbt_model_13to125"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_25 = train_results25[validation_results25.columns[1:]] - validation_results25[validation_results25.columns[1:]]\n",
    "results_25['resultname'] = train_results25['resultname']\n",
    "results_25.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on generalization, the best in class features were as follows.\n",
    "- **gbt_model_1to175** - 0.024326\n",
    "- **gbt_model_3to125** - 0.028995\n",
    "- **gbt_model_5to175** - 0.040094\n",
    "- **gbt_model_7to150** - 0.041693\n",
    "- **gbt_model_9to175** - 0.049611\n",
    "- **gbt_model_11to1mean** - 0.050464\n",
    "- **gbt_model_13to1mean** - 0.052361"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination - Ensemble of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create Custom Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator that we can use instead of BinaryClassificationEvaluator() in grid search\n",
    "class ClassEvaluatorPandas:\n",
    "\n",
    "    def __init__(self, modelname, model, y_pred, y_true):\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.modelname = modelname\n",
    "        self.y_pred = y_pred \n",
    "        self.y_true = y_true\n",
    "        self.model = model\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        self.cm = confusion_matrix(y_true,y_pred)\n",
    "        \n",
    "        # Calculate confusion matrix values\n",
    "        self.tp = self.cm[0][0]\n",
    "        self.fp = self.cm[0][1]\n",
    "        self.tn = self.cm[1][1]\n",
    "        self.fn = self.cm[1][0]\n",
    "        \n",
    "    def evaluate(self):\n",
    "        \n",
    "        # Calculate Metrics and add epsilon to prevent division by zero\n",
    "        precision = self.tp / float(self.tp + self.fp + 0.00001)\n",
    "        recall = self.tp / float(self.tp + self.fn + 0.00001)\n",
    "        f1 = (2 * precision * recall) / float(precision + recall + 0.00001)\n",
    "        error = (self.fp + self.fn + 0.00001) / (self.tp + self.fp + self.tn + self.fn + 0.00001)\n",
    "        \n",
    "        # Instantiate Evaluator and call AUC metric\n",
    "        from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_true, self.y_pred)\n",
    "        AUC = round(auc(false_positive_rate, true_positive_rate), ndigits=5)\n",
    "        \n",
    "        return pd.DataFrame(data=[[self.modelname, AUC, f1, precision, recall, error]], \n",
    "                            columns=['modelname', 'AUC', 'f1', 'precision', 'recall', 'error'])\n",
    "    \n",
    "    def confusionmatrix(self):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Print Confusion Matrix\n",
    "        return self.cm\n",
    "        \n",
    "    \n",
    "    def modelparams(self):\n",
    "        scores = self.model.avgMetrics\n",
    "        params = [{p.name: v for p, v in m.items()} for m in self.model.getEstimatorParamMaps()]\n",
    "        params_pd = pd.DataFrame(params)\n",
    "        params_pd['AUC score'] = scores\n",
    "        return params_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Import Data</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Build Ensemble - Train Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Probability Values as Spark DF\n",
    "gbt_model_1to1_train = gbt_model_1to175.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_3to1_train = gbt_model_3to125.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_5to1_train = gbt_model_5to175.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_7to1_train = gbt_model_7to150.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_9to1_train = gbt_model_9to175.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_11to1_train = gbt_model_11to1mean.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_13to1_train = gbt_model_13to1mean.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single DF with all Predictions and Convert back to Spark DF\n",
    "Jan2016_predictsgbt = pd.merge(gbt_model_1to1_train[['msno','prediction']], gbt_model_3to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_5to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_7to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_9to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_11to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_13to1_train[['msno','prediction', 'is_churn']], on='msno')\n",
    "\n",
    "# Rename Columns\n",
    "Jan2016_predictsgbt.columns = ['msno', 'gbt_model_1to175', 'gbt_model_3to150', 'gbt_model_5to175', 'gbt_model_7to150', 'gbt_model_9to175', 'gbt_model_11to1mean', 'gbt_model_13to175', 'is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan2016_predictsgbt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to GCS\n",
    "sparkDf = spark.createDataFrame(Jan2016_predictsgbt)    \n",
    "sparkDf.coalesce(1).write.option(\"header\",\"true\").csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Jan2016_predictsgbt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Build Ensemble - Validation Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Prediction Values as Spark DF\n",
    "gbt_model_1to1_valid = gbt_model_1to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_3to1_valid = gbt_model_3to150.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_5to1_valid = gbt_model_5to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_7to1_valid = gbt_model_7to150.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_9to1_valid = gbt_model_9to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_11to1_valid = gbt_model_11to1mean.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_13to1_valid = gbt_model_13to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single DF with all Predictions and Convert back to Spark DF\n",
    "Feb2016_predictsgbt = pd.merge(gbt_model_1to1_valid[['msno','prediction']], gbt_model_3to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_5to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_7to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_9to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_11to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_13to1_valid[['msno','prediction', 'is_churn']], on='msno')\n",
    "\n",
    "# Rename Columns\n",
    "Feb2016_predictsgbt.columns = ['msno', 'gbt_model_1to175', 'gbt_model_3to150', 'gbt_model_5to175', 'gbt_model_7to150', 'gbt_model_9to175', 'gbt_model_11to1mean', 'gbt_model_13to175', 'is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feb2016_predictsgbt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to GCS\n",
    "sparkDf = spark.createDataFrame(Feb2016_predictsgbt)    \n",
    "sparkDf.coalesce(1).write.option(\"header\",\"true\").csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Feb2016_predictsgbt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Import Ensemble Sets (if already built)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan2016_predictsgbt = pd.read_csv('D:\\J-5 Local\\Jan2016_predictsgbt.csv')\n",
    "Feb2016_predictsgbt = pd.read_csv('D:\\J-5 Local\\Feb2016_predictsgbt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Train x and y\n",
    "train_x = Jan2016_predictsgbt[Jan2016_predictsgbt.columns[1:-1]]\n",
    "train_y = Jan2016_predictsgbt['is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Validation x and y\n",
    "valid_x = Feb2016_predictsgbt[Feb2016_predictsgbt.columns[1:-1]]\n",
    "valid_y = Feb2016_predictsgbt['is_churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Train Model: All Splits, All Splits, XGB + RFECV</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Estimators\n",
    "rfc = RandomForestClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 78\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc1 = RFECV(rfc, min_features_to_select=1, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 70\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc2 = RFECV(rfc, min_features_to_select=2, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 60\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc3 = RFECV(rfc, min_features_to_select=3, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 50\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc4 = RFECV(rfc, min_features_to_select=4, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 39\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc5 = RFECV(rfc, min_features_to_select=5, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1043\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtgmb4 = RFECV(gbm, min_features_to_select=4, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 718\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtxgb4 = RFECV(xgb, min_features_to_select=4, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were createdgg\n",
    "ensembles_created = {\n",
    "                  'GBT_RFC1' : gbtrfc1,\n",
    "                  'GBT_RFC2' : gbtrfc2,\n",
    "                  'GBT_RFC3' : gbtrfc3,\n",
    "                  'GBT_RFC4' : gbtrfc4,\n",
    "                  'GBT_RFC5' : gbtrfc5,\n",
    "                  'GBT_GBM4' : gbtgmb4,\n",
    "                  'GBT_XGB4' : gbtxgb4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + RFECV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT_RFC1\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "Time spent for training: 736\n",
      "\n",
      "GBT_RFC2\n",
      "[[665625   7126]\n",
      " [  9382   9766]]\n",
      "Time spent for training: 737\n",
      "\n",
      "GBT_RFC3\n",
      "[[665613   7138]\n",
      " [  9371   9777]]\n",
      "Time spent for training: 738\n",
      "\n",
      "GBT_RFC4\n",
      "[[665632   7119]\n",
      " [  9391   9757]]\n",
      "Time spent for training: 738\n",
      "\n",
      "GBT_RFC5\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "Time spent for training: 739\n",
      "\n",
      "GBT_GBM4\n",
      "[[665629   7122]\n",
      " [  9381   9767]]\n",
      "Time spent for training: 741\n",
      "\n",
      "GBT_XGB4\n",
      "[[665632   7119]\n",
      " [  9391   9757]]\n",
      "Time spent for training: 742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_ensemble_results = pd.DataFrame()\n",
    "\n",
    "for model_name, model1 in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_ensemble_results = train_ensemble_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    end = time.time()\n",
    "    print('Time spent for training: {}'.format(round(end-start)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC1</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC2</td>\n",
       "      <td>0.74972</td>\n",
       "      <td>0.987747</td>\n",
       "      <td>0.989408</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.023859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC3</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.986117</td>\n",
       "      <td>0.023860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC4</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC5</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_GBM4</td>\n",
       "      <td>0.74975</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.986102</td>\n",
       "      <td>0.023852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_XGB4</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname      AUC        f1  precision    recall     error\n",
       "0  GBT_RFC1  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBT_RFC2  0.74972  0.987747   0.989408  0.986101  0.023859\n",
       "0  GBT_RFC3  0.75000  0.987746   0.989390  0.986117  0.023860\n",
       "0  GBT_RFC4  0.74949  0.987745   0.989418  0.986088  0.023862\n",
       "0  GBT_RFC5  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBT_GBM4  0.74975  0.987750   0.989414  0.986102  0.023852\n",
       "0  GBT_XGB4  0.74949  0.987745   0.989418  0.986088  0.023862"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + RFECV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT_RFC1\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "Time spent for training: 743\n",
      "\n",
      "GBT_RFC2\n",
      "[[521507   6697]\n",
      " [ 11823   8100]]\n",
      "Time spent for training: 743\n",
      "\n",
      "GBT_RFC3\n",
      "[[521480   6724]\n",
      " [ 11821   8102]]\n",
      "Time spent for training: 744\n",
      "\n",
      "GBT_RFC4\n",
      "[[521515   6689]\n",
      " [ 11840   8083]]\n",
      "Time spent for training: 745\n",
      "\n",
      "GBT_RFC5\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "Time spent for training: 745\n",
      "\n",
      "GBT_GBM4\n",
      "[[521506   6698]\n",
      " [ 11828   8095]]\n",
      "Time spent for training: 747\n",
      "\n",
      "GBT_XGB4\n",
      "[[521515   6689]\n",
      " [ 11840   8083]]\n",
      "Time spent for training: 747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "valid_ensemble_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    valid_ensemble_results = valid_ensemble_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    end = time.time()\n",
    "    print('Time spent for training: {}'.format(round(end-start)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC1</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC2</td>\n",
       "      <td>0.69694</td>\n",
       "      <td>0.982549</td>\n",
       "      <td>0.987321</td>\n",
       "      <td>0.977832</td>\n",
       "      <td>0.033788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC3</td>\n",
       "      <td>0.69697</td>\n",
       "      <td>0.982525</td>\n",
       "      <td>0.987270</td>\n",
       "      <td>0.977834</td>\n",
       "      <td>0.033833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC4</td>\n",
       "      <td>0.69652</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.977801</td>\n",
       "      <td>0.033804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC5</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_GBM4</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_XGB4</td>\n",
       "      <td>0.69652</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.977801</td>\n",
       "      <td>0.033804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname      AUC        f1  precision    recall     error\n",
       "0  GBT_RFC1  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBT_RFC2  0.69694  0.982549   0.987321  0.977832  0.033788\n",
       "0  GBT_RFC3  0.69697  0.982525   0.987270  0.977834  0.033833\n",
       "0  GBT_RFC4  0.69652  0.982540   0.987336  0.977801  0.033804\n",
       "0  GBT_RFC5  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBT_GBM4  0.69682  0.982543   0.987319  0.977823  0.033799\n",
       "0  GBT_XGB4  0.69652  0.982540   0.987336  0.977801  0.033804"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>-0.009929</td>\n",
       "      <td>GBT_RFC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBT_RFC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBT_RFC5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05293</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>GBT_GBM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05297</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>-0.009942</td>\n",
       "      <td>GBT_RFC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05297</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>-0.009942</td>\n",
       "      <td>GBT_XGB4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05303</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>-0.009973</td>\n",
       "      <td>GBT_RFC3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error modelname\n",
       "0  0.05278  0.005198   0.002086  0.008269 -0.009929  GBT_RFC2\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBT_RFC1\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBT_RFC5\n",
       "0  0.05293  0.005207   0.002094  0.008280 -0.009947  GBT_GBM4\n",
       "0  0.05297  0.005205   0.002082  0.008287 -0.009942  GBT_RFC4\n",
       "0  0.05297  0.005205   0.002082  0.008287 -0.009942  GBT_XGB4\n",
       "0  0.05303  0.005221   0.002120  0.008282 -0.009973  GBT_RFC3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_ensemble_results[train_ensemble_results.columns[1:]] - valid_ensemble_results[valid_ensemble_results.columns[1:]]\n",
    "results_all['modelname'] = train_ensemble_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Train Model: All Splits, XGB + GridCV </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>XGBOOST Parameter Tuning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Param Grid\n",
    "\n",
    "param_rfc = {\n",
    "         'bootstrap': [True, False],\n",
    "         'max_depth': [3, 5, 7],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'n_estimators': [100, 500, 1000]\n",
    "        }\n",
    "\n",
    "param_gbm = {\n",
    "        'learning_rate': [.1, .5, .01],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        }\n",
    "\n",
    "param_xgb = {\n",
    "        'learning_rate': [.1, .5, .01],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        }\n",
    "\n",
    "# Instatiate Esitmator Object\n",
    "rfc = RandomForestClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# # Instatiate StratKFold Object\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "# Instatiate Random Search CV Object\n",
    "rscv_rfc = RandomizedSearchCV(rfc, param_distributions=param_rfc, n_iter=5, scoring='roc_auc', \n",
    "                                   n_jobs=4, cv=5, verbose=3)\n",
    "\n",
    "rscv_gbm = RandomizedSearchCV(gbm, param_distributions=param_gbm, n_iter=5, scoring='roc_auc', \n",
    "                                   n_jobs=4, cv=5, verbose=3)\n",
    "\n",
    "rscv_xgb = RandomizedSearchCV(xgb, param_distributions=param_xgb, n_iter=5, scoring='roc_auc', \n",
    "                                   n_jobs=4, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 913\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "GBMrfc = rscv_rfc.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 38.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 2584\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "GBMgmb = rscv_gbm.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1312\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "GBMxgb = rscv_xgb.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "ensembles_created1 = {\n",
    "                  'GBM_RFC_rscv' : GBMrfc,\n",
    "                  'GBM_GBM_rscv' : GBMgmb,\n",
    "                  'GBM_XGB_rscv' : GBMxgb}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[665629   7122]\n",
      " [  9382   9766]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_rscv_results = train_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.74972</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.74972  0.987750   0.989414  0.986101  0.023853\n",
       "0  GBM_GBM_rscv  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBM_XGB_rscv  0.74964  0.987748   0.989415  0.986097  0.023856"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[521506   6698]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_rscv_results = validation_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.69682  0.982543   0.987319  0.977823  0.033799\n",
       "0  GBM_GBM_rscv  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBM_XGB_rscv  0.69682  0.982547   0.987327  0.977823  0.033791"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05290</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error     modelname\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_GBM_rscv\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_XGB_rscv\n",
       "0  0.05290  0.005207   0.002094  0.008278 -0.009946  GBM_RFC_rscv"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_rscv_results[train_rscv_results.columns[1:]] - validation_rscv_results[validation_rscv_results.columns[1:]]\n",
    "results_all['modelname'] = train_rscv_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[665615   7136]\n",
      " [  9377   9771]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[665632   7119]\n",
      " [  9391   9757]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_rscv_results = train_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.74984</td>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.989393</td>\n",
       "      <td>0.986108</td>\n",
       "      <td>0.023866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBM_GBM_rscv  0.74984  0.987743   0.989393  0.986108  0.023866\n",
       "0  GBM_XGB_rscv  0.74949  0.987745   0.989418  0.986088  0.023862"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[521485   6719]\n",
      " [ 11833   8090]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[521515   6689]\n",
      " [ 11840   8083]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_rscv_results = validation_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.69667</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>0.987280</td>\n",
       "      <td>0.977812</td>\n",
       "      <td>0.033846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.69652</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.977801</td>\n",
       "      <td>0.033804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBM_GBM_rscv  0.69667  0.982518   0.987280  0.977812  0.033846\n",
       "0  GBM_XGB_rscv  0.69652  0.982540   0.987336  0.977801  0.033804"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05297</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>-0.009942</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05317</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>-0.009980</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error     modelname\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_RFC_rscv\n",
       "0  0.05297  0.005205   0.002082  0.008287 -0.009942  GBM_XGB_rscv\n",
       "0  0.05317  0.005224   0.002113  0.008295 -0.009980  GBM_GBM_rscv"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_rscv_results[train_rscv_results.columns[1:]] - validation_rscv_results[validation_rscv_results.columns[1:]]\n",
    "results_all['modelname'] = train_rscv_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[665629   7122]\n",
      " [  9382   9766]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[665526   7225]\n",
      " [  9342   9806]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_rscv_results = train_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.74972</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.75069</td>\n",
       "      <td>0.987701</td>\n",
       "      <td>0.989261</td>\n",
       "      <td>0.986157</td>\n",
       "      <td>0.023944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.74972  0.987750   0.989414  0.986101  0.023853\n",
       "0  GBM_GBM_rscv  0.75069  0.987701   0.989261  0.986157  0.023944\n",
       "0  GBM_XGB_rscv  0.74964  0.987748   0.989415  0.986097  0.023856"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[521506   6698]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[521372   6832]\n",
      " [ 11765   8158]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_rscv_results = validation_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.69827</td>\n",
       "      <td>0.982473</td>\n",
       "      <td>0.987066</td>\n",
       "      <td>0.977933</td>\n",
       "      <td>0.033928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.69682  0.982543   0.987319  0.977823  0.033799\n",
       "0  GBM_GBM_rscv  0.69827  0.982473   0.987066  0.977933  0.033928\n",
       "0  GBM_XGB_rscv  0.69682  0.982547   0.987327  0.977823  0.033791"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05242</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>-0.009984</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05290</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error     modelname\n",
       "0  0.05242  0.005229   0.002195  0.008225 -0.009984  GBM_GBM_rscv\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_XGB_rscv\n",
       "0  0.05290  0.005207   0.002094  0.008278 -0.009946  GBM_RFC_rscv"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_rscv_results[train_rscv_results.columns[1:]] - validation_rscv_results[validation_rscv_results.columns[1:]]\n",
    "results_all['modelname'] = train_rscv_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
