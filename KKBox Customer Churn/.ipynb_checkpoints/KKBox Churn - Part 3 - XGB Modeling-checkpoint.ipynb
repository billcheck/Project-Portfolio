{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KKBox Customer Churn Prediction\n",
    "### w/ XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: <font color=green>*Model Creation and Evaluation*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "from __future__ import absolute_import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Working Locally\n",
    "\n",
    "# Import Subsamples\n",
    "DRV_Jan2016_1to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_1to1')\n",
    "DRV_Jan2016_3to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_3to1')\n",
    "DRV_Jan2016_5to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_5to1')\n",
    "DRV_Jan2016_7to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_7to1')\n",
    "DRV_Jan2016_9to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_9to1')\n",
    "DRV_Jan2016_11to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_11to1')\n",
    "DRV_Jan2016_13to1 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016_13to1')\n",
    "\n",
    "# Import Main Sets\n",
    "DRV_Jan20160 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016000000000000')\n",
    "DRV_Jan20161 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016000000000001')\n",
    "DRV_Jan20162 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Jan2016000000000002')\n",
    "\n",
    "DRV_Jan2016 = pd.concat([DRV_Jan20160,DRV_Jan20161,DRV_Jan20162])\n",
    "\n",
    "del DRV_Jan20160\n",
    "del DRV_Jan20161\n",
    "del DRV_Jan20162\n",
    "\n",
    "# Import DRV_Feb2016 (Validation Set) \n",
    "DRV_Feb20160 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Feb2016000000000000')\n",
    "DRV_Feb20161 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Feb2016000000000001')\n",
    "DRV_Feb20162 = pd.read_csv('D:\\J-5 Local\\Datasets_KKBox User Data_Monthly Datasets_DRV_Feb2016000000000002')\n",
    "\n",
    "DRV_Feb2016 = pd.concat([DRV_Feb20160,DRV_Feb20161,DRV_Feb20162])\n",
    "\n",
    "del DRV_Feb20160\n",
    "del DRV_Feb20161\n",
    "del DRV_Feb20162\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # If Working on Cloud ML ##\n",
    "# import pyspark\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark import SparkConf\n",
    "# # spark = SparkSession.Builder().config(conf=SparkConf().setMaster(\"local[*]\")).getOrCreate()\n",
    "# spark = SparkSession.Builder().getOrCreate()\n",
    "\n",
    "# from tensorflow.python.lib.io import file_io\n",
    "# from pandas.compat import StringIO\n",
    "# import pandas as pd\n",
    "\n",
    "# # read the input data\n",
    "# def read_data(gcs_path):\n",
    "#    print('downloading csv file from', gcs_path)     \n",
    "#    file_stream = file_io.FileIO(gcs_path, mode='r')\n",
    "#    data = pd.read_csv(StringIO(file_stream.read()))\n",
    "#    return data\n",
    "\n",
    "# # Import DRV_Jan2016 (Train Set) \n",
    "# DRV_Jan2016_1to1 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_1to1')\n",
    "# DRV_Jan2016_3to1 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_3to1')\n",
    "# DRV_Jan2016_5to1 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_5to1')\n",
    "# DRV_Jan2016_7to1 = read_data'gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_7to1')\n",
    "# DRV_Jan2016_9to1 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_9to1')\n",
    "# DRV_Jan2016_11to1 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_11to1')\n",
    "# DRV_Jan2016_13to1 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_13to1'))\n",
    "\n",
    "# DRV_Jan20160 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000000')\n",
    "# DRV_Jan20161 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000001')\n",
    "# DRV_Jan20162 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000002')\n",
    "\n",
    "# DRV_Jan2016 = pd.concat([DRV_Jan20160,DRV_Jan20161,DRV_Jan20162])\n",
    "\n",
    "# del DRV_Jan20160\n",
    "# del DRV_Jan20161\n",
    "# del DRV_Jan20162\n",
    "\n",
    "# # Import DRV_Feb2016 (Validation Set) \n",
    "# DRV_Feb20160 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000000')\n",
    "# DRV_Feb20161 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000001')\n",
    "# DRV_Feb20162 = read_data('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000002')\n",
    "\n",
    "# DRV_Feb2016 = pd.concat([DRV_Feb20160,DRV_Feb20161,DRV_Feb20162])\n",
    "\n",
    "# del DRV_Feb20160\n",
    "# del DRV_Feb20161\n",
    "# del DRV_Feb20162\n",
    "\n",
    "# # # Import DRV_Mar2016 (Test Set) \n",
    "# # DRV_Mar20160 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Mar2016000000000000')\n",
    "# # DRV_Mar20161 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Mar2016000000000001')\n",
    "# # DRV_Mar20162 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Mar2016000000000002')\n",
    "\n",
    "# # DRV_Mar2016 = DRV_Mar20160.union(DRV_Mar20161)\n",
    "# # DRV_Mar2016 = DRV_Mar2016.union(DRV_Mar20162)\n",
    "\n",
    "# # DRV_Mar2016 = DRV_Mar2016.toPandas()\n",
    "\n",
    "# # DRV_Mar20160 = None\n",
    "# # DRV_Mar20161 = None\n",
    "# # DRV_Mar20162 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Data Pre-Processing</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Split Feautres by Categorical or Continuous*</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Categorical feature names\n",
    "cat_feats = ['is_auto_renew', 'total_spent_zero', 'city_agg', 'payment_method_agg', 'never_active_subscriber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Initial Feature Selection*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all un-needed columns\n",
    "DRV_Jan2016 = DRV_Jan2016.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Feb2016 = DRV_Feb2016.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "\n",
    "DRV_Jan2016_1to1 = DRV_Jan2016_1to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Jan2016_3to1 = DRV_Jan2016_3to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Jan2016_5to1 = DRV_Jan2016_5to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Jan2016_7to1 = DRV_Jan2016_7to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Jan2016_9to1 = DRV_Jan2016_9to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Jan2016_11to1 = DRV_Jan2016_11to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)\n",
    "DRV_Jan2016_13to1 = DRV_Jan2016_13to1.drop(['msno', 'membership_expire_date', 'is_net_paid_amount', 'registration_init_time','registration_init_time',\n",
    "                          'city','bd','payment_method_id','registered_via'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Encode Categorical Variables*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoded all categoricals\n",
    "DRV_Jan2016 = pd.get_dummies(DRV_Jan2016, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Feb2016 = pd.get_dummies(DRV_Feb2016, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "\n",
    "DRV_Jan2016_1to1 = pd.get_dummies(DRV_Jan2016_1to1, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Jan2016_3to1 = pd.get_dummies(DRV_Jan2016_3to1, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Jan2016_5to1 = pd.get_dummies(DRV_Jan2016_5to1, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Jan2016_7to1 = pd.get_dummies(DRV_Jan2016_7to1, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Jan2016_9to1 = pd.get_dummies(DRV_Jan2016_9to1, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Jan2016_11to1 = pd.get_dummies(DRV_Jan2016_11to1, prefix=cat_feats, columns=cat_feats, drop_first=True)\n",
    "DRV_Jan2016_13to1 = pd.get_dummies(DRV_Jan2016_13to1, prefix=cat_feats, columns=cat_feats, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Feature Scaling*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Scaler Object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# # Scale Train and Validation Sets\n",
    "DRV_Jan2016_scaled = scaler.fit_transform(DRV_Jan2016.drop('is_churn', axis=1))\n",
    "DRV_Feb2016_scaled = scaler.fit_transform(DRV_Feb2016.drop('is_churn', axis=1))\n",
    "\n",
    "# Scale Split Sets\n",
    "DRV_Jan2016_1to1_scaled = scaler.fit_transform(DRV_Jan2016_1to1.drop('is_churn', axis=1))\n",
    "DRV_Jan2016_3to1_scaled = scaler.fit_transform(DRV_Jan2016_3to1.drop('is_churn', axis=1))\n",
    "DRV_Jan2016_5to1_scaled = scaler.fit_transform(DRV_Jan2016_5to1.drop('is_churn', axis=1))\n",
    "DRV_Jan2016_7to1_scaled = scaler.fit_transform(DRV_Jan2016_7to1.drop('is_churn', axis=1))\n",
    "DRV_Jan2016_9to1_scaled = scaler.fit_transform(DRV_Jan2016_9to1.drop('is_churn', axis=1))\n",
    "DRV_Jan2016_11to1_scaled = scaler.fit_transform(DRV_Jan2016_11to1.drop('is_churn', axis=1))\n",
    "DRV_Jan2016_13to1_scaled = scaler.fit_transform(DRV_Jan2016_13to1.drop('is_churn', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38013, 241)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRV_Jan2016_1to1_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264393, 241)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRV_Jan2016_13to1_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation: Pipeline and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Model Tuning</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>XGBOOST Parameter Tuning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Param Grid\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [.1, .075, .05, .025, .01],\n",
    "        'n_estimators': [100, 250, 500, 750, 1000]\n",
    "        }\n",
    "\n",
    "# Instatiate Esitmator Object\n",
    "xgb = XGBClassifier(objective='binary:logistic', n_jobs=1)\n",
    "\n",
    "# Instatiate StratKFold Object\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=4, shuffle = True)\n",
    "\n",
    "# # Instatiate Random Search CV Object\n",
    "# rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "#                                    n_jobs=4, cv=skf, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create Custom Evaluator***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator that we can use instead of BinaryClassificationEvaluator() in grid search\n",
    "class ClassEvaluatorPandas:\n",
    "\n",
    "    def __init__(self, modelname, model, y_pred, y_true):\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.modelname = modelname\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        self.model = model\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        self.cm = confusion_matrix(y_true,y_pred)\n",
    "        \n",
    "        # Calculate confusion matrix values\n",
    "        self.tp = self.cm[0][0]\n",
    "        self.fp = self.cm[0][1]\n",
    "        self.tn = self.cm[1][1]\n",
    "        self.fn = self.cm[1][0]\n",
    "        \n",
    "    def evaluate(self):\n",
    "        \n",
    "        # Calculate Metrics and add epsilon to prevent division by zero\n",
    "        precision = self.tp / float(self.tp + self.fp + 0.00001)\n",
    "        recall = self.tp / float(self.tp + self.fn + 0.00001)\n",
    "        f1 = (2 * precision * recall) / float(precision + recall + 0.00001)\n",
    "        error = (self.fp + self.fn + 0.00001) / (self.tp + self.fp + self.tn + self.fn + 0.00001)\n",
    "        \n",
    "        # Instantiate Evaluator and call AUC metric\n",
    "        from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "        \n",
    "        AUC = roc_auc_score(self.y_true, self.y_pred)\n",
    "        \n",
    "        return pd.DataFrame(data=[[self.modelname, AUC, f1, precision, recall, error]], \n",
    "                            columns=['modelname', 'AUC', 'f1', 'precision', 'recall', 'error'])\n",
    "    \n",
    "    def confusionmatrix(self):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Print Confusion Matrix\n",
    "        return self.cm\n",
    "        \n",
    "    \n",
    "    def modelparams(self):\n",
    "        scores = self.model.avgMetrics\n",
    "        params = [{p.name: v for p, v in m.items()} for m in self.model.getEstimatorParamMaps()]\n",
    "        params_pd = pd.DataFrame(params)\n",
    "        params_pd['AUC score'] = scores\n",
    "        return params_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Execution and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Train Model: All Splits, XGB + GridCV </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 13.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 13.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 919\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx1to1 = rscv.fit(DRV_Jan2016_1to1_scaled, DRV_Jan2016_1to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 22.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 22.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1785\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx3to1 = rscv.fit(DRV_Jan2016_3to1_scaled, DRV_Jan2016_3to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 27.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 27.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 2589\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx5to1 = rscv.fit(DRV_Jan2016_5to1_scaled, DRV_Jan2016_5to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "gbx5to1 = rscv.fit(DRV_Jan2016_5to1_scaled, DRV_Jan2016_5to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 58.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 58.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 4430\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx7to1 = rscv.fit(DRV_Jan2016_7to1_scaled, DRV_Jan2016_7to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 57.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 57.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 4427\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx9to1 = rscv.fit(DRV_Jan2016_9to1_scaled, DRV_Jan2016_9to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 90.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 90.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 6651\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx11to1 = rscv.fit(DRV_Jan2016_11to1_scaled, DRV_Jan2016_11to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 56.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed: 56.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 4487\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rscv = RandomizedSearchCV(xgb, param_distributions=params, n_iter=5, scoring='recall', \n",
    "                                   n_jobs=4, cv=skf, verbose=3)\n",
    "gbx13to1 = rscv.fit(DRV_Jan2016_13to1_scaled, DRV_Jan2016_13to1['is_churn'])\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "ensembles_created = {\n",
    "                  'gbx1to1' : gbx1to1,\n",
    "                  'gbx3to1' : gbx3to1,\n",
    "                  'gbx5to1' : gbx5to1,\n",
    "                  'gbx7to1' : gbx7to1,\n",
    "                  'gbx9to1' : gbx9to1,\n",
    "                  'gbx11to1' : gbx11to1,\n",
    "                  'gbx13to1' : gbx13to1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbx1to1\n",
      "[[534460 138291]\n",
      " [  1234  17914]]\n",
      "\n",
      "gbx3to1\n",
      "[[627870  44881]\n",
      " [  3792  15356]]\n",
      "\n",
      "gbx5to1\n",
      "[[635427  37324]\n",
      " [  3779  15369]]\n",
      "\n",
      "gbx7to1\n",
      "[[646655  26096]\n",
      " [  5331  13817]]\n",
      "\n",
      "gbx9to1\n",
      "[[650036  22715]\n",
      " [  5287  13861]]\n",
      "\n",
      "gbx11to1\n",
      "[[659452  13299]\n",
      " [  6680  12468]]\n",
      "\n",
      "gbx13to1\n",
      "[[668067   4684]\n",
      " [  9940   9208]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_all_results = pd.DataFrame()\n",
    "\n",
    "for model_name, model1 in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(DRV_Jan2016_scaled)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=DRV_Jan2016['is_churn'])\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_all_results = train_all_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx1to1</td>\n",
       "      <td>0.864997</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.794440</td>\n",
       "      <td>0.997696</td>\n",
       "      <td>0.201655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx3to1</td>\n",
       "      <td>0.867626</td>\n",
       "      <td>0.962681</td>\n",
       "      <td>0.933287</td>\n",
       "      <td>0.993997</td>\n",
       "      <td>0.070347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx5to1</td>\n",
       "      <td>0.873581</td>\n",
       "      <td>0.968665</td>\n",
       "      <td>0.944520</td>\n",
       "      <td>0.994088</td>\n",
       "      <td>0.059406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx7to1</td>\n",
       "      <td>0.841400</td>\n",
       "      <td>0.976272</td>\n",
       "      <td>0.961210</td>\n",
       "      <td>0.991823</td>\n",
       "      <td>0.045421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx9to1</td>\n",
       "      <td>0.845062</td>\n",
       "      <td>0.978910</td>\n",
       "      <td>0.966236</td>\n",
       "      <td>0.991932</td>\n",
       "      <td>0.040471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx11to1</td>\n",
       "      <td>0.815685</td>\n",
       "      <td>0.985073</td>\n",
       "      <td>0.980232</td>\n",
       "      <td>0.989972</td>\n",
       "      <td>0.028876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx13to1</td>\n",
       "      <td>0.736962</td>\n",
       "      <td>0.989168</td>\n",
       "      <td>0.993038</td>\n",
       "      <td>0.985339</td>\n",
       "      <td>0.021136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname       AUC        f1  precision    recall     error\n",
       "0   gbx1to1  0.864997  0.884537   0.794440  0.997696  0.201655\n",
       "0   gbx3to1  0.867626  0.962681   0.933287  0.993997  0.070347\n",
       "0   gbx5to1  0.873581  0.968665   0.944520  0.994088  0.059406\n",
       "0   gbx7to1  0.841400  0.976272   0.961210  0.991823  0.045421\n",
       "0   gbx9to1  0.845062  0.978910   0.966236  0.991932  0.040471\n",
       "0  gbx11to1  0.815685  0.985073   0.980232  0.989972  0.028876\n",
       "0  gbx13to1  0.736962  0.989168   0.993038  0.985339  0.021136"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbx1to1\n",
      "[[418953 109251]\n",
      " [  1504  18419]]\n",
      "\n",
      "gbx3to1\n",
      "[[494368  33836]\n",
      " [  5497  14426]]\n",
      "\n",
      "gbx5to1\n",
      "[[504021  24183]\n",
      " [  6711  13212]]\n",
      "\n",
      "gbx7to1\n",
      "[[514751  13453]\n",
      " [  9418  10505]]\n",
      "\n",
      "gbx9to1\n",
      "[[518019  10185]\n",
      " [ 10202   9721]]\n",
      "\n",
      "gbx11to1\n",
      "[[518417   9787]\n",
      " [ 10587   9336]]\n",
      "\n",
      "gbx13to1\n",
      "[[524023   4181]\n",
      " [ 13505   6418]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_all_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(DRV_Feb2016_scaled)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=DRV_Feb2016['is_churn'])\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_all_results = validation_all_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx1to1</td>\n",
       "      <td>0.858837</td>\n",
       "      <td>0.883246</td>\n",
       "      <td>0.793165</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.202061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx3to1</td>\n",
       "      <td>0.830015</td>\n",
       "      <td>0.961736</td>\n",
       "      <td>0.935941</td>\n",
       "      <td>0.989003</td>\n",
       "      <td>0.071759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx5to1</td>\n",
       "      <td>0.808685</td>\n",
       "      <td>0.970259</td>\n",
       "      <td>0.954217</td>\n",
       "      <td>0.986860</td>\n",
       "      <td>0.056363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx7to1</td>\n",
       "      <td>0.750905</td>\n",
       "      <td>0.978262</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.041726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx9to1</td>\n",
       "      <td>0.734323</td>\n",
       "      <td>0.980697</td>\n",
       "      <td>0.980718</td>\n",
       "      <td>0.980686</td>\n",
       "      <td>0.037194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx11to1</td>\n",
       "      <td>0.725038</td>\n",
       "      <td>0.980723</td>\n",
       "      <td>0.981471</td>\n",
       "      <td>0.979987</td>\n",
       "      <td>0.037170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx13to1</td>\n",
       "      <td>0.657112</td>\n",
       "      <td>0.983400</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.974876</td>\n",
       "      <td>0.032266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname       AUC        f1  precision    recall     error\n",
       "0   gbx1to1  0.858837  0.883246   0.793165  0.996423  0.202061\n",
       "0   gbx3to1  0.830015  0.961736   0.935941  0.989003  0.071759\n",
       "0   gbx5to1  0.808685  0.970259   0.954217  0.986860  0.056363\n",
       "0   gbx7to1  0.750905  0.978262   0.974531  0.982033  0.041726\n",
       "0   gbx9to1  0.734323  0.980697   0.980718  0.980686  0.037194\n",
       "0  gbx11to1  0.725038  0.980723   0.981471  0.979987  0.037170\n",
       "0  gbx13to1  0.657112  0.983400   0.992084  0.974876  0.032266"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>gbx1to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.037611</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>-0.002654</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>-0.001412</td>\n",
       "      <td>gbx3to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064897</td>\n",
       "      <td>-0.001593</td>\n",
       "      <td>-0.009696</td>\n",
       "      <td>0.007228</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>gbx5to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.079849</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>-0.011130</td>\n",
       "      <td>gbx13to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>-0.001990</td>\n",
       "      <td>-0.013321</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>gbx7to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.090648</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>-0.008295</td>\n",
       "      <td>gbx11to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.110739</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>-0.014482</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>gbx9to1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error modelname\n",
       "0  0.006160  0.001290   0.001274  0.001274 -0.000406   gbx1to1\n",
       "0  0.037611  0.000945  -0.002654  0.004994 -0.001412   gbx3to1\n",
       "0  0.064897 -0.001593  -0.009696  0.007228  0.003043   gbx5to1\n",
       "0  0.079849  0.005769   0.000953  0.010464 -0.011130  gbx13to1\n",
       "0  0.090495 -0.001990  -0.013321  0.009791  0.003696   gbx7to1\n",
       "0  0.090648  0.004349  -0.001239  0.009985 -0.008295  gbx11to1\n",
       "0  0.110739 -0.001787  -0.014482  0.011246  0.003277   gbx9to1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_all_results[train_all_results.columns[1:]] - validation_all_results[validation_all_results.columns[1:]]\n",
    "results_all['modelname'] = train_all_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### - <font color=blue>Test Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbx1to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n",
      "gbx3to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n",
      "gbx5to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n",
      "gbx7to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n",
      "gbx9to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n",
      "gbx11to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n",
      "gbx13to1\n",
      "[[680492  14262]\n",
      " [ 15022  11956]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "test_all_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, (model1, sub_samp, sub_results, estimator) in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(DRV_Fe2016_scaled)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=DRV_Mar2016['is_churn'])\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    test_all_results = test_all_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx1to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx3to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx5to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx7to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx9to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx11to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gbx13to1</td>\n",
       "      <td>0.71132</td>\n",
       "      <td>0.978931</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.978402</td>\n",
       "      <td>0.040575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname      AUC        f1  precision    recall     error\n",
       "0   gbx1to1  0.71132  0.978931   0.979472  0.978402  0.040575\n",
       "0   gbx3to1  0.71132  0.978931   0.979472  0.978402  0.040575\n",
       "0   gbx5to1  0.71132  0.978931   0.979472  0.978402  0.040575\n",
       "0   gbx7to1  0.71132  0.978931   0.979472  0.978402  0.040575\n",
       "0   gbx9to1  0.71132  0.978931   0.979472  0.978402  0.040575\n",
       "0  gbx11to1  0.71132  0.978931   0.979472  0.978402  0.040575\n",
       "0  gbx13to1  0.71132  0.978931   0.979472  0.978402  0.040575"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### <font color=purple>Generalization Between Validation and Test</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx1to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx3to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx5to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx7to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx9to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx11to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>gbx13to1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error modelname\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304   gbx1to1\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304   gbx3to1\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304   gbx5to1\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304   gbx7to1\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304   gbx9to1\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304  gbx11to1\n",
       "0  0.00766  0.002277   0.003444  0.001115 -0.004304  gbx13to1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = validation_all_results[train_all_results.columns[1:]] - test_all_results[validation_all_results.columns[1:]]\n",
    "results_all['modelname'] = validation_all_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
