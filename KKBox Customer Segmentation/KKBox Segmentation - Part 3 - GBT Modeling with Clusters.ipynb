{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KKBox Customer Churn Prediction\n",
    "### w/ BigQuery and Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: <font color=green>*Model Creation and Evaluation*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "from __future__ import absolute_import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports for PySpark\n",
    "import findspark\n",
    "findspark.init('C:\\spark\\spark-2.4.4-bin-hadoop2.7')\n",
    "# import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# # Imports for BigQuery connection\n",
    "# import json\n",
    "# import pprint\n",
    "# import subprocess\n",
    "\n",
    "# # Imports for GCP\n",
    "# from google.cloud import bigquery\n",
    "import time \n",
    "# import gcsfs\n",
    "\n",
    "# Imports for Spark ML\n",
    "from pyspark.ml.feature import (VectorAssembler,StandardScaler, OneHotEncoderEstimator, OneHotEncoder)\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, Evaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataproc Specs\n",
    "\n",
    "# Jupyter Initialization: gs://srcd-dataproc/jupyter.sh \n",
    "# Components Installed: Anaconda and Jupyter\n",
    "# Master Node:   x1 - 4 vCPU w/ 15 GB RAM each\n",
    "# Workers Nodes: x5 - 4 vCPU w/ 15 GB RAM each\n",
    "# Disk: 100GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session and Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Google Credentials\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='D:\\OneDrive\\J-5\\GitHub\\Google Credentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.Builder().config(conf=SparkConf().setMaster(\"local[*]\")).getOrCreate()\n",
    "\n",
    "# Instantiate BigQuery magic\n",
    "# %load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Working Locally on Computer, Importing Data Locally#\n",
    "\n",
    "# Import DRV_Jan2016 (Train Set) \n",
    "DRV_Jan2016_1to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_1to1_clust',inferSchema=True,header=True)\n",
    "DRV_Jan2016_3to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_3to1_clust',inferSchema=True,header=True)\n",
    "DRV_Jan2016_5to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_5to1_clust',inferSchema=True,header=True)\n",
    "DRV_Jan2016_7to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_7to1_clust',inferSchema=True,header=True)\n",
    "DRV_Jan2016_9to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_9to1_clust',inferSchema=True,header=True)\n",
    "DRV_Jan2016_11to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_11to1_clust',inferSchema=True,header=True)\n",
    "DRV_Jan2016_13to1 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_13to1_clust',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Jan2016 = spark.read.csv('D:\\J-5 Local\\DRV_Jan2016_With_Cluster',inferSchema=True,header=True)\n",
    "\n",
    "# Import DRV_Feb2016 (Validation Set) \n",
    "DRV_Feb2016 = spark.read.csv('D:\\J-5 Local\\DRV_Feb2016_With_Cluster',inferSchema=True,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ## If Working Locally on Computer, Importing Data from GCS ##\n",
    "\n",
    "# # Import DRV_Jan2016 (Train Set) from Google Cloud Storage via Pandas\n",
    "# DRV_Jan2016_Balanced_1 = spark.createDataFrame(pd.read_csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_Balanced_1'))\n",
    "# DRV_Jan2016_Balanced_2 = spark.createDataFrame(pd.read_csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_Balanced_2'))\n",
    "# DRV_Jan2016_Balanced_3 = spark.createDataFrame(pd.read_csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_Balanced_3'))\n",
    "\n",
    "# # Import DRV_Feb2016 (Validation Set) from Google Cloud Storage via Pandas\n",
    "# DRV_Feb2016 = spark.createDataFrame(pd.read_csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016'))\n",
    "\n",
    "# # Import DRV_Mar2016 (Test Set) from Google Cloud Storage via Pandas\n",
    "# DRV_Mar2016 = spark.createDataFrame(pd.read_csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Mar2016'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Working on Dataproc Cloud ##\n",
    "\n",
    "# Import DRV_Jan2016 (Train Set) \n",
    "DRV_Jan2016_1to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_1to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_3to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_3to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_5to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_5to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_7to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_7to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_9to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_9to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_11to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_11to1',inferSchema=True,header=True)\n",
    "DRV_Jan2016_13to1 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016_13to1',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Jan20160 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000000',inferSchema=True,header=True)\n",
    "DRV_Jan20161 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000001',inferSchema=True,header=True)\n",
    "DRV_Jan20162 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Jan2016000000000002',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Jan2016 = DRV_Jan20160.union(DRV_Jan20161)\n",
    "DRV_Jan2016 = DRV_Jan2016.union(DRV_Jan20162)\n",
    "\n",
    "DRV_Jan20160 = None\n",
    "DRV_Jan20161 = None\n",
    "DRV_Jan20162 = None\n",
    "\n",
    "# Import DRV_Feb2016 (Validation Set) \n",
    "DRV_Feb20160 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000000',inferSchema=True,header=True)\n",
    "DRV_Feb20161 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000001',inferSchema=True,header=True)\n",
    "DRV_Feb20162 = spark.read.csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Monthly Datasets/DRV_Feb2016000000000002',inferSchema=True,header=True)\n",
    "\n",
    "DRV_Feb2016 = DRV_Feb20160.union(DRV_Feb20161)\n",
    "DRV_Feb2016 = DRV_Feb2016.union(DRV_Feb20162)\n",
    "\n",
    "DRV_Feb20160 = None\n",
    "DRV_Feb20161 = None\n",
    "DRV_Feb20162 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cast Correct Column Types on All Sets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "column_types_pd = [('msno', 'STRING'),\n",
    " ('membership_expire_date', 'DATE'),\n",
    " ('payment_method_id', 'INT64'),\n",
    " ('payment_plan_days', 'INT64'),\n",
    " ('plan_list_price', 'INT64'),\n",
    " ('net_paid_amount', 'INT64'),\n",
    " ('is_net_paid_amount', 'STRING'),\n",
    " ('is_auto_renew', 'INT64'),\n",
    " ('city', 'INT64'),\n",
    " ('bd', 'INT64'),\n",
    " ('registered_via', 'INT64'),\n",
    " ('registration_init_time', 'DATE'),\n",
    " ('membership_length', 'INT64'),\n",
    " ('is_churn', 'FLOAT64'),\n",
    " ('total_songs', 'INT64'),\n",
    " ('total_logins', 'INT64'),\n",
    " ('total_secs', 'FLOAT64'),\n",
    " ('sum_num_unq', 'INT64'),\n",
    " ('sum_num_repeat', 'INT64'),\n",
    " ('sum_over_50pec', 'INT64'),\n",
    " ('sum_over_75pec', 'INT64'),\n",
    " ('sum_over_985pec', 'INT64'),\n",
    " ('total_transactions', 'INT64'),\n",
    " ('total_spent', 'FLOAT64'),\n",
    " ('avg_spent_trans', 'FLOAT64'),\n",
    " ('spent_per_logins', 'FLOAT64'),\n",
    " ('spent_per_secs', 'FLOAT64'),\n",
    " ('spent_per_song', 'FLOAT64'),\n",
    " ('spent_per_num_unq', 'FLOAT64'),\n",
    " ('spent_per_num_repeats', 'FLOAT64'),\n",
    " ('never_active_subscriber', 'FLOAT64'),\n",
    " ('total_spent_zero', 'FLOAT64'),\n",
    " ('city_agg', 'INT64'),\n",
    " ('payment_method_agg', 'INT64'),\n",
    " ('songs_last_7', 'FLOAT64'),\n",
    " ('songs_last_7_AVG', 'FLOAT64'),\n",
    " ('logins_last_7', 'FLOAT64'),\n",
    " ('logins_last_7_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_7', 'FLOAT64'),\n",
    " ('total_secs_last_7_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_7', 'FLOAT64'),\n",
    " ('num_unq_last_7_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_7', 'FLOAT64'),\n",
    " ('num_repeat_last_7_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_7', 'FLOAT64'),\n",
    " ('over_50perc_last_7_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_7', 'FLOAT64'),\n",
    " ('over_75perc_last_7_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_7', 'FLOAT64'),\n",
    " ('over_985perc_last_7_AVG', 'FLOAT64'),\n",
    " ('songs_last_15', 'FLOAT64'),\n",
    " ('songs_last_15_AVG', 'FLOAT64'),\n",
    " ('logins_last_15', 'FLOAT64'),\n",
    " ('logins_last_15_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_15', 'FLOAT64'),\n",
    " ('total_secs_last_15_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_15', 'FLOAT64'),\n",
    " ('num_unq_last_15_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_15', 'FLOAT64'),\n",
    " ('num_repeat_last_15_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_15', 'FLOAT64'),\n",
    " ('over_50perc_last_15_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_15', 'FLOAT64'),\n",
    " ('over_75perc_last_15_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_15', 'FLOAT64'),\n",
    " ('over_985perc_last_15_AVG', 'FLOAT64'),\n",
    " ('songs_last_30', 'FLOAT64'),\n",
    " ('songs_last_30_AVG', 'FLOAT64'),\n",
    " ('logins_last_30', 'FLOAT64'),\n",
    " ('logins_last_30_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_30', 'FLOAT64'),\n",
    " ('total_secs_last_30_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_30', 'FLOAT64'),\n",
    " ('num_unq_last_30_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_30', 'FLOAT64'),\n",
    " ('num_repeat_last_30_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_30', 'FLOAT64'),\n",
    " ('over_50perc_last_30_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_30', 'FLOAT64'),\n",
    " ('over_75perc_last_30_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_30', 'FLOAT64'),\n",
    " ('over_985perc_last_30_AVG', 'FLOAT64'),\n",
    " ('songs_last_60', 'FLOAT64'),\n",
    " ('songs_last_60_AVG', 'FLOAT64'),\n",
    " ('logins_last_60', 'FLOAT64'),\n",
    " ('logins_last_60_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_60', 'FLOAT64'),\n",
    " ('total_secs_last_60_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_60', 'FLOAT64'),\n",
    " ('num_unq_last_60_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_60', 'FLOAT64'),\n",
    " ('num_repeat_last_60_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_60', 'FLOAT64'),\n",
    " ('over_50perc_last_60_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_60', 'FLOAT64'),\n",
    " ('over_75perc_last_60_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_60', 'FLOAT64'),\n",
    " ('over_985perc_last_60_AVG', 'FLOAT64'),\n",
    " ('songs_last_120', 'FLOAT64'),\n",
    " ('songs_last_120_AVG', 'FLOAT64'),\n",
    " ('logins_last_120', 'FLOAT64'),\n",
    " ('logins_last_120_AVG', 'FLOAT64'),\n",
    " ('total_secs_last_120', 'FLOAT64'),\n",
    " ('total_secs_last_120_AVG', 'FLOAT64'),\n",
    " ('num_unq_last_120', 'FLOAT64'),\n",
    " ('num_unq_last_120_AVG', 'FLOAT64'),\n",
    " ('num_repeat_last_120', 'FLOAT64'),\n",
    " ('num_repeat_last_120_AVG', 'FLOAT64'),\n",
    " ('over_50perc_last_120', 'FLOAT64'),\n",
    " ('over_50perc_last_120_AVG', 'FLOAT64'),\n",
    " ('over_75perc_last_120', 'FLOAT64'),\n",
    " ('over_75perc_last_120_AVG', 'FLOAT64'),\n",
    " ('over_985perc_last_120', 'FLOAT64'),\n",
    " ('over_985perc_last_120_AVG', 'FLOAT64'),\n",
    " ('SUM_unq_songs_0_15', 'FLOAT64'),\n",
    " ('AVG_unq_songs_0_15', 'FLOAT64'),\n",
    " ('SUM_songs_0_15', 'FLOAT64'),\n",
    " ('AVG_songs_0_15', 'FLOAT64'),\n",
    " ('SUM_secs_0_15', 'FLOAT64'),\n",
    " ('AVG_secs_0_15', 'FLOAT64'),\n",
    " ('SUM_songs50_0_15', 'FLOAT64'),\n",
    " ('AVG_songs50_0_15', 'FLOAT64'),\n",
    " ('SUM_logins_0_15', 'FLOAT64'),\n",
    " ('AVG_logins_0_15', 'FLOAT64'),\n",
    " ('SUM_repeats_0_15', 'FLOAT64'),\n",
    " ('AVG_repeats_0_15', 'FLOAT64'),\n",
    " ('SUM_unq_songs_15_30', 'FLOAT64'),\n",
    " ('AVG_unq_songs_15_30', 'FLOAT64'),\n",
    " ('SUM_songs_15_30', 'FLOAT64'),\n",
    " ('AVG_songs_15_30', 'FLOAT64'),\n",
    " ('SUM_secs_15_30', 'FLOAT64'),\n",
    " ('AVG_secs_15_30', 'FLOAT64'),\n",
    " ('SUM_songs50_15_30', 'FLOAT64'),\n",
    " ('AVG_songs50_15_30', 'FLOAT64'),\n",
    " ('SUM_logins_15_30', 'FLOAT64'),\n",
    " ('AVG_logins_15_30', 'FLOAT64'),\n",
    " ('SUM_repeats_15_30', 'FLOAT64'),\n",
    " ('AVG_repeats_15_30', 'FLOAT64'),\n",
    " ('SUM_unq_songs_30_45', 'FLOAT64'),\n",
    " ('AVG_unq_songs_30_45', 'FLOAT64'),\n",
    " ('SUM_songs_30_45', 'FLOAT64'),\n",
    " ('AVG_songs_30_45', 'FLOAT64'),\n",
    " ('SUM_secs_30_45', 'FLOAT64'),\n",
    " ('AVG_secs_30_45', 'FLOAT64'),\n",
    " ('SUM_songs50_30_45', 'FLOAT64'),\n",
    " ('AVG_songs50_30_45', 'FLOAT64'),\n",
    " ('SUM_logins_30_45', 'FLOAT64'),\n",
    " ('AVG_logins_30_45', 'FLOAT64'),\n",
    " ('SUM_repeats_30_45', 'FLOAT64'),\n",
    " ('AVG_repeats_30_45', 'FLOAT64'),\n",
    " ('SUM_unq_songs_45_60', 'FLOAT64'),\n",
    " ('AVG_unq_songs_45_60', 'FLOAT64'),\n",
    " ('SUM_songs_45_60', 'FLOAT64'),\n",
    " ('AVG_songs_45_60', 'FLOAT64'),\n",
    " ('SUM_secs_45_60', 'FLOAT64'),\n",
    " ('AVG_secs_45_60', 'FLOAT64'),\n",
    " ('SUM_songs50_45_60', 'FLOAT64'),\n",
    " ('AVG_songs50_45_60', 'FLOAT64'),\n",
    " ('SUM_logins_45_60', 'FLOAT64'),\n",
    " ('AVG_logins_45_60', 'FLOAT64'),\n",
    " ('SUM_repeats_45_60', 'FLOAT64'),\n",
    " ('AVG_repeats_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_unq_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_unq_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_secs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_secs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_songs50_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_songs50_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_logins_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_logins_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_repeats_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFAVG_repeats_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSUM_unq_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_unq_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_secs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_secs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_songs50_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_songs50_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_logins_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_logins_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_repeats_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFAVG_repeats_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSUM_unq_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_unq_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_secs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_secs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_songs50_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_songs50_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_logins_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_logins_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSUM_repeats_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFAVG_repeats_30_45_45_60', 'FLOAT64'),\n",
    " ('expire_last_login', 'INT64'),\n",
    " ('total_cancelations', 'INT64'),\n",
    " ('login_after_expire_10', 'INT64'),\n",
    " ('login_after_expire_20', 'INT64'),\n",
    " ('login_after_expire_30', 'INT64'),\n",
    " ('STD_unq_songs_0_15', 'FLOAT64'),\n",
    " ('STD_songs_0_15', 'FLOAT64'),\n",
    " ('STD_secs_0_15', 'FLOAT64'),\n",
    " ('STD_songs50_0_15', 'FLOAT64'),\n",
    " ('STD_repeats_0_15', 'FLOAT64'),\n",
    " ('STD_unq_songs_15_30', 'FLOAT64'),\n",
    " ('STD_songs_15_30', 'FLOAT64'),\n",
    " ('STD_secs_15_30', 'FLOAT64'),\n",
    " ('STD_songs50_15_30', 'FLOAT64'),\n",
    " ('STD_repeats_15_30', 'FLOAT64'),\n",
    " ('STD_unq_songs_30_45', 'FLOAT64'),\n",
    " ('STD_songs_30_45', 'FLOAT64'),\n",
    " ('STD_secs_30_45', 'FLOAT64'),\n",
    " ('STD_songs50_30_45', 'FLOAT64'),\n",
    " ('STD_repeats_30_45', 'FLOAT64'),\n",
    " ('STD_unq_songs_45_60', 'FLOAT64'),\n",
    " ('STD_songs_45_60', 'FLOAT64'),\n",
    " ('STD_secs_45_60', 'FLOAT64'),\n",
    " ('STD_songs50_45_60', 'FLOAT64'),\n",
    " ('STD_repeats_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_unq_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_songs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_secs_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_songs50_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_repeats_0_15_15_30', 'FLOAT64'),\n",
    " ('DIFSTD_unq_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_songs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_secs_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_songs50_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_repeats_15_30_30_45', 'FLOAT64'),\n",
    " ('DIFSTD_unq_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_songs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_secs_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_songs50_30_45_45_60', 'FLOAT64'),\n",
    " ('DIFSTD_repeats_30_45_45_60', 'FLOAT64'),\n",
    " ('is_cancel', 'INT64')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Correctly Cast DRV_Feb2016\n",
    "for feature, datatype in column_types_pd:\n",
    "    if datatype == 'STRING':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS string)\"))')\n",
    "    if datatype == 'DATE':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS timestamp)\"))')\n",
    "    if datatype == 'INT64':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS integer)\"))')\n",
    "    if datatype == 'FLOAT64':\n",
    "        exec(f'DRV_Jan2016_1to1 = DRV_Feb2016.withColumn(\"{feature}\", expr(\"CAST({feature} AS double)\"))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pre-Processing\n",
    "https://medium.com/@dhiraj.p.rai/essentials-of-feature-engineering-in-pyspark-part-i-76a57680a85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Split Feautres by Categorical or Continuous</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Categorical feature names\n",
    "cat_feats = ['is_auto_renew', 'total_spent_zero', 'city_agg', 'payment_method_agg', 'never_active_subscriber', 'Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of Continuous feature names\n",
    "cont_feats = [x for x in DRV_Jan2016_1to1.columns if x not in cat_feats]\n",
    "cont_feats.remove('msno')\n",
    "cont_feats.remove('is_churn')\n",
    "cont_feats.remove('membership_expire_date')\n",
    "cont_feats.remove('registration_init_time')\n",
    "cont_feats.remove('city')\n",
    "cont_feats.remove('bd')\n",
    "cont_feats.remove('payment_method_id')\n",
    "cont_feats.remove('is_net_paid_amount')\n",
    "cont_feats.remove('registered_via')\n",
    "cont_feats.remove('_c0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Data Pre-Processing</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Encode Categorical Variables*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical, 'Vector' feature names\n",
    "cat_feats_vec = ['is_auto_renew_vec', 'total_spent_zero_vec', 'city_agg_vec', \n",
    "                 'payment_method_agg_vec', 'never_active_subscriber_vec', 'Cluster_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "\n",
    "is_auto_renew_encoder = OneHotEncoder(inputCol='is_auto_renew',outputCol='is_auto_renew_vec')\n",
    "total_spent_zero_encoder = OneHotEncoder(inputCol='total_spent_zero',outputCol='total_spent_zero_vec')\n",
    "city_agg_encoder = OneHotEncoder(inputCol='city_agg',outputCol='city_agg_vec')\n",
    "payment_method_agg_encoder = OneHotEncoder(inputCol='payment_method_agg',outputCol='payment_method_agg_vec')\n",
    "never_active_subscriber_encoder = OneHotEncoder(inputCol='never_active_subscriber',outputCol='never_active_subscriber_vec')\n",
    "clueter_encoder = OneHotEncoder(inputCol='Cluster',outputCol='Cluster_vec')\n",
    "# is_net_paid_amount_encoder = OneHotEncoder(inputCol='is_net_paid_amount',outputCol='is_net_paid_amount_vec')\n",
    "\n",
    "# registered_via_encoder = OneHotEncoder(inputCol='registered_via',outputCol='registered_via_vec')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Vector Assembler*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = cont_feats + cat_feats_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>*Feature Scaling*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale all features into our final output features\n",
    "scaler = StandardScaler(inputCol='features', \n",
    "                        outputCol='features_scaled',\n",
    "                        withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation: Pipeline and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Create Pipeline Object</font> -\n",
    "https://spark.apache.org/docs/2.4.3/ml-pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate Model Estimators and Parameters\n",
    "gbt = GBTClassifier(featuresCol='features_scaled',\n",
    "                    labelCol='is_churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            clueter_encoder,assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Model Tuning</font> -\n",
    "https://spark.apache.org/docs/2.4.3/ml-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_evaluator = BinaryClassificationEvaluator(labelCol='is_churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Gradient Boosted Trees Parameter Tuning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Execution and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: All Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 285\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to1 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 333\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to1 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 384\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to1 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 455\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to1 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 613\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to1 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 801\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to1 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1015\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to1 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Evaluate Trained Model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create Custom Evaluator***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator that we can use instead of BinaryClassificationEvaluator() in grid search\n",
    "class ClassEvaluator:\n",
    "\n",
    "    def __init__(self, resultname, resultdata, model):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Initialize variables\n",
    "        self.resultPandas = resultdata[['is_churn', 'prediction']].toPandas()\n",
    "        self.resultdata = resultdata \n",
    "        self.resultname = resultname\n",
    "        self.model = model\n",
    "        \n",
    "        self.cm = confusion_matrix(self.resultPandas['is_churn'],self.resultPandas['prediction'])\n",
    "        \n",
    "        # Calculate confusion matrix values\n",
    "        self.tp = self.cm[0][0]\n",
    "        self.fp = self.cm[0][1]\n",
    "        self.tn = self.cm[1][1]\n",
    "        self.fn = self.cm[1][0]\n",
    "        \n",
    "    def evaluate(self):\n",
    "        # Calculate Metrics and add epsilon to prevent division by zero\n",
    "        precision = self.tp / float(self.tp + self.fp + 0.00001)\n",
    "        recall = self.tp / float(self.tp + self.fn + 0.00001)\n",
    "        f1 = (2 * precision * recall) / float(precision + recall + 0.00001)\n",
    "        error = (self.fp + self.fn + 0.00001) / (self.tp + self.fp + self.tn + self.fn + 0.00001)\n",
    "        \n",
    "        # Instantiate Evaluator and call AUC metric\n",
    "        my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                                labelCol='is_churn')\n",
    "        AUC = my_eval.evaluate(self.resultdata)\n",
    "        \n",
    "        \n",
    "        return pd.DataFrame(data=[[self.resultname, AUC, f1, precision, recall, error]], \n",
    "                            columns=['resultname', 'AUC', 'f1', 'precision', 'recall', 'error'])\n",
    "    \n",
    "    def confusionmatrix(self):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Print Confusion Matrix\n",
    "        return self.cm\n",
    "        \n",
    "    \n",
    "    def modelparams(self):\n",
    "        scores = self.model.avgMetrics\n",
    "        params = [{p.name: v for p, v in m.items()} for m in self.model.getEstimatorParamMaps()]\n",
    "        params_pd = pd.DataFrame(params)\n",
    "        params_pd['AUC score'] = scores\n",
    "        return params_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: All Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transform Train Data on Trained Models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created = {\n",
    "                  'gbt_model_1to1' : (gbt_model_1to1, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to1' : (gbt_model_3to1, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to1' : (gbt_model_5to1, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to1' : (gbt_model_7to1, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to1' : (gbt_model_9to1, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to1' : (gbt_model_11to1, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to1' : (gbt_model_13to1, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to1\n",
      "[[589237  83514]\n",
      " [  1943  17205]]\n",
      " \n",
      "gbt_model_3to1\n",
      "[[634127  38624]\n",
      " [  4063  15085]]\n",
      " \n",
      "gbt_model_5to1\n",
      "[[648451  24300]\n",
      " [  5649  13499]]\n",
      " \n",
      "gbt_model_7to1\n",
      "[[655955  16796]\n",
      " [  7050  12098]]\n",
      " \n",
      "gbt_model_9to1\n",
      "[[659533  13218]\n",
      " [  7639  11509]]\n",
      " \n",
      "gbt_model_11to1\n",
      "[[662619  10132]\n",
      " [  8402  10746]]\n",
      " \n",
      "gbt_model_13to1\n",
      "[[664652   8099]\n",
      " [  9080  10068]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_resultsall = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_resultsall = train_resultsall.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1</td>\n",
       "      <td>0.887195</td>\n",
       "      <td>0.932383</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>0.123511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1</td>\n",
       "      <td>0.865199</td>\n",
       "      <td>0.967433</td>\n",
       "      <td>0.942588</td>\n",
       "      <td>0.993634</td>\n",
       "      <td>0.061695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1</td>\n",
       "      <td>0.834431</td>\n",
       "      <td>0.977424</td>\n",
       "      <td>0.963880</td>\n",
       "      <td>0.991364</td>\n",
       "      <td>0.043285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.975034</td>\n",
       "      <td>0.989367</td>\n",
       "      <td>0.034465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1</td>\n",
       "      <td>0.790704</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.030145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1</td>\n",
       "      <td>0.773073</td>\n",
       "      <td>0.986202</td>\n",
       "      <td>0.984939</td>\n",
       "      <td>0.987479</td>\n",
       "      <td>0.026787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1</td>\n",
       "      <td>0.756880</td>\n",
       "      <td>0.987237</td>\n",
       "      <td>0.987961</td>\n",
       "      <td>0.986523</td>\n",
       "      <td>0.024829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to1  0.887195  0.932383   0.875862  0.996713  0.123511\n",
       "0   gbt_model_3to1  0.865199  0.967433   0.942588  0.993634  0.061695\n",
       "0   gbt_model_5to1  0.834431  0.977424   0.963880  0.991364  0.043285\n",
       "0   gbt_model_7to1  0.803425  0.982143   0.975034  0.989367  0.034465\n",
       "0   gbt_model_9to1  0.790704  0.984429   0.980352  0.988550  0.030145\n",
       "0  gbt_model_11to1  0.773073  0.986202   0.984939  0.987479  0.026787\n",
       "0  gbt_model_13to1  0.756880  0.987237   0.987961  0.986523  0.024829"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_resultsall.sort_values('AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: All Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to1\n",
      "[[450285  77919]\n",
      " [  2476  17447]]\n",
      " \n",
      "gbt_model_3to1\n",
      "[[493859  34345]\n",
      " [  5259  14664]]\n",
      " \n",
      "gbt_model_5to1\n",
      "[[507065  21139]\n",
      " [  7330  12593]]\n",
      " \n",
      "gbt_model_7to1\n",
      "[[513140  15064]\n",
      " [  9005  10918]]\n",
      " \n",
      "gbt_model_9to1\n",
      "[[516137  12067]\n",
      " [  9909  10014]]\n",
      " \n",
      "gbt_model_11to1\n",
      "[[518683   9521]\n",
      " [ 10788   9135]]\n",
      " \n",
      "gbt_model_13to1\n",
      "[[520483   7721]\n",
      " [ 11560   8363]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_resultsall = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_resultsall = validation_resultsall.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1</td>\n",
       "      <td>0.864102</td>\n",
       "      <td>0.918040</td>\n",
       "      <td>0.852483</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>0.146672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1</td>\n",
       "      <td>0.835506</td>\n",
       "      <td>0.961444</td>\n",
       "      <td>0.934978</td>\n",
       "      <td>0.989463</td>\n",
       "      <td>0.072253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1</td>\n",
       "      <td>0.796031</td>\n",
       "      <td>0.972689</td>\n",
       "      <td>0.959979</td>\n",
       "      <td>0.985750</td>\n",
       "      <td>0.051939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1</td>\n",
       "      <td>0.759745</td>\n",
       "      <td>0.977080</td>\n",
       "      <td>0.971481</td>\n",
       "      <td>0.982754</td>\n",
       "      <td>0.043911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1</td>\n",
       "      <td>0.739895</td>\n",
       "      <td>0.979150</td>\n",
       "      <td>0.977155</td>\n",
       "      <td>0.981163</td>\n",
       "      <td>0.040093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1</td>\n",
       "      <td>0.720245</td>\n",
       "      <td>0.980793</td>\n",
       "      <td>0.981975</td>\n",
       "      <td>0.979625</td>\n",
       "      <td>0.037052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1</td>\n",
       "      <td>0.702574</td>\n",
       "      <td>0.981810</td>\n",
       "      <td>0.985383</td>\n",
       "      <td>0.978272</td>\n",
       "      <td>0.035176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to1  0.864102  0.918040   0.852483  0.994531  0.146672\n",
       "0   gbt_model_3to1  0.835506  0.961444   0.934978  0.989463  0.072253\n",
       "0   gbt_model_5to1  0.796031  0.972689   0.959979  0.985750  0.051939\n",
       "0   gbt_model_7to1  0.759745  0.977080   0.971481  0.982754  0.043911\n",
       "0   gbt_model_9to1  0.739895  0.979150   0.977155  0.981163  0.040093\n",
       "0  gbt_model_11to1  0.720245  0.980793   0.981975  0.979625  0.037052\n",
       "0  gbt_model_13to1  0.702574  0.981810   0.985383  0.978272  0.035176"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_resultsall.sort_values('AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now currently have ~230 Features with the inclusion of our *Bi-Weekly Activity Block* and *Comparison of Bi-Weekly Activity Block Features*. Looking at the results above we can see that we have made some improvements on AUC. We also notice how Recall increased significantly over the Ratio'd subsets. The ratio'd subsets seemed to have helped address the issue of having a high amount of False Positives.\n",
    "\n",
    "We can see that our models are still overfitting with the higher ratio'd models being the worst. However our Precision scores are better over our higher ratio'd models along with an improvement in model error and a slight decrease in Recall. Each of these models have there pros and cons and we might benefit from some sort of ensemble of these models. Before we do such a thing let's play around a bit with feature selection to see if we improve on the overall generalization between our Train and Validation models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxIter</th>\n",
       "      <th>maxDepth</th>\n",
       "      <th>minInstancesPerNode</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954903</td>\n",
       "      <td>gbt_model_1to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954625</td>\n",
       "      <td>gbt_model_3to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954089</td>\n",
       "      <td>gbt_model_5to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954205</td>\n",
       "      <td>gbt_model_7to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954931</td>\n",
       "      <td>gbt_model_9to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954439</td>\n",
       "      <td>gbt_model_11to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.954333</td>\n",
       "      <td>gbt_model_13to1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   maxIter  maxDepth  minInstancesPerNode       AUC            Model\n",
       "0       20         5                   20  0.954903   gbt_model_1to1\n",
       "0       20         5                   20  0.954625   gbt_model_3to1\n",
       "0       20         5                   20  0.954089   gbt_model_5to1\n",
       "0       20         5                   20  0.954205   gbt_model_7to1\n",
       "0       20         5                   20  0.954931   gbt_model_9to1\n",
       "0       20         5                   20  0.954439  gbt_model_11to1\n",
       "0       20         5                   20  0.954333  gbt_model_13to1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Feature Importance</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will derive average feature importance scores for all features. Then we will produce a 5 Number Summary on these scores and group our features based on their scores against the following thresholds: Mean, 75th Percentile, 50th Percentile, and 25th Percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "importances = gbt_model_1to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column1 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_3to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column3 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_5to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column5 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_7to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column7 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_9to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column9 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_11to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column11 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)\n",
    "\n",
    "importances = gbt_model_13to1.bestModel.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = final_features\n",
    "column13 = pd.DataFrame(data=list(zip(names, importances_list)), columns=['Features', 'Importance Score']).sort_values(by='Importance Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.merge(column1, column3 , on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column5, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column7, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column9, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column11, on='Features')\n",
    "feature_imp = pd.merge(feature_imp, column13, on='Features')\n",
    "\n",
    "feature_imp['avg'] = feature_imp[list(feature_imp.columns[1:-1])].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    231.000000\n",
       "mean       0.004126\n",
       "std        0.018269\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000331\n",
       "75%        0.001119\n",
       "max        0.167198\n",
       "Name: avg, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show 5-Number Sumamry\n",
    "feature_imp['avg'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>login_after_expire_30</td>\n",
       "      <td>0.136184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_transactions</td>\n",
       "      <td>0.140791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is_auto_renew_vec</td>\n",
       "      <td>0.167198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>login_after_expire_20</td>\n",
       "      <td>0.017738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is_cancel</td>\n",
       "      <td>0.038142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plan_list_price</td>\n",
       "      <td>0.072796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_spent_trans</td>\n",
       "      <td>0.036482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_spent</td>\n",
       "      <td>0.034143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>net_paid_amount</td>\n",
       "      <td>0.034785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>expire_last_login</td>\n",
       "      <td>0.036996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>membership_length</td>\n",
       "      <td>0.032826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spent_per_logins</td>\n",
       "      <td>0.023170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SUM_logins_30_45</td>\n",
       "      <td>0.006484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>logins_last_60</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>payment_method_agg_vec</td>\n",
       "      <td>0.008785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_spent_zero_vec</td>\n",
       "      <td>0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_logins</td>\n",
       "      <td>0.006155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>logins_last_120</td>\n",
       "      <td>0.004976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SUM_logins_45_60</td>\n",
       "      <td>0.002179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_secs_last_60</td>\n",
       "      <td>0.002097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sum_over_985pec</td>\n",
       "      <td>0.001640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SUM_songs50_30_45</td>\n",
       "      <td>0.002641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num_unq_last_7</td>\n",
       "      <td>0.002314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>payment_plan_days</td>\n",
       "      <td>0.005380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>spent_per_num_unq</td>\n",
       "      <td>0.001763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>spent_per_secs</td>\n",
       "      <td>0.000906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SUM_songs_30_45</td>\n",
       "      <td>0.001269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SUM_songs50_0_15</td>\n",
       "      <td>0.006850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>num_repeat_last_120</td>\n",
       "      <td>0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DIFSUM_logins_15_30_30_45</td>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Features       avg\n",
       "0       login_after_expire_30  0.136184\n",
       "1          total_transactions  0.140791\n",
       "2           is_auto_renew_vec  0.167198\n",
       "3       login_after_expire_20  0.017738\n",
       "4                   is_cancel  0.038142\n",
       "5             plan_list_price  0.072796\n",
       "6             avg_spent_trans  0.036482\n",
       "7                 total_spent  0.034143\n",
       "8             net_paid_amount  0.034785\n",
       "9           expire_last_login  0.036996\n",
       "10          membership_length  0.032826\n",
       "11           spent_per_logins  0.023170\n",
       "12           SUM_logins_30_45  0.006484\n",
       "13             logins_last_60  0.006255\n",
       "14     payment_method_agg_vec  0.008785\n",
       "15       total_spent_zero_vec  0.004564\n",
       "16               total_logins  0.006155\n",
       "17            logins_last_120  0.004976\n",
       "18           SUM_logins_45_60  0.002179\n",
       "19         total_secs_last_60  0.002097\n",
       "20            sum_over_985pec  0.001640\n",
       "21          SUM_songs50_30_45  0.002641\n",
       "22             num_unq_last_7  0.002314\n",
       "23          payment_plan_days  0.005380\n",
       "24          spent_per_num_unq  0.001763\n",
       "25             spent_per_secs  0.000906\n",
       "26            SUM_songs_30_45  0.001269\n",
       "27           SUM_songs50_0_15  0.006850\n",
       "28        num_repeat_last_120  0.001404\n",
       "29  DIFSUM_logins_15_30_30_45  0.003713"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp[['Features','avg']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feats = feature_imp[feature_imp['avg'] > .004158]['Features'].tolist()\n",
    "quart25_feats = feature_imp[feature_imp['avg'] > .000215]['Features'].tolist()\n",
    "quart50_feats = feature_imp[feature_imp['avg'] > .000455]['Features'].tolist()\n",
    "quart75_feats = feature_imp[feature_imp['avg'] > .001476]['Features'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mean_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'is_cancel',\n",
    " 'total_spent',\n",
    " 'expire_last_login',\n",
    " 'net_paid_amount',\n",
    " 'membership_length',\n",
    " 'spent_per_logins',\n",
    " 'logins_last_60',\n",
    " 'total_logins',\n",
    " 'SUM_logins_30_45',\n",
    " 'payment_plan_days',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'payment_method_agg_vec',\n",
    " 'SUM_songs50_0_15',\n",
    " 'num_unq_last_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quart25_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'is_cancel',\n",
    " 'total_spent',\n",
    " 'expire_last_login',\n",
    " 'net_paid_amount',\n",
    " 'membership_length',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'total_logins',\n",
    " 'SUM_logins_30_45',\n",
    " 'payment_plan_days',\n",
    " 'logins_last_120',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'payment_method_agg_vec',\n",
    " 'sum_over_50pec',\n",
    " 'SUM_songs50_0_15',\n",
    " 'SUM_logins_45_60',\n",
    " 'songs_last_60',\n",
    " 'songs_last_120',\n",
    " 'spent_per_song',\n",
    " 'DIFSUM_songs50_0_15_15_30',\n",
    " 'total_secs_last_15',\n",
    " 'SUM_songs_30_45',\n",
    " 'num_repeat_last_120',\n",
    " 'STD_songs50_30_45',\n",
    " 'sum_over_985pec',\n",
    " 'SUM_songs50_30_45',\n",
    " 'sum_num_unq',\n",
    " 'spent_per_num_repeats',\n",
    " 'spent_per_num_unq',\n",
    " 'DIFSUM_logins_30_45_45_60',\n",
    " 'SUM_unq_songs_30_45',\n",
    " 'sum_over_75pec',\n",
    " 'over_50perc_last_7',\n",
    " 'DIFSUM_secs_0_15_15_30',\n",
    " 'DIFSUM_unq_songs_30_45_45_60',\n",
    " 'total_secs_last_7',\n",
    " 'DIFSUM_songs50_15_30_30_45',\n",
    " 'STD_songs_45_60',\n",
    " 'DIFSUM_secs_30_45_45_60',\n",
    " 'songs_last_7',\n",
    " 'DIFSTD_repeats_15_30_30_45',\n",
    " 'STD_unq_songs_30_45',\n",
    " 'sum_num_repeat',\n",
    " 'over_75perc_last_7',\n",
    " 'num_unq_last_7',\n",
    " 'DIFAVG_logins_30_45_45_60',\n",
    " 'over_985perc_last_120',\n",
    " 'STD_repeats_30_45',\n",
    " 'STD_songs_15_30',\n",
    " 'STD_unq_songs_15_30',\n",
    " 'DIFSUM_logins_0_15_15_30',\n",
    " 'total_secs_last_60',\n",
    " 'SUM_repeats_15_30',\n",
    " 'num_unq_last_15',\n",
    " 'logins_last_15',\n",
    " 'num_unq_last_30',\n",
    " 'num_repeat_last_60',\n",
    " 'DIFSTD_repeats_0_15_15_30',\n",
    " 'over_75perc_last_15',\n",
    " 'STD_secs_15_30',\n",
    " 'SUM_songs_45_60',\n",
    " 'songs_last_15',\n",
    " 'SUM_songs50_45_60',\n",
    " 'total_secs',\n",
    " 'SUM_repeats_45_60',\n",
    " 'DIFSUM_logins_15_30_30_45',\n",
    " 'DIFSUM_songs50_30_45_45_60',\n",
    " 'over_75perc_last_60',\n",
    " 'logins_last_30',\n",
    " 'over_75perc_last_120',\n",
    " 'num_unq_last_120',\n",
    " 'DIFSUM_unq_songs_15_30_30_45',\n",
    " 'total_secs_last_30',\n",
    " 'over_985perc_last_7',\n",
    " 'num_unq_last_60',\n",
    " 'SUM_secs_30_45',\n",
    " 'over_985perc_last_30',\n",
    " 'num_repeat_last_7',\n",
    " 'DIFAVG_songs50_15_30_30_45',\n",
    " 'SUM_songs50_15_30',\n",
    " 'DIFSTD_songs_0_15_15_30',\n",
    " 'DIFSTD_songs50_0_15_15_30',\n",
    " 'DIFSUM_songs_0_15_15_30',\n",
    " 'DIFAVG_logins_0_15_15_30',\n",
    " 'DIFAVG_songs_0_15_15_30',\n",
    " 'DIFSUM_secs_15_30_30_45',\n",
    " 'songs_last_30',\n",
    " 'STD_songs50_45_60',\n",
    " 'SUM_secs_45_60',\n",
    " 'STD_secs_45_60',\n",
    " 'STD_unq_songs_45_60',\n",
    " 'SUM_unq_songs_45_60',\n",
    " 'DIFSUM_repeats_15_30_30_45',\n",
    " 'total_songs',\n",
    " 'DIFSTD_repeats_30_45_45_60',\n",
    " 'DIFSTD_secs_30_45_45_60',\n",
    " 'DIFSTD_songs_30_45_45_60',\n",
    " 'DIFSTD_songs50_15_30_30_45',\n",
    " 'STD_repeats_45_60',\n",
    " 'DIFSTD_songs_15_30_30_45',\n",
    " 'DIFSTD_unq_songs_15_30_30_45',\n",
    " 'DIFSUM_repeats_0_15_15_30',\n",
    " 'DIFAVG_songs50_0_15_15_30',\n",
    " 'DIFSTD_unq_songs_0_15_15_30',\n",
    " 'DIFAVG_unq_songs_0_15_15_30',\n",
    " 'DIFSUM_unq_songs_0_15_15_30',\n",
    " 'SUM_songs_15_30',\n",
    " 'over_985perc_last_60',\n",
    " 'over_50perc_last_30',\n",
    " 'over_75perc_last_30',\n",
    " 'num_unq_last_60_AVG',\n",
    " 'over_50perc_last_60',\n",
    " 'logins_last_7',\n",
    " 'num_repeat_last_15',\n",
    " 'over_50perc_last_15',\n",
    " 'SUM_secs_15_30',\n",
    " 'STD_songs50_15_30',\n",
    " 'STD_repeats_15_30',\n",
    " 'STD_songs50_0_15',\n",
    " 'AVG_songs50_0_15',\n",
    " 'total_secs_last_120',\n",
    " 'over_50perc_last_120',\n",
    " 'spent_per_secs',\n",
    " 'STD_unq_songs_0_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quart50_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'is_cancel',\n",
    " 'total_spent',\n",
    " 'expire_last_login',\n",
    " 'net_paid_amount',\n",
    " 'membership_length',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'total_logins',\n",
    " 'SUM_logins_30_45',\n",
    " 'payment_plan_days',\n",
    " 'logins_last_120',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'payment_method_agg_vec',\n",
    " 'sum_over_50pec',\n",
    " 'SUM_songs50_0_15',\n",
    " 'SUM_logins_45_60',\n",
    " 'songs_last_60',\n",
    " 'songs_last_120',\n",
    " 'spent_per_song',\n",
    " 'DIFSUM_songs50_0_15_15_30',\n",
    " 'total_secs_last_15',\n",
    " 'SUM_songs_30_45',\n",
    " 'num_repeat_last_120',\n",
    " 'STD_songs50_30_45',\n",
    " 'sum_over_985pec',\n",
    " 'SUM_songs50_30_45',\n",
    " 'sum_num_unq',\n",
    " 'spent_per_num_repeats',\n",
    " 'spent_per_num_unq',\n",
    " 'DIFSUM_logins_30_45_45_60',\n",
    " 'SUM_unq_songs_30_45',\n",
    " 'sum_over_75pec',\n",
    " 'over_50perc_last_7',\n",
    " 'DIFSUM_secs_0_15_15_30',\n",
    " 'DIFSUM_unq_songs_30_45_45_60',\n",
    " 'total_secs_last_7',\n",
    " 'DIFSUM_secs_30_45_45_60',\n",
    " 'songs_last_7',\n",
    " 'STD_unq_songs_30_45',\n",
    " 'sum_num_repeat',\n",
    " 'over_75perc_last_7',\n",
    " 'num_unq_last_7',\n",
    " 'DIFAVG_logins_30_45_45_60',\n",
    " 'over_985perc_last_120',\n",
    " 'STD_repeats_30_45',\n",
    " 'STD_songs_15_30',\n",
    " 'DIFSUM_logins_0_15_15_30',\n",
    " 'total_secs_last_60',\n",
    " 'SUM_repeats_15_30',\n",
    " 'num_unq_last_15',\n",
    " 'logins_last_15',\n",
    " 'num_unq_last_30',\n",
    " 'num_repeat_last_60',\n",
    " 'SUM_songs_45_60',\n",
    " 'songs_last_15',\n",
    " 'SUM_songs50_45_60',\n",
    " 'total_secs',\n",
    " 'SUM_repeats_45_60',\n",
    " 'DIFSUM_logins_15_30_30_45',\n",
    " 'DIFSUM_songs50_30_45_45_60',\n",
    " 'over_75perc_last_60',\n",
    " 'logins_last_30',\n",
    " 'num_unq_last_120',\n",
    " 'total_secs_last_30',\n",
    " 'num_unq_last_60',\n",
    " 'SUM_secs_30_45',\n",
    " 'num_repeat_last_7',\n",
    " 'SUM_songs50_15_30',\n",
    " 'DIFSUM_songs_0_15_15_30',\n",
    " 'DIFAVG_logins_0_15_15_30',\n",
    " 'DIFSUM_secs_15_30_30_45',\n",
    " 'songs_last_30',\n",
    " 'STD_songs50_45_60',\n",
    " 'STD_secs_45_60',\n",
    " 'STD_unq_songs_45_60',\n",
    " 'SUM_unq_songs_45_60',\n",
    " 'DIFSUM_repeats_15_30_30_45',\n",
    " 'total_songs',\n",
    " 'DIFSTD_songs_30_45_45_60',\n",
    " 'DIFSTD_songs50_15_30_30_45',\n",
    " 'STD_repeats_45_60',\n",
    " 'DIFSTD_unq_songs_0_15_15_30',\n",
    " 'DIFAVG_unq_songs_0_15_15_30',\n",
    " 'over_985perc_last_60',\n",
    " 'over_50perc_last_30',\n",
    " 'over_75perc_last_30',\n",
    " 'num_unq_last_60_AVG',\n",
    " 'over_50perc_last_60',\n",
    " 'logins_last_7',\n",
    " 'num_repeat_last_15',\n",
    " 'STD_songs50_15_30',\n",
    " 'STD_repeats_15_30',\n",
    " 'STD_songs50_0_15',\n",
    " 'total_secs_last_120',\n",
    " 'spent_per_secs',\n",
    " 'STD_unq_songs_0_15']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quart75_feats = ['login_after_expire_30',\n",
    " 'total_transactions',\n",
    " 'is_auto_renew_vec',\n",
    " 'login_after_expire_20',\n",
    " 'plan_list_price',\n",
    " 'avg_spent_trans',\n",
    " 'is_cancel',\n",
    " 'total_spent',\n",
    " 'expire_last_login',\n",
    " 'net_paid_amount',\n",
    " 'membership_length',\n",
    " 'spent_per_logins',\n",
    " 'total_spent_zero_vec',\n",
    " 'logins_last_60',\n",
    " 'total_logins',\n",
    " 'SUM_logins_30_45',\n",
    " 'payment_plan_days',\n",
    " 'logins_last_120',\n",
    " 'DIFAVG_logins_15_30_30_45',\n",
    " 'payment_method_agg_vec',\n",
    " 'sum_over_50pec',\n",
    " 'SUM_songs50_0_15',\n",
    " 'SUM_logins_45_60',\n",
    " 'songs_last_60',\n",
    " 'songs_last_120',\n",
    " 'SUM_songs50_30_45',\n",
    " 'sum_num_unq',\n",
    " 'songs_last_7',\n",
    " 'sum_num_repeat',\n",
    " 'num_unq_last_7',\n",
    " 'DIFAVG_logins_30_45_45_60',\n",
    " 'over_985perc_last_120',\n",
    " 'DIFSUM_logins_0_15_15_30',\n",
    " 'total_secs_last_60',\n",
    " 'num_unq_last_15',\n",
    " 'logins_last_15',\n",
    " 'num_unq_last_30',\n",
    " 'songs_last_15',\n",
    " 'DIFSUM_logins_15_30_30_45',\n",
    " 'over_75perc_last_60',\n",
    " 'logins_last_30',\n",
    " 'total_secs_last_30',\n",
    " 'num_unq_last_60',\n",
    " 'SUM_secs_30_45',\n",
    " 'num_repeat_last_7',\n",
    " 'songs_last_30',\n",
    " 'STD_songs50_45_60',\n",
    " 'over_50perc_last_60',\n",
    " 'total_secs_last_120']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: Mean Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = mean_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 147\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to1mean = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 175\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to1mean = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 205\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to1mean = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 228\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to1mean = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 254\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to1mean = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 292\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to1mean = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 309\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to1mean = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_createdmean = {\n",
    "                  'gbt_model_1to1mean' : (gbt_model_1to1mean, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to1mean' : (gbt_model_3to1mean, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to1mean' : (gbt_model_5to1mean, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to1mean' : (gbt_model_7to1mean, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to1mean' : (gbt_model_9to1mean, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to1mean' : (gbt_model_11to1mean, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to1mean' : (gbt_model_13to1mean, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: Mean Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to1mean\n",
      "[[589479  83272]\n",
      " [  1948  17200]]\n",
      " \n",
      "gbt_model_3to1mean\n",
      "[[635623  37128]\n",
      " [  4069  15079]]\n",
      " \n",
      "gbt_model_5to1mean\n",
      "[[648524  24227]\n",
      " [  5524  13624]]\n",
      " \n",
      "gbt_model_7to1mean\n",
      "[[655800  16951]\n",
      " [  6998  12150]]\n",
      " \n",
      "gbt_model_9to1mean\n",
      "[[659279  13472]\n",
      " [  7548  11600]]\n",
      " \n",
      "gbt_model_11to1mean\n",
      "[[662423  10328]\n",
      " [  8351  10797]]\n",
      " \n",
      "gbt_model_13to1mean\n",
      "[[664784   7967]\n",
      " [  9221   9927]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_resultsmean = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_createdmean.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_resultsmean = train_resultsmean.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1mean</td>\n",
       "      <td>0.887244</td>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>0.996706</td>\n",
       "      <td>0.123168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1mean</td>\n",
       "      <td>0.866155</td>\n",
       "      <td>0.968605</td>\n",
       "      <td>0.944812</td>\n",
       "      <td>0.993639</td>\n",
       "      <td>0.059542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1mean</td>\n",
       "      <td>0.837749</td>\n",
       "      <td>0.977572</td>\n",
       "      <td>0.963988</td>\n",
       "      <td>0.991554</td>\n",
       "      <td>0.042999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1mean</td>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.974803</td>\n",
       "      <td>0.989442</td>\n",
       "      <td>0.034613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1mean</td>\n",
       "      <td>0.792891</td>\n",
       "      <td>0.984303</td>\n",
       "      <td>0.979975</td>\n",
       "      <td>0.988681</td>\n",
       "      <td>0.030380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1mean</td>\n",
       "      <td>0.774260</td>\n",
       "      <td>0.986092</td>\n",
       "      <td>0.984648</td>\n",
       "      <td>0.987550</td>\n",
       "      <td>0.026997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1mean</td>\n",
       "      <td>0.753296</td>\n",
       "      <td>0.987232</td>\n",
       "      <td>0.988158</td>\n",
       "      <td>0.986319</td>\n",
       "      <td>0.024842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to1mean  0.887244  0.932584   0.876222  0.996706  0.123168\n",
       "0   gbt_model_3to1mean  0.866155  0.968605   0.944812  0.993639  0.059542\n",
       "0   gbt_model_5to1mean  0.837749  0.977572   0.963988  0.991554  0.042999\n",
       "0   gbt_model_7to1mean  0.804667  0.982063   0.974803  0.989442  0.034613\n",
       "0   gbt_model_9to1mean  0.792891  0.984303   0.979975  0.988681  0.030380\n",
       "0  gbt_model_11to1mean  0.774260  0.986092   0.984648  0.987550  0.026997\n",
       "0  gbt_model_13to1mean  0.753296  0.987232   0.988158  0.986319  0.024842"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_resultsmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: Mean Features, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to1mean\n",
      "[[451279  76925]\n",
      " [  2407  17516]]\n",
      " \n",
      "gbt_model_3to1mean\n",
      "[[491516  36688]\n",
      " [  5241  14682]]\n",
      " \n",
      "gbt_model_5to1mean\n",
      "[[505446  22758]\n",
      " [  7500  12423]]\n",
      " \n",
      "gbt_model_7to1mean\n",
      "[[512838  15366]\n",
      " [  9112  10811]]\n",
      " \n",
      "gbt_model_9to1mean\n",
      "[[515809  12395]\n",
      " [  9734  10189]]\n",
      " \n",
      "gbt_model_11to1mean\n",
      "[[518516   9688]\n",
      " [ 10708   9215]]\n",
      " \n",
      "gbt_model_13to1mean\n",
      "[[520712   7492]\n",
      " [ 11699   8224]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_resultsmean = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_createdmean.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_resultsmean = validation_resultsmean.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to1mean</td>\n",
       "      <td>0.866775</td>\n",
       "      <td>0.919200</td>\n",
       "      <td>0.854365</td>\n",
       "      <td>0.994695</td>\n",
       "      <td>0.144733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to1mean</td>\n",
       "      <td>0.833740</td>\n",
       "      <td>0.959087</td>\n",
       "      <td>0.930542</td>\n",
       "      <td>0.989450</td>\n",
       "      <td>0.076495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to1mean</td>\n",
       "      <td>0.790233</td>\n",
       "      <td>0.970933</td>\n",
       "      <td>0.956914</td>\n",
       "      <td>0.985379</td>\n",
       "      <td>0.055203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to1mean</td>\n",
       "      <td>0.756774</td>\n",
       "      <td>0.976686</td>\n",
       "      <td>0.970909</td>\n",
       "      <td>0.982542</td>\n",
       "      <td>0.044658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to1mean</td>\n",
       "      <td>0.743976</td>\n",
       "      <td>0.978995</td>\n",
       "      <td>0.976534</td>\n",
       "      <td>0.981478</td>\n",
       "      <td>0.040372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to1mean</td>\n",
       "      <td>0.722095</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.981659</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>0.037210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to1mean</td>\n",
       "      <td>0.699303</td>\n",
       "      <td>0.981901</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.978026</td>\n",
       "      <td>0.035012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to1mean  0.866775  0.919200   0.854365  0.994695  0.144733\n",
       "0   gbt_model_3to1mean  0.833740  0.959087   0.930542  0.989450  0.076495\n",
       "0   gbt_model_5to1mean  0.790233  0.970933   0.956914  0.985379  0.055203\n",
       "0   gbt_model_7to1mean  0.756774  0.976686   0.970909  0.982542  0.044658\n",
       "0   gbt_model_9to1mean  0.743976  0.978995   0.976534  0.981478  0.040372\n",
       "0  gbt_model_11to1mean  0.722095  0.980707   0.981659  0.979767  0.037210\n",
       "0  gbt_model_13to1mean  0.699303  0.981901   0.985816  0.978026  0.035012"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_resultsmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_createdmean.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: 75th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = quart75_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 162\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to175 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 196\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to175 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 228\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to175 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 248\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to175 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 279\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to175 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 313\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to175 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 336\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to175 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created75 = {\n",
    "                  'gbt_model_1to175' : (gbt_model_1to175, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to175' : (gbt_model_3to175, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to175' : (gbt_model_5to175, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to175' : (gbt_model_7to175, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to175' : (gbt_model_9to175, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to175' : (gbt_model_11to175, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to175' : (gbt_model_13to175, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: 75th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to175\n",
      "[[588069  84682]\n",
      " [  1921  17227]]\n",
      " \n",
      "gbt_model_3to175\n",
      "[[633400  39351]\n",
      " [  4007  15141]]\n",
      " \n",
      "gbt_model_5to175\n",
      "[[648476  24275]\n",
      " [  5583  13565]]\n",
      " \n",
      "gbt_model_7to175\n",
      "[[655759  16992]\n",
      " [  6999  12149]]\n",
      " \n",
      "gbt_model_9to175\n",
      "[[659640  13111]\n",
      " [  7684  11464]]\n",
      " \n",
      "gbt_model_11to175\n",
      "[[662484  10267]\n",
      " [  8384  10764]]\n",
      " \n",
      "gbt_model_13to175\n",
      "[[664918   7833]\n",
      " [  9257   9891]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_results75 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created75.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_results75 = train_results75.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to175</td>\n",
       "      <td>0.886901</td>\n",
       "      <td>0.931412</td>\n",
       "      <td>0.874126</td>\n",
       "      <td>0.996744</td>\n",
       "      <td>0.125167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to175</td>\n",
       "      <td>0.866121</td>\n",
       "      <td>0.966901</td>\n",
       "      <td>0.941507</td>\n",
       "      <td>0.993714</td>\n",
       "      <td>0.062665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to175</td>\n",
       "      <td>0.836173</td>\n",
       "      <td>0.977491</td>\n",
       "      <td>0.963917</td>\n",
       "      <td>0.991464</td>\n",
       "      <td>0.043154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to175</td>\n",
       "      <td>0.804611</td>\n",
       "      <td>0.982031</td>\n",
       "      <td>0.974743</td>\n",
       "      <td>0.989440</td>\n",
       "      <td>0.034674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to175</td>\n",
       "      <td>0.789608</td>\n",
       "      <td>0.984477</td>\n",
       "      <td>0.980511</td>\n",
       "      <td>0.988485</td>\n",
       "      <td>0.030055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to175</td>\n",
       "      <td>0.773443</td>\n",
       "      <td>0.986114</td>\n",
       "      <td>0.984739</td>\n",
       "      <td>0.987503</td>\n",
       "      <td>0.026956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to175</td>\n",
       "      <td>0.752456</td>\n",
       "      <td>0.987307</td>\n",
       "      <td>0.988357</td>\n",
       "      <td>0.986269</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to175  0.886901  0.931412   0.874126  0.996744  0.125167\n",
       "0   gbt_model_3to175  0.866121  0.966901   0.941507  0.993714  0.062665\n",
       "0   gbt_model_5to175  0.836173  0.977491   0.963917  0.991464  0.043154\n",
       "0   gbt_model_7to175  0.804611  0.982031   0.974743  0.989440  0.034674\n",
       "0   gbt_model_9to175  0.789608  0.984477   0.980511  0.988485  0.030055\n",
       "0  gbt_model_11to175  0.773443  0.986114   0.984739  0.987503  0.026956\n",
       "0  gbt_model_13to175  0.752456  0.987307   0.988357  0.986269  0.024700"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_results75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: 75th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to175\n",
      "[[451959  76245]\n",
      " [  2403  17520]]\n",
      " \n",
      "gbt_model_3to175\n",
      "[[493954  34250]\n",
      " [  5248  14675]]\n",
      " \n",
      "gbt_model_5to175\n",
      "[[507006  21198]\n",
      " [  7582  12341]]\n",
      " \n",
      "gbt_model_7to175\n",
      "[[513176  15028]\n",
      " [  9121  10802]]\n",
      " \n",
      "gbt_model_9to175\n",
      "[[516314  11890]\n",
      " [ 10002   9921]]\n",
      " \n",
      "gbt_model_11to175\n",
      "[[518654   9550]\n",
      " [ 10804   9119]]\n",
      " \n",
      "gbt_model_13to175\n",
      "[[520836   7368]\n",
      " [ 11695   8228]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_results75 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created75.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_results75 = validation_results75.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to175</td>\n",
       "      <td>0.867519</td>\n",
       "      <td>0.919952</td>\n",
       "      <td>0.855652</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.143485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to175</td>\n",
       "      <td>0.835872</td>\n",
       "      <td>0.961551</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.989487</td>\n",
       "      <td>0.072060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to175</td>\n",
       "      <td>0.789651</td>\n",
       "      <td>0.972396</td>\n",
       "      <td>0.959868</td>\n",
       "      <td>0.985266</td>\n",
       "      <td>0.052506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to175</td>\n",
       "      <td>0.756868</td>\n",
       "      <td>0.977007</td>\n",
       "      <td>0.971549</td>\n",
       "      <td>0.982537</td>\n",
       "      <td>0.044057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to175</td>\n",
       "      <td>0.737728</td>\n",
       "      <td>0.979235</td>\n",
       "      <td>0.977490</td>\n",
       "      <td>0.980996</td>\n",
       "      <td>0.039940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to175</td>\n",
       "      <td>0.719816</td>\n",
       "      <td>0.980751</td>\n",
       "      <td>0.981920</td>\n",
       "      <td>0.979594</td>\n",
       "      <td>0.037134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to175</td>\n",
       "      <td>0.699520</td>\n",
       "      <td>0.982023</td>\n",
       "      <td>0.986051</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.034778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to175  0.867519  0.919952   0.855652  0.994711  0.143485\n",
       "0   gbt_model_3to175  0.835872  0.961551   0.935158  0.989487  0.072060\n",
       "0   gbt_model_5to175  0.789651  0.972396   0.959868  0.985266  0.052506\n",
       "0   gbt_model_7to175  0.756868  0.977007   0.971549  0.982537  0.044057\n",
       "0   gbt_model_9to175  0.737728  0.979235   0.977490  0.980996  0.039940\n",
       "0  gbt_model_11to175  0.719816  0.980751   0.981920  0.979594  0.037134\n",
       "0  gbt_model_13to175  0.699520  0.982023   0.986051  0.978039  0.034778"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_results75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created75.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: 50th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = quart50_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 196\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to150 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 238\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to150 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 273\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to150 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 306\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to150 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 343\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to150 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 374\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to150 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 412\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to150 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created50 = {\n",
    "                  'gbt_model_1to150' : (gbt_model_1to150, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to150' : (gbt_model_3to150, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to150' : (gbt_model_5to150, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to150' : (gbt_model_7to150, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to150' : (gbt_model_9to150, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to150' : (gbt_model_11to150, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to150' : (gbt_model_13to150, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: 50th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to150\n",
      "[[589029  83722]\n",
      " [  1949  17199]]\n",
      " \n",
      "gbt_model_3to150\n",
      "[[633860  38891]\n",
      " [  3965  15183]]\n",
      " \n",
      "gbt_model_5to150\n",
      "[[648310  24441]\n",
      " [  5574  13574]]\n",
      " \n",
      "gbt_model_7to150\n",
      "[[655771  16980]\n",
      " [  6992  12156]]\n",
      " \n",
      "gbt_model_9to150\n",
      "[[659713  13038]\n",
      " [  7721  11427]]\n",
      " \n",
      "gbt_model_11to150\n",
      "[[662457  10294]\n",
      " [  8389  10759]]\n",
      " \n",
      "gbt_model_13to150\n",
      "[[664466   8285]\n",
      " [  9047  10101]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_results50 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created50.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_results50 = train_results50.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to150</td>\n",
       "      <td>0.886883</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.875553</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>0.123820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to150</td>\n",
       "      <td>0.867560</td>\n",
       "      <td>0.967295</td>\n",
       "      <td>0.942191</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.061940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to150</td>\n",
       "      <td>0.836285</td>\n",
       "      <td>0.977370</td>\n",
       "      <td>0.963670</td>\n",
       "      <td>0.991476</td>\n",
       "      <td>0.043381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to150</td>\n",
       "      <td>0.804802</td>\n",
       "      <td>0.982045</td>\n",
       "      <td>0.974760</td>\n",
       "      <td>0.989450</td>\n",
       "      <td>0.034647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to150</td>\n",
       "      <td>0.788696</td>\n",
       "      <td>0.984505</td>\n",
       "      <td>0.980620</td>\n",
       "      <td>0.988432</td>\n",
       "      <td>0.030003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to150</td>\n",
       "      <td>0.773293</td>\n",
       "      <td>0.986090</td>\n",
       "      <td>0.984699</td>\n",
       "      <td>0.987495</td>\n",
       "      <td>0.027002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to150</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.987121</td>\n",
       "      <td>0.987685</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.025050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to150  0.886883  0.932203   0.875553  0.996702  0.123820\n",
       "0   gbt_model_3to150  0.867560  0.967295   0.942191  0.993784  0.061940\n",
       "0   gbt_model_5to150  0.836285  0.977370   0.963670  0.991476  0.043381\n",
       "0   gbt_model_7to150  0.804802  0.982045   0.974760  0.989450  0.034647\n",
       "0   gbt_model_9to150  0.788696  0.984505   0.980620  0.988432  0.030003\n",
       "0  gbt_model_11to150  0.773293  0.986090   0.984699  0.987495  0.027002\n",
       "0  gbt_model_13to150  0.757604  0.987121   0.987685  0.986567  0.025050"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_results50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: 50th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to150\n",
      "[[451132  77072]\n",
      " [  2388  17535]]\n",
      " \n",
      "gbt_model_3to150\n",
      "[[492185  36019]\n",
      " [  5534  14389]]\n",
      " \n",
      "gbt_model_5to150\n",
      "[[506962  21242]\n",
      " [  7434  12489]]\n",
      " \n",
      "gbt_model_7to150\n",
      "[[513024  15180]\n",
      " [  9042  10881]]\n",
      " \n",
      "gbt_model_9to150\n",
      "[[516376  11828]\n",
      " [  9993   9930]]\n",
      " \n",
      "gbt_model_11to150\n",
      "[[518543   9661]\n",
      " [ 10768   9155]]\n",
      " \n",
      "gbt_model_13to150\n",
      "[[520476   7728]\n",
      " [ 11603   8320]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_results50 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created50.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_results50 = validation_results50.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to150</td>\n",
       "      <td>0.867113</td>\n",
       "      <td>0.919056</td>\n",
       "      <td>0.854087</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>0.144966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to150</td>\n",
       "      <td>0.827020</td>\n",
       "      <td>0.959492</td>\n",
       "      <td>0.931809</td>\n",
       "      <td>0.988881</td>\n",
       "      <td>0.075809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to150</td>\n",
       "      <td>0.793324</td>\n",
       "      <td>0.972491</td>\n",
       "      <td>0.959784</td>\n",
       "      <td>0.985548</td>\n",
       "      <td>0.052316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to150</td>\n",
       "      <td>0.758707</td>\n",
       "      <td>0.976932</td>\n",
       "      <td>0.971261</td>\n",
       "      <td>0.982680</td>\n",
       "      <td>0.044190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to150</td>\n",
       "      <td>0.738013</td>\n",
       "      <td>0.979303</td>\n",
       "      <td>0.977607</td>\n",
       "      <td>0.981015</td>\n",
       "      <td>0.039810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to150</td>\n",
       "      <td>0.720614</td>\n",
       "      <td>0.980677</td>\n",
       "      <td>0.981710</td>\n",
       "      <td>0.979657</td>\n",
       "      <td>0.037271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to150</td>\n",
       "      <td>0.701489</td>\n",
       "      <td>0.981763</td>\n",
       "      <td>0.985369</td>\n",
       "      <td>0.978193</td>\n",
       "      <td>0.035267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to150  0.867113  0.919056   0.854087  0.994735  0.144966\n",
       "0   gbt_model_3to150  0.827020  0.959492   0.931809  0.988881  0.075809\n",
       "0   gbt_model_5to150  0.793324  0.972491   0.959784  0.985548  0.052316\n",
       "0   gbt_model_7to150  0.758707  0.976932   0.971261  0.982680  0.044190\n",
       "0   gbt_model_9to150  0.738013  0.979303   0.977607  0.981015  0.039810\n",
       "0  gbt_model_11to150  0.720614  0.980677   0.981710  0.979657  0.037271\n",
       "0  gbt_model_13to150  0.701489  0.981763   0.985369  0.978193  0.035267"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Validation Model\n",
    "validation_results50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created50.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Train Model: 25th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master list of feature names for model\n",
    "final_features = quart25_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the numeric features we will be transforming, and the name of the resulting output feature\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= final_features,\n",
    "    outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create pipeline objects\n",
    "gbt_pipe = Pipeline(stages=[is_auto_renew_encoder,never_active_subscriber_encoder,\n",
    "                            total_spent_zero_encoder,city_agg_encoder,payment_method_agg_encoder,\n",
    "                            assembler,scaler,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Grid for Gradient Boosted Trees Hyperparameterization\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [20]) \\\n",
    "    .build()\n",
    "\n",
    "# Instantiate Cross Validation block\n",
    "gbt_cv = CrossValidator(estimator=gbt_pipe,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=binary_evaluator,\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Gradient Boosted Trees***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 219\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 1 to 1\n",
    "start = time.time()\n",
    "gbt_model_1to125 = gbt_cv.fit(DRV_Jan2016_1to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 266\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 3 to 1\n",
    "start = time.time()\n",
    "gbt_model_3to125 = gbt_cv.fit(DRV_Jan2016_3to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 299\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 5 to 1\n",
    "start = time.time()\n",
    "gbt_model_5to125 = gbt_cv.fit(DRV_Jan2016_5to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 335\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 7 to 1\n",
    "start = time.time()\n",
    "gbt_model_7to125 = gbt_cv.fit(DRV_Jan2016_7to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 379\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 9 to 1\n",
    "start = time.time()\n",
    "gbt_model_9to125 = gbt_cv.fit(DRV_Jan2016_9to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 416\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 11 to 1\n",
    "start = time.time()\n",
    "gbt_model_11to125 = gbt_cv.fit(DRV_Jan2016_11to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 463\n"
     ]
    }
   ],
   "source": [
    "# GBT Training on Trainset 13 to 1\n",
    "start = time.time()\n",
    "gbt_model_13to125 = gbt_cv.fit(DRV_Jan2016_13to1)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "models_created25 = {\n",
    "                  'gbt_model_1to125' : (gbt_model_1to125, DRV_Jan2016_1to1),\n",
    "                  'gbt_model_3to125' : (gbt_model_3to125, DRV_Jan2016_3to1),\n",
    "                  'gbt_model_5to125' : (gbt_model_5to125, DRV_Jan2016_5to1),\n",
    "                  'gbt_model_7to125' : (gbt_model_7to125, DRV_Jan2016_7to1),\n",
    "                  'gbt_model_9to125' : (gbt_model_9to125, DRV_Jan2016_9to1),\n",
    "                  'gbt_model_11to125' : (gbt_model_11to125, DRV_Jan2016_11to1),\n",
    "                  'gbt_model_13to125' : (gbt_model_13to125, DRV_Jan2016_13to1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Train Model: 25th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to125\n",
      "[[589180  83571]\n",
      " [  1936  17212]]\n",
      " \n",
      "gbt_model_3to125\n",
      "[[633316  39435]\n",
      " [  3955  15193]]\n",
      " \n",
      "gbt_model_5to125\n",
      "[[648190  24561]\n",
      " [  5552  13596]]\n",
      " \n",
      "gbt_model_7to125\n",
      "[[655981  16770]\n",
      " [  7017  12131]]\n",
      " \n",
      "gbt_model_9to125\n",
      "[[659603  13148]\n",
      " [  7674  11474]]\n",
      " \n",
      "gbt_model_11to125\n",
      "[[662721  10030]\n",
      " [  8395  10753]]\n",
      " \n",
      "gbt_model_13to125\n",
      "[[664744   8007]\n",
      " [  9121  10027]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## Create empty dataframe and populate with Train Set transformation results.\n",
    "train_results25 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set_test) in models_created25.items():\n",
    "    temp = model1.transform(DRV_Jan2016)\n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    train_results25 = train_results25.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to125</td>\n",
       "      <td>0.887335</td>\n",
       "      <td>0.932340</td>\n",
       "      <td>0.875777</td>\n",
       "      <td>0.996725</td>\n",
       "      <td>0.123583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to125</td>\n",
       "      <td>0.867417</td>\n",
       "      <td>0.966873</td>\n",
       "      <td>0.941382</td>\n",
       "      <td>0.993794</td>\n",
       "      <td>0.062711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to125</td>\n",
       "      <td>0.836770</td>\n",
       "      <td>0.977294</td>\n",
       "      <td>0.963492</td>\n",
       "      <td>0.991507</td>\n",
       "      <td>0.043522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to125</td>\n",
       "      <td>0.804306</td>\n",
       "      <td>0.982187</td>\n",
       "      <td>0.975073</td>\n",
       "      <td>0.989416</td>\n",
       "      <td>0.034379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to125</td>\n",
       "      <td>0.789842</td>\n",
       "      <td>0.984457</td>\n",
       "      <td>0.980456</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.030094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to125</td>\n",
       "      <td>0.773332</td>\n",
       "      <td>0.986285</td>\n",
       "      <td>0.985091</td>\n",
       "      <td>0.987491</td>\n",
       "      <td>0.026630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to125</td>\n",
       "      <td>0.755878</td>\n",
       "      <td>0.987276</td>\n",
       "      <td>0.988098</td>\n",
       "      <td>0.986465</td>\n",
       "      <td>0.024755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to125  0.887335  0.932340   0.875777  0.996725  0.123583\n",
       "0   gbt_model_3to125  0.867417  0.966873   0.941382  0.993794  0.062711\n",
       "0   gbt_model_5to125  0.836770  0.977294   0.963492  0.991507  0.043522\n",
       "0   gbt_model_7to125  0.804306  0.982187   0.975073  0.989416  0.034379\n",
       "0   gbt_model_9to125  0.789842  0.984457   0.980456  0.988500  0.030094\n",
       "0  gbt_model_11to125  0.773332  0.986285   0.985091  0.987491  0.026630\n",
       "0  gbt_model_13to125  0.755878  0.987276   0.988098  0.986465  0.024755"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Training Model\n",
    "train_results25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Evaluate Validation Model: 25th Percentile, All Splits</font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_model_1to125\n",
      "[[452018  76186]\n",
      " [  2444  17479]]\n",
      " \n",
      "gbt_model_3to125\n",
      "[[492364  35840]\n",
      " [  5469  14454]]\n",
      " \n",
      "gbt_model_5to125\n",
      "[[506779  21425]\n",
      " [  7267  12656]]\n",
      " \n",
      "gbt_model_7to125\n",
      "[[513179  15025]\n",
      " [  9151  10772]]\n",
      " \n",
      "gbt_model_9to125\n",
      "[[516249  11955]\n",
      " [ 10001   9922]]\n",
      " \n",
      "gbt_model_11to125\n",
      "[[518813   9391]\n",
      " [ 10854   9069]]\n",
      " \n",
      "gbt_model_13to125\n",
      "[[520566   7638]\n",
      " [ 11603   8320]]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe and populate with Train Set transformation results.\n",
    "validation_results25 = pd.DataFrame()\n",
    "\n",
    "# Transform Train Sets\n",
    "for model_name, (model1, train_set) in models_created25.items():\n",
    "    temp = model1.transform(DRV_Feb2016)    \n",
    "    \n",
    "    # Create a Dataframe of Train Results\n",
    "    validation_results25 = validation_results25.append(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(ClassEvaluator(resultname=model_name, resultdata=temp, model=model1).confusionmatrix())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_1to125</td>\n",
       "      <td>0.866546</td>\n",
       "      <td>0.919978</td>\n",
       "      <td>0.855764</td>\n",
       "      <td>0.994622</td>\n",
       "      <td>0.143452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_3to125</td>\n",
       "      <td>0.828820</td>\n",
       "      <td>0.959734</td>\n",
       "      <td>0.932147</td>\n",
       "      <td>0.989014</td>\n",
       "      <td>0.075364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_5to125</td>\n",
       "      <td>0.797342</td>\n",
       "      <td>0.972466</td>\n",
       "      <td>0.959438</td>\n",
       "      <td>0.985863</td>\n",
       "      <td>0.052346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_7to125</td>\n",
       "      <td>0.756118</td>\n",
       "      <td>0.976982</td>\n",
       "      <td>0.971555</td>\n",
       "      <td>0.982480</td>\n",
       "      <td>0.044107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_9to125</td>\n",
       "      <td>0.737692</td>\n",
       "      <td>0.979173</td>\n",
       "      <td>0.977367</td>\n",
       "      <td>0.980996</td>\n",
       "      <td>0.040056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_11to125</td>\n",
       "      <td>0.718712</td>\n",
       "      <td>0.980858</td>\n",
       "      <td>0.982221</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.036935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbt_model_13to125</td>\n",
       "      <td>0.701574</td>\n",
       "      <td>0.981849</td>\n",
       "      <td>0.985540</td>\n",
       "      <td>0.978197</td>\n",
       "      <td>0.035103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          resultname       AUC        f1  precision    recall     error\n",
       "0   gbt_model_1to125  0.866546  0.919978   0.855764  0.994622  0.143452\n",
       "0   gbt_model_3to125  0.828820  0.959734   0.932147  0.989014  0.075364\n",
       "0   gbt_model_5to125  0.797342  0.972466   0.959438  0.985863  0.052346\n",
       "0   gbt_model_7to125  0.756118  0.976982   0.971555  0.982480  0.044107\n",
       "0   gbt_model_9to125  0.737692  0.979173   0.977367  0.980996  0.040056\n",
       "0  gbt_model_11to125  0.718712  0.980858   0.982221  0.979508  0.036935\n",
       "0  gbt_model_13to125  0.701574  0.981849   0.985540  0.978197  0.035103"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Model Evaluation: Optimal Parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_params = pd.DataFrame()\n",
    "\n",
    "for model_name, (model1, train_set) in models_created50.items():\n",
    "    scores = model1.avgMetrics\n",
    "    params = [{p.name: v for p, v in m.items()} for m in model1.getEstimatorParamMaps()]\n",
    "    params_pd = pd.DataFrame(params)\n",
    "    params_pd['AUC'] = scores\n",
    "    params_pd['Model'] = model_name\n",
    "    best = params_pd.sort_values('AUC', ascending=False).head(1)\n",
    "    opti_params = opti_params.append(best)\n",
    "\n",
    "opti_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=black>Evaluation of Generalization over All Models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.023379</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>-0.023161</td>\n",
       "      <td>gbt_model_1to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029694</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>-0.010558</td>\n",
       "      <td>gbt_model_3to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038399</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>-0.008653</td>\n",
       "      <td>gbt_model_5to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>-0.009447</td>\n",
       "      <td>gbt_model_7to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050809</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>-0.009948</td>\n",
       "      <td>gbt_model_9to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052828</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>-0.010264</td>\n",
       "      <td>gbt_model_11to1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>-0.010347</td>\n",
       "      <td>gbt_model_13to1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error       resultname\n",
       "0  0.023092  0.014343   0.023379  0.002182 -0.023161   gbt_model_1to1\n",
       "0  0.029694  0.005989   0.007610  0.004170 -0.010558   gbt_model_3to1\n",
       "0  0.038399  0.004734   0.003900  0.005613 -0.008653   gbt_model_5to1\n",
       "0  0.043679  0.005063   0.003553  0.006613 -0.009447   gbt_model_7to1\n",
       "0  0.050809  0.005279   0.003198  0.007387 -0.009948   gbt_model_9to1\n",
       "0  0.052828  0.005409   0.002965  0.007854 -0.010264  gbt_model_11to1\n",
       "0  0.054306  0.005427   0.002579  0.008250 -0.010347  gbt_model_13to1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_resultsall[train_resultsall.columns[1:]] - validation_resultsall[validation_resultsall.columns[1:]]\n",
    "results_all['resultname'] = train_resultsall['resultname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.021857</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>-0.021565</td>\n",
       "      <td>gbt_model_1to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>-0.016953</td>\n",
       "      <td>gbt_model_3to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047517</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>-0.012203</td>\n",
       "      <td>gbt_model_5to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047893</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>-0.010044</td>\n",
       "      <td>gbt_model_7to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048915</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>-0.009992</td>\n",
       "      <td>gbt_model_9to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052165</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>-0.010214</td>\n",
       "      <td>gbt_model_11to1mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053994</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>-0.010170</td>\n",
       "      <td>gbt_model_13to1mean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error           resultname\n",
       "0  0.020469  0.013384   0.021857  0.002012 -0.021565   gbt_model_1to1mean\n",
       "0  0.032415  0.009518   0.014270  0.004190 -0.016953   gbt_model_3to1mean\n",
       "0  0.047517  0.006639   0.007074  0.006176 -0.012203   gbt_model_5to1mean\n",
       "0  0.047893  0.005377   0.003894  0.006899 -0.010044   gbt_model_7to1mean\n",
       "0  0.048915  0.005309   0.003441  0.007203 -0.009992   gbt_model_9to1mean\n",
       "0  0.052165  0.005385   0.002990  0.007784 -0.010214  gbt_model_11to1mean\n",
       "0  0.053994  0.005332   0.002341  0.008293 -0.010170  gbt_model_13to1mean"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mean = train_resultsmean[train_resultsmean.columns[1:]] - validation_resultsmean[validation_resultsmean.columns[1:]]\n",
    "results_mean['resultname'] = train_resultsmean['resultname']\n",
    "results_mean.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>0.018473</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>-0.018318</td>\n",
       "      <td>gbt_model_1to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030250</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>-0.009395</td>\n",
       "      <td>gbt_model_3to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046522</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>-0.009352</td>\n",
       "      <td>gbt_model_5to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047743</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>-0.009383</td>\n",
       "      <td>gbt_model_7to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051880</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>-0.009885</td>\n",
       "      <td>gbt_model_9to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052936</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.008230</td>\n",
       "      <td>-0.010078</td>\n",
       "      <td>gbt_model_13to175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053627</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>-0.010177</td>\n",
       "      <td>gbt_model_11to175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error         resultname\n",
       "0  0.019382  0.011460   0.018473  0.002033 -0.018318   gbt_model_1to175\n",
       "0  0.030250  0.005351   0.006350  0.004226 -0.009395   gbt_model_3to175\n",
       "0  0.046522  0.005095   0.004049  0.006198 -0.009352   gbt_model_5to175\n",
       "0  0.047743  0.005024   0.003194  0.006903 -0.009383   gbt_model_7to175\n",
       "0  0.051880  0.005242   0.003022  0.007489 -0.009885   gbt_model_9to175\n",
       "0  0.052936  0.005283   0.002306  0.008230 -0.010078  gbt_model_13to175\n",
       "0  0.053627  0.005363   0.002819  0.007909 -0.010177  gbt_model_11to175"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_75 = train_results75[validation_results25.columns[1:]] - validation_results75[validation_results25.columns[1:]]\n",
    "results_75['resultname'] = train_results75['resultname']\n",
    "results_75.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019771</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>-0.021146</td>\n",
       "      <td>gbt_model_1to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>-0.013869</td>\n",
       "      <td>gbt_model_3to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042961</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>-0.008936</td>\n",
       "      <td>gbt_model_5to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046095</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>-0.009544</td>\n",
       "      <td>gbt_model_7to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050683</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>-0.009807</td>\n",
       "      <td>gbt_model_9to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052678</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>-0.010268</td>\n",
       "      <td>gbt_model_11to150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056115</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>-0.010217</td>\n",
       "      <td>gbt_model_13to150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error         resultname\n",
       "0  0.019771  0.013147   0.021466  0.001968 -0.021146   gbt_model_1to150\n",
       "0  0.040540  0.007803   0.010383  0.004902 -0.013869   gbt_model_3to150\n",
       "0  0.042961  0.004879   0.003886  0.005927 -0.008936   gbt_model_5to150\n",
       "0  0.046095  0.005113   0.003499  0.006770 -0.009544   gbt_model_7to150\n",
       "0  0.050683  0.005202   0.003013  0.007417 -0.009807   gbt_model_9to150\n",
       "0  0.052678  0.005413   0.002989  0.007838 -0.010268  gbt_model_11to150\n",
       "0  0.056115  0.005358   0.002316  0.008374 -0.010217  gbt_model_13to150"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_50 = train_results50[train_results50.columns[1:]] - validation_results50[validation_results50.columns[1:]]\n",
    "results_50['resultname'] = train_results50['resultname']\n",
    "results_50.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>resultname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.012362</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>-0.019869</td>\n",
       "      <td>gbt_model_1to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>-0.012652</td>\n",
       "      <td>gbt_model_3to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039428</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>-0.008823</td>\n",
       "      <td>gbt_model_5to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048188</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>-0.009727</td>\n",
       "      <td>gbt_model_7to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052150</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>-0.009962</td>\n",
       "      <td>gbt_model_9to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054304</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>gbt_model_13to125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054620</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>-0.010305</td>\n",
       "      <td>gbt_model_11to125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        f1  precision    recall     error         resultname\n",
       "0  0.020789  0.012362   0.020013  0.002103 -0.019869   gbt_model_1to125\n",
       "0  0.038596  0.007139   0.009235  0.004779 -0.012652   gbt_model_3to125\n",
       "0  0.039428  0.004828   0.004054  0.005644 -0.008823   gbt_model_5to125\n",
       "0  0.048188  0.005205   0.003518  0.006936 -0.009727   gbt_model_7to125\n",
       "0  0.052150  0.005284   0.003090  0.007504 -0.009962   gbt_model_9to125\n",
       "0  0.054304  0.005426   0.002558  0.008268 -0.010348  gbt_model_13to125\n",
       "0  0.054620  0.005427   0.002870  0.007983 -0.010305  gbt_model_11to125"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_25 = train_results25[validation_results25.columns[1:]] - validation_results25[validation_results25.columns[1:]]\n",
    "results_25['resultname'] = train_results25['resultname']\n",
    "results_25.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on generalization, the best in class features were as follows.\n",
    "- **gbt_model_1to150** - 0.019771\n",
    "- **gbt_model_3to1** - 0.029694\n",
    "- **gbt_model_5to1** - 0.038399\n",
    "- **gbt_model_7to1** - 0.043679\n",
    "- **gbt_model_9to1mean** - 0.048915\n",
    "- **gbt_model_11to1mean** - 0.052165\n",
    "- **gbt_model_13to175** - 0.052936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on generalization, the best in class features were as follows.\n",
    "- **gbt_model_1to175** - 0.024326\n",
    "- **gbt_model_3to125** - 0.028995\n",
    "- **gbt_model_5to175** - 0.040094\n",
    "- **gbt_model_7to150** - 0.041693\n",
    "- **gbt_model_9to175** - 0.049611\n",
    "- **gbt_model_11to1mean** - 0.050464\n",
    "- **gbt_model_13to1mean** - 0.052361"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination - Ensemble of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create Custom Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom evaluator that we can use instead of BinaryClassificationEvaluator() in grid search\n",
    "class ClassEvaluatorPandas:\n",
    "\n",
    "    def __init__(self, modelname, model, y_pred, y_true):\n",
    "        \n",
    "        # Initialize variables\n",
    "        self.modelname = modelname\n",
    "        self.y_pred = y_pred \n",
    "        self.y_true = y_true\n",
    "        self.model = model\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        self.cm = confusion_matrix(y_true,y_pred)\n",
    "        \n",
    "        # Calculate confusion matrix values\n",
    "        self.tp = self.cm[0][0]\n",
    "        self.fp = self.cm[0][1]\n",
    "        self.tn = self.cm[1][1]\n",
    "        self.fn = self.cm[1][0]\n",
    "        \n",
    "    def evaluate(self):\n",
    "        \n",
    "        # Calculate Metrics and add epsilon to prevent division by zero\n",
    "        precision = self.tp / float(self.tp + self.fp + 0.00001)\n",
    "        recall = self.tp / float(self.tp + self.fn + 0.00001)\n",
    "        f1 = (2 * precision * recall) / float(precision + recall + 0.00001)\n",
    "        error = (self.fp + self.fn + 0.00001) / (self.tp + self.fp + self.tn + self.fn + 0.00001)\n",
    "        \n",
    "        # Instantiate Evaluator and call AUC metric\n",
    "        from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(self.y_true, self.y_pred)\n",
    "        AUC = round(auc(false_positive_rate, true_positive_rate), ndigits=5)\n",
    "        \n",
    "        return pd.DataFrame(data=[[self.modelname, AUC, f1, precision, recall, error]], \n",
    "                            columns=['modelname', 'AUC', 'f1', 'precision', 'recall', 'error'])\n",
    "    \n",
    "    def confusionmatrix(self):\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        # Print Confusion Matrix\n",
    "        return self.cm\n",
    "        \n",
    "    \n",
    "    def modelparams(self):\n",
    "        scores = self.model.avgMetrics\n",
    "        params = [{p.name: v for p, v in m.items()} for m in self.model.getEstimatorParamMaps()]\n",
    "        params_pd = pd.DataFrame(params)\n",
    "        params_pd['AUC score'] = scores\n",
    "        return params_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - <font color=blue>Import Data</font> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Build Ensemble - Train Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Probability Values as Spark DF\n",
    "gbt_model_1to1_train = gbt_model_1to175.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_3to1_train = gbt_model_3to125.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_5to1_train = gbt_model_5to175.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_7to1_train = gbt_model_7to150.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_9to1_train = gbt_model_9to175.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_11to1_train = gbt_model_11to1mean.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_13to1_train = gbt_model_13to1mean.transform(DRV_Jan2016).select(['msno','prediction','is_churn']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single DF with all Predictions and Convert back to Spark DF\n",
    "Jan2016_predictsgbt = pd.merge(gbt_model_1to1_train[['msno','prediction']], gbt_model_3to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_5to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_7to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_9to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_11to1_train[['msno','prediction']], on='msno')\n",
    "Jan2016_predictsgbt = pd.merge(Jan2016_predictsgbt, gbt_model_13to1_train[['msno','prediction', 'is_churn']], on='msno')\n",
    "\n",
    "# Rename Columns\n",
    "Jan2016_predictsgbt.columns = ['msno', 'gbt_model_1to175', 'gbt_model_3to150', 'gbt_model_5to175', 'gbt_model_7to150', 'gbt_model_9to175', 'gbt_model_11to1mean', 'gbt_model_13to175', 'is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan2016_predictsgbt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to GCS\n",
    "sparkDf = spark.createDataFrame(Jan2016_predictsgbt)    \n",
    "sparkDf.coalesce(1).write.option(\"header\",\"true\").csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Jan2016_predictsgbt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Build Ensemble - Validation Set</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Prediction Values as Spark DF\n",
    "gbt_model_1to1_valid = gbt_model_1to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_3to1_valid = gbt_model_3to150.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_5to1_valid = gbt_model_5to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_7to1_valid = gbt_model_7to150.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_9to1_valid = gbt_model_9to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_11to1_valid = gbt_model_11to1mean.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n",
    "gbt_model_13to1_valid = gbt_model_13to175.transform(DRV_Feb2016).select(['msno','prediction','is_churn']).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single DF with all Predictions and Convert back to Spark DF\n",
    "Feb2016_predictsgbt = pd.merge(gbt_model_1to1_valid[['msno','prediction']], gbt_model_3to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_5to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_7to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_9to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_11to1_valid[['msno','prediction']], on='msno')\n",
    "Feb2016_predictsgbt = pd.merge(Feb2016_predictsgbt, gbt_model_13to1_valid[['msno','prediction', 'is_churn']], on='msno')\n",
    "\n",
    "# Rename Columns\n",
    "Feb2016_predictsgbt.columns = ['msno', 'gbt_model_1to175', 'gbt_model_3to150', 'gbt_model_5to175', 'gbt_model_7to150', 'gbt_model_9to175', 'gbt_model_11to1mean', 'gbt_model_13to175', 'is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feb2016_predictsgbt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to GCS\n",
    "sparkDf = spark.createDataFrame(Feb2016_predictsgbt)    \n",
    "sparkDf.coalesce(1).write.option(\"header\",\"true\").csv('gs://dataproc-fb3fa26d-011a-4757-afb9-5efdd6e75d60-us-east1/Datasets/KKBox User Data/Feb2016_predictsgbt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Import Ensemble Sets (if already built)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan2016_predictsgbt = pd.read_csv('D:\\J-5 Local\\Jan2016_predictsgbt.csv')\n",
    "Feb2016_predictsgbt = pd.read_csv('D:\\J-5 Local\\Feb2016_predictsgbt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Train x and y\n",
    "train_x = Jan2016_predictsgbt[Jan2016_predictsgbt.columns[1:-1]]\n",
    "train_y = Jan2016_predictsgbt['is_churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Validation x and y\n",
    "valid_x = Feb2016_predictsgbt[Feb2016_predictsgbt.columns[1:-1]]\n",
    "valid_y = Feb2016_predictsgbt['is_churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Train Model: All Splits, All Splits, XGB + RFECV</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Estimators\n",
    "rfc = RandomForestClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 78\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc1 = RFECV(rfc, min_features_to_select=1, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 70\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc2 = RFECV(rfc, min_features_to_select=2, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 60\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc3 = RFECV(rfc, min_features_to_select=3, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 50\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc4 = RFECV(rfc, min_features_to_select=4, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 39\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtrfc5 = RFECV(rfc, min_features_to_select=5, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1043\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtgmb4 = RFECV(gbm, min_features_to_select=4, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 718\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbtxgb4 = RFECV(xgb, min_features_to_select=4, cv=10, scoring='roc_auc').fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were createdgg\n",
    "ensembles_created = {\n",
    "                  'GBT_RFC1' : gbtrfc1,\n",
    "                  'GBT_RFC2' : gbtrfc2,\n",
    "                  'GBT_RFC3' : gbtrfc3,\n",
    "                  'GBT_RFC4' : gbtrfc4,\n",
    "                  'GBT_RFC5' : gbtrfc5,\n",
    "                  'GBT_GBM4' : gbtgmb4,\n",
    "                  'GBT_XGB4' : gbtxgb4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + RFECV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT_RFC1\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "Time spent for training: 736\n",
      "\n",
      "GBT_RFC2\n",
      "[[665625   7126]\n",
      " [  9382   9766]]\n",
      "Time spent for training: 737\n",
      "\n",
      "GBT_RFC3\n",
      "[[665613   7138]\n",
      " [  9371   9777]]\n",
      "Time spent for training: 738\n",
      "\n",
      "GBT_RFC4\n",
      "[[665632   7119]\n",
      " [  9391   9757]]\n",
      "Time spent for training: 738\n",
      "\n",
      "GBT_RFC5\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "Time spent for training: 739\n",
      "\n",
      "GBT_GBM4\n",
      "[[665629   7122]\n",
      " [  9381   9767]]\n",
      "Time spent for training: 741\n",
      "\n",
      "GBT_XGB4\n",
      "[[665632   7119]\n",
      " [  9391   9757]]\n",
      "Time spent for training: 742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_ensemble_results = pd.DataFrame()\n",
    "\n",
    "for model_name, model1 in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_ensemble_results = train_ensemble_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    end = time.time()\n",
    "    print('Time spent for training: {}'.format(round(end-start)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC1</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC2</td>\n",
       "      <td>0.74972</td>\n",
       "      <td>0.987747</td>\n",
       "      <td>0.989408</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.023859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC3</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.989390</td>\n",
       "      <td>0.986117</td>\n",
       "      <td>0.023860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC4</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC5</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_GBM4</td>\n",
       "      <td>0.74975</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.986102</td>\n",
       "      <td>0.023852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_XGB4</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname      AUC        f1  precision    recall     error\n",
       "0  GBT_RFC1  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBT_RFC2  0.74972  0.987747   0.989408  0.986101  0.023859\n",
       "0  GBT_RFC3  0.75000  0.987746   0.989390  0.986117  0.023860\n",
       "0  GBT_RFC4  0.74949  0.987745   0.989418  0.986088  0.023862\n",
       "0  GBT_RFC5  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBT_GBM4  0.74975  0.987750   0.989414  0.986102  0.023852\n",
       "0  GBT_XGB4  0.74949  0.987745   0.989418  0.986088  0.023862"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + RFECV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT_RFC1\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "Time spent for training: 743\n",
      "\n",
      "GBT_RFC2\n",
      "[[521507   6697]\n",
      " [ 11823   8100]]\n",
      "Time spent for training: 743\n",
      "\n",
      "GBT_RFC3\n",
      "[[521480   6724]\n",
      " [ 11821   8102]]\n",
      "Time spent for training: 744\n",
      "\n",
      "GBT_RFC4\n",
      "[[521515   6689]\n",
      " [ 11840   8083]]\n",
      "Time spent for training: 745\n",
      "\n",
      "GBT_RFC5\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "Time spent for training: 745\n",
      "\n",
      "GBT_GBM4\n",
      "[[521506   6698]\n",
      " [ 11828   8095]]\n",
      "Time spent for training: 747\n",
      "\n",
      "GBT_XGB4\n",
      "[[521515   6689]\n",
      " [ 11840   8083]]\n",
      "Time spent for training: 747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "valid_ensemble_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    valid_ensemble_results = valid_ensemble_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    end = time.time()\n",
    "    print('Time spent for training: {}'.format(round(end-start)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC1</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC2</td>\n",
       "      <td>0.69694</td>\n",
       "      <td>0.982549</td>\n",
       "      <td>0.987321</td>\n",
       "      <td>0.977832</td>\n",
       "      <td>0.033788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC3</td>\n",
       "      <td>0.69697</td>\n",
       "      <td>0.982525</td>\n",
       "      <td>0.987270</td>\n",
       "      <td>0.977834</td>\n",
       "      <td>0.033833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC4</td>\n",
       "      <td>0.69652</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.977801</td>\n",
       "      <td>0.033804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_RFC5</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_GBM4</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBT_XGB4</td>\n",
       "      <td>0.69652</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.977801</td>\n",
       "      <td>0.033804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelname      AUC        f1  precision    recall     error\n",
       "0  GBT_RFC1  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBT_RFC2  0.69694  0.982549   0.987321  0.977832  0.033788\n",
       "0  GBT_RFC3  0.69697  0.982525   0.987270  0.977834  0.033833\n",
       "0  GBT_RFC4  0.69652  0.982540   0.987336  0.977801  0.033804\n",
       "0  GBT_RFC5  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBT_GBM4  0.69682  0.982543   0.987319  0.977823  0.033799\n",
       "0  GBT_XGB4  0.69652  0.982540   0.987336  0.977801  0.033804"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>-0.009929</td>\n",
       "      <td>GBT_RFC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBT_RFC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBT_RFC5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05293</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>GBT_GBM4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05297</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>-0.009942</td>\n",
       "      <td>GBT_RFC4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05297</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>-0.009942</td>\n",
       "      <td>GBT_XGB4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05303</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>-0.009973</td>\n",
       "      <td>GBT_RFC3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error modelname\n",
       "0  0.05278  0.005198   0.002086  0.008269 -0.009929  GBT_RFC2\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBT_RFC1\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBT_RFC5\n",
       "0  0.05293  0.005207   0.002094  0.008280 -0.009947  GBT_GBM4\n",
       "0  0.05297  0.005205   0.002082  0.008287 -0.009942  GBT_RFC4\n",
       "0  0.05297  0.005205   0.002082  0.008287 -0.009942  GBT_XGB4\n",
       "0  0.05303  0.005221   0.002120  0.008282 -0.009973  GBT_RFC3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_ensemble_results[train_ensemble_results.columns[1:]] - valid_ensemble_results[valid_ensemble_results.columns[1:]]\n",
    "results_all['modelname'] = train_ensemble_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Train Model: All Splits, XGB + GridCV </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>XGBOOST Parameter Tuning</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Param Grid\n",
    "\n",
    "param_rfc = {\n",
    "         'bootstrap': [True, False],\n",
    "         'max_depth': [3, 5, 7],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_leaf': [1, 2, 4],\n",
    "         'min_samples_split': [2, 5, 10],\n",
    "         'n_estimators': [100, 500, 1000]\n",
    "        }\n",
    "\n",
    "param_gbm = {\n",
    "        'learning_rate': [.1, .5, .01],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        }\n",
    "\n",
    "param_xgb = {\n",
    "        'learning_rate': [.1, .5, .01],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        }\n",
    "\n",
    "# Instatiate Esitmator Object\n",
    "rfc = RandomForestClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# # Instatiate StratKFold Object\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "# Instatiate Random Search CV Object\n",
    "rscv_rfc = RandomizedSearchCV(rfc, param_distributions=param_rfc, n_iter=5, scoring='roc_auc', \n",
    "                                   n_jobs=4, cv=5, verbose=3)\n",
    "\n",
    "rscv_gbm = RandomizedSearchCV(gbm, param_distributions=param_gbm, n_iter=5, scoring='roc_auc', \n",
    "                                   n_jobs=4, cv=5, verbose=3)\n",
    "\n",
    "rscv_xgb = RandomizedSearchCV(xgb, param_distributions=param_xgb, n_iter=5, scoring='roc_auc', \n",
    "                                   n_jobs=4, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 913\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "GBMrfc = rscv_rfc.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 38.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 2584\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "GBMgmb = rscv_gbm.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training: 1312\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "GBMxgb = rscv_xgb.fit(train_x, train_y)\n",
    "end = time.time()\n",
    "print('Time spent for training: {}'.format(round(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Models that were created\n",
    "ensembles_created1 = {\n",
    "                  'GBM_RFC_rscv' : GBMrfc,\n",
    "                  'GBM_GBM_rscv' : GBMgmb,\n",
    "                  'GBM_XGB_rscv' : GBMxgb}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[665629   7122]\n",
      " [  9382   9766]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_rscv_results = train_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.74972</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.74972  0.987750   0.989414  0.986101  0.023853\n",
       "0  GBM_GBM_rscv  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBM_XGB_rscv  0.74964  0.987748   0.989415  0.986097  0.023856"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[521506   6698]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_rscv_results = validation_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.69682  0.982543   0.987319  0.977823  0.033799\n",
       "0  GBM_GBM_rscv  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBM_XGB_rscv  0.69682  0.982547   0.987327  0.977823  0.033791"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05290</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error     modelname\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_GBM_rscv\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_XGB_rscv\n",
       "0  0.05290  0.005207   0.002094  0.008278 -0.009946  GBM_RFC_rscv"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_rscv_results[train_rscv_results.columns[1:]] - validation_rscv_results[validation_rscv_results.columns[1:]]\n",
    "results_all['modelname'] = train_rscv_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[665615   7136]\n",
      " [  9377   9771]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[665632   7119]\n",
      " [  9391   9757]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_rscv_results = train_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.74984</td>\n",
       "      <td>0.987743</td>\n",
       "      <td>0.989393</td>\n",
       "      <td>0.986108</td>\n",
       "      <td>0.023866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.74949</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.986088</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.74964  0.987748   0.989415  0.986097  0.023856\n",
       "0  GBM_GBM_rscv  0.74984  0.987743   0.989393  0.986108  0.023866\n",
       "0  GBM_XGB_rscv  0.74949  0.987745   0.989418  0.986088  0.023862"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[521485   6719]\n",
      " [ 11833   8090]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[521515   6689]\n",
      " [ 11840   8083]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_rscv_results = validation_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.69667</td>\n",
       "      <td>0.982518</td>\n",
       "      <td>0.987280</td>\n",
       "      <td>0.977812</td>\n",
       "      <td>0.033846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.69652</td>\n",
       "      <td>0.982540</td>\n",
       "      <td>0.987336</td>\n",
       "      <td>0.977801</td>\n",
       "      <td>0.033804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.69682  0.982547   0.987327  0.977823  0.033791\n",
       "0  GBM_GBM_rscv  0.69667  0.982518   0.987280  0.977812  0.033846\n",
       "0  GBM_XGB_rscv  0.69652  0.982540   0.987336  0.977801  0.033804"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05297</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>-0.009942</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05317</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>-0.009980</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error     modelname\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_RFC_rscv\n",
       "0  0.05297  0.005205   0.002082  0.008287 -0.009942  GBM_XGB_rscv\n",
       "0  0.05317  0.005224   0.002113  0.008295 -0.009980  GBM_GBM_rscv"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_rscv_results[train_rscv_results.columns[1:]] - validation_rscv_results[validation_rscv_results.columns[1:]]\n",
    "results_all['modelname'] = train_rscv_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized for Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Train Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[665629   7122]\n",
      " [  9382   9766]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[665526   7225]\n",
      " [  9342   9806]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[665630   7121]\n",
      " [  9385   9763]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Model Results\n",
    "train_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(train_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=train_y)\n",
    "   \n",
    "    # Create a Dataframe of Train Results and Print Confusion Matrixes\n",
    "    train_rscv_results = train_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.74972</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.986101</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.75069</td>\n",
       "      <td>0.987701</td>\n",
       "      <td>0.989261</td>\n",
       "      <td>0.986157</td>\n",
       "      <td>0.023944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.74964</td>\n",
       "      <td>0.987748</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>0.986097</td>\n",
       "      <td>0.023856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.74972  0.987750   0.989414  0.986101  0.023853\n",
       "0  GBM_GBM_rscv  0.75069  0.987701   0.989261  0.986157  0.023944\n",
       "0  GBM_XGB_rscv  0.74964  0.987748   0.989415  0.986097  0.023856"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - <font color=blue>Evaluate Valuation Model: All Splits, XGB + GridCV </font> -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_RFC_rscv\n",
      "[[521506   6698]\n",
      " [ 11828   8095]]\n",
      "\n",
      "GBM_GBM_rscv\n",
      "[[521372   6832]\n",
      " [ 11765   8158]]\n",
      "\n",
      "GBM_XGB_rscv\n",
      "[[521510   6694]\n",
      " [ 11828   8095]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Model Results\n",
    "validation_rscv_results = pd.DataFrame()\n",
    "\n",
    "# Create a Dataframe of Validation Results and Print Confusion Matrixes\n",
    "for model_name, model1 in ensembles_created1.items():\n",
    "    \n",
    "    # Temporary Variables for our Loop\n",
    "    temp = model1.predict(valid_x)\n",
    "    temp_class = ClassEvaluatorPandas(modelname=model_name, model=model1, y_pred=temp, y_true=valid_y)\n",
    "\n",
    "    # Validation Results and Print Confusion Matrixes\n",
    "    validation_rscv_results = validation_rscv_results.append(temp_class.evaluate())\n",
    "    print('{}'.format(model_name))\n",
    "    print(temp_class.confusionmatrix())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982543</td>\n",
       "      <td>0.987319</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "      <td>0.69827</td>\n",
       "      <td>0.982473</td>\n",
       "      <td>0.987066</td>\n",
       "      <td>0.977933</td>\n",
       "      <td>0.033928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "      <td>0.69682</td>\n",
       "      <td>0.982547</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.977823</td>\n",
       "      <td>0.033791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelname      AUC        f1  precision    recall     error\n",
       "0  GBM_RFC_rscv  0.69682  0.982543   0.987319  0.977823  0.033799\n",
       "0  GBM_GBM_rscv  0.69827  0.982473   0.987066  0.977933  0.033928\n",
       "0  GBM_XGB_rscv  0.69682  0.982547   0.987327  0.977823  0.033791"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_rscv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=purple>Generalization Between Train and Validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05242</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>-0.009984</td>\n",
       "      <td>GBM_GBM_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05282</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>-0.009935</td>\n",
       "      <td>GBM_XGB_rscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.05290</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>GBM_RFC_rscv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AUC        f1  precision    recall     error     modelname\n",
       "0  0.05242  0.005229   0.002195  0.008225 -0.009984  GBM_GBM_rscv\n",
       "0  0.05282  0.005201   0.002088  0.008274 -0.009935  GBM_XGB_rscv\n",
       "0  0.05290  0.005207   0.002094  0.008278 -0.009946  GBM_RFC_rscv"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_all = train_rscv_results[train_rscv_results.columns[1:]] - validation_rscv_results[validation_rscv_results.columns[1:]]\n",
    "results_all['modelname'] = train_rscv_results['modelname']\n",
    "results_all.sort_values('AUC', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
